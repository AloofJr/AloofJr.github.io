<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【从入门到放弃-Java】并发编程-JUC-CopyOnWriteArrayList]]></title>
    <url>%2F4f4e5516.html</url>
    <content type="text"><![CDATA[前言上文【从入门到放弃-Java】并发编程-JUC-ConcurrentHashMap中，我们学习了常用的并发容器CurrentHashMap，本文我们来了解下List的并发容器：CopyOnWriteArrayList直接来看源码。 CopyOnWriteArrayListadd1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123; //使用synchronized加锁 synchronized (lock) &#123; Object[] es = getArray(); int len = es.length; //拷贝一份array，数组大小加一 es = Arrays.copyOf(es, len + 1); //设置最后一位为需要添加的值e es[len] = e; //将新的array设置为当前List的中的值，array是volatile类型的，因此写入后其它线程能立即看到 setArray(es); return true; &#125;&#125;/** * Inserts the specified element at the specified position in this * list. Shifts the element currently at that position (if any) and * any subsequent elements to the right (adds one to their indices). * * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public void add(int index, E element) &#123; //使用synchronized加锁 synchronized (lock) &#123; Object[] es = getArray(); int len = es.length; if (index &gt; len || index &lt; 0) throw new IndexOutOfBoundsException(outOfBounds(index, len)); Object[] newElements; int numMoved = len - index; if (numMoved == 0) //如果是在尾部插入，则将List中的数组直接copy并将长度加一 newElements = Arrays.copyOf(es, len + 1); else &#123; //如果不是在尾部插入，则以index处将原array分割成两部分copy到新数组中，空出index的位置 newElements = new Object[len + 1]; System.arraycopy(es, 0, newElements, 0, index); System.arraycopy(es, index, newElements, index + 1, numMoved); &#125; //在index出设置element的值 newElements[index] = element; setArray(newElements); &#125;&#125; addAll12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * Appends all of the elements in the specified collection to the end * of this list, in the order that they are returned by the specified * collection's iterator. * * @param c collection containing elements to be added to this list * @return &#123;@code true&#125; if this list changed as a result of the call * @throws NullPointerException if the specified collection is null * @see #add(Object) */public boolean addAll(Collection&lt;? extends E&gt; c) &#123; //获取数组 Object[] cs = (c.getClass() == CopyOnWriteArrayList.class) ? ((CopyOnWriteArrayList&lt;?&gt;)c).getArray() : c.toArray(); if (cs.length == 0) return false; synchronized (lock) &#123; Object[] es = getArray(); int len = es.length; Object[] newElements; if (len == 0 &amp;&amp; cs.getClass() == Object[].class) //如果当前List长度为0，则直接设置array为新数组 newElements = cs; else &#123; //将原数组copy为新的数组，新的数组长度为len+cs.lenth newElements = Arrays.copyOf(es, len + cs.length); //从len处开始，设置为需要添加的数组 System.arraycopy(cs, 0, newElements, len, cs.length); &#125; //将值写入List的成员变量array，array是volatile类型的，因此写入后其它线程能立即看到 setArray(newElements); return true; &#125;&#125;/** * Inserts all of the elements in the specified collection into this * list, starting at the specified position. Shifts the element * currently at that position (if any) and any subsequent elements to * the right (increases their indices). The new elements will appear * in this list in the order that they are returned by the * specified collection's iterator. * * @param index index at which to insert the first element * from the specified collection * @param c collection containing elements to be added to this list * @return &#123;@code true&#125; if this list changed as a result of the call * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; * @throws NullPointerException if the specified collection is null * @see #add(int,Object) */public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; //获取数组 Object[] cs = c.toArray(); synchronized (lock) &#123; Object[] es = getArray(); int len = es.length; if (index &gt; len || index &lt; 0) throw new IndexOutOfBoundsException(outOfBounds(index, len)); if (cs.length == 0) //如果当前List长度为0，直接返回false插入失败 return false; int numMoved = len - index; Object[] newElements; if (numMoved == 0) //如果List尾部插入，则直接在尾部copy要插入的数组 newElements = Arrays.copyOf(es, len + cs.length); else &#123; //如果不是在尾部插入，则以index处将原array分割成两部分copy到新数组中，空出index到index+cs.length长度的位置 newElements = new Object[len + cs.length]; System.arraycopy(es, 0, newElements, 0, index); System.arraycopy(es, index, newElements, index + cs.length, numMoved); &#125; //将index到index+cs.length填充需要插入的数组 System.arraycopy(cs, 0, newElements, index, cs.length); setArray(newElements); return true; &#125;&#125; get1234567//get方式就比较简单了 因为array是volatile类型的，不需要任何同步操作就可取到值，保证了并发public E get(int index) &#123; return elementAt(getArray(), index);&#125;static &lt;E&gt; E elementAt(Object[] a, int index) &#123; return (E) a[index];&#125; remove12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485/** * Removes the element at the specified position in this list. * Shifts any subsequent elements to the left (subtracts one from their * indices). Returns the element that was removed from the list. * * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E remove(int index) &#123; //同步锁 synchronized (lock) &#123; Object[] es = getArray(); int len = es.length; E oldValue = elementAt(es, index); int numMoved = len - index - 1; Object[] newElements; if (numMoved == 0) //如果是移除最后一个元素，则直接copy 0到len-2位置的元素即可 newElements = Arrays.copyOf(es, len - 1); else &#123; //如果不是最后一个元素，则copy需要删除数组[0,index)和[index,length]的元素到新数组。 newElements = new Object[len - 1]; System.arraycopy(es, 0, newElements, 0, index); System.arraycopy(es, index + 1, newElements, index, numMoved); &#125; setArray(newElements); return oldValue; &#125;&#125;/** * Removes the first occurrence of the specified element from this list, * if it is present. If this list does not contain the element, it is * unchanged. More formally, removes the element with the lowest index * &#123;@code i&#125; such that &#123;@code Objects.equals(o, get(i))&#125; * (if such an element exists). Returns &#123;@code true&#125; if this list * contained the specified element (or equivalently, if this list * changed as a result of the call). * * @param o element to be removed from this list, if present * @return &#123;@code true&#125; if this list contained the specified element */public boolean remove(Object o) &#123; Object[] snapshot = getArray(); //找到需要删除元素的索引 int index = indexOfRange(o, snapshot, 0, snapshot.length); return index &gt;= 0 &amp;&amp; remove(o, snapshot, index);&#125;/** * A version of remove(Object) using the strong hint that given * recent snapshot contains o at the given index. */private boolean remove(Object o, Object[] snapshot, int index) &#123; synchronized (lock) &#123; Object[] current = getArray(); int len = current.length; //加锁后验证数组是否在找到要删除的索引后改动过，如果改动的话，删除改动后的第一个o元素 if (snapshot != current) findIndex: &#123; int prefix = Math.min(index, len); for (int i = 0; i &lt; prefix; i++) &#123; if (current[i] != snapshot[i] &amp;&amp; Objects.equals(o, current[i])) &#123; index = i; break findIndex; &#125; &#125; if (index &gt;= len) return false; if (current[index] == o) break findIndex; index = indexOfRange(o, current, index, len); if (index &lt; 0) return false; &#125; //删除index位置的元素 Object[] newElements = new Object[len - 1]; System.arraycopy(current, 0, newElements, 0, index); System.arraycopy(current, index + 1, newElements, index, len - index - 1); setArray(newElements); return true; &#125;&#125; iterator1234567891011121314/** * Returns an iterator over the elements in this list in proper sequence. * * &lt;p&gt;The returned iterator provides a snapshot of the state of the list * when the iterator was constructed. No synchronization is needed while * traversing the iterator. The iterator does &lt;em&gt;NOT&lt;/em&gt; support the * &#123;@code remove&#125; method. * * @return an iterator over the elements in this list in proper sequence */public Iterator&lt;E&gt; iterator() &#123; //和ArrayList不同，CopyOnWriteArrayList在iterator遍历时，是对当前的array做了一个快照，在遍历期间，array可能会被别的线程更改，但快照不会改变，不受影响，因此在迭代中，数组元素不能改。 return new COWIterator&lt;E&gt;(getArray(), 0);&#125; 总结通过源码分析我们了解到，CopyOnWriteArrayList写操作时，都是以加synchronized锁并copy一份数组进行修改的方式进行的，如果List比较大时，会非常占用资源。 读操作时不用加锁，因为array是volatile的，不需要额外同步，因此读性能非常高。 因此CopyOnWriteArrayList更适用于读多写少的并发操作中。 在遍历时，将当前的array做一个快照，不受其他线程更改的影响。因此，在iterator中，list中的元素是不能更改的（因为更改的是快照，不会写到原数组中，更改一定是无效的）。 但在for循环时，CopyOnWriteArrayList中的元素可以被更改，而ArrayList不行，因为ArrayList的元素被遍历到时总会先检查是否被更改，更改会抛出ConcurrentModificationException]]></content>
      <tags>
        <tag>Java</tag>
        <tag>并发编程</tag>
        <tag>线程安全</tag>
        <tag>锁机制</tag>
        <tag>同步</tag>
        <tag>synchronized</tag>
        <tag>锁</tag>
        <tag>CopyOnWriteArrayList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-Java】并发编程-JUC-ConcurrentHashMap]]></title>
    <url>%2F304643e5.html</url>
    <content type="text"><![CDATA[前言上文【从入门到放弃-Java】并发编程-锁-synchronized中，我们介绍了可以使用内置锁synchronized同步类或代码块儿，到达线程安全的目的。 jdk帮我们把常用的一些模块封装成同步容器，如Vector、Hashtable、Collections.synchronizedXxx等。实现方式主要是将常用的容器类加了Synchronized同步。但我们知道，synchronized的频繁使用及竞争较为激烈时，对性能的影响比较大。 jdk1.5之后为我们提供了多种并发容器类，来提升同步容器的性能，这些类主要在java.util.concurrent包（简称juc，包内还有很多其它的并发工具类）中。我们本文先来学习下最常用的并发容器-ConcurrentHashMap。 ConcurrentHashMapput123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127/** * Maps the specified key to the specified value in this table. * Neither the key nor the value can be null. * * &lt;p&gt;The value can be retrieved by calling the &#123;@code get&#125; method * with a key that is equal to the original key. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with &#123;@code key&#125;, or * &#123;@code null&#125; if there was no mapping for &#123;@code key&#125; * @throws NullPointerException if the specified key or value is null */ // key和value都不能是nullpublic V put(K key, V value) &#123; return putVal(key, value, false);&#125;/** Implementation for put and putIfAbsent */final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //如果key或者value是null则立即抛出空指针异常 if (key == null || value == null) throw new NullPointerException(); //求hash值，将哈希的高位扩展到低位，并将高位强制为0。主要是为了减少hash冲突。 int hash = spread(key.hashCode()); int binCount = 0; //Node是Map.Entry的实现类，存放key、value。但key、value都不能是null。table的个数是2的n次方 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; K fk; V fv; //Node会延迟初始化、即在第一次插入数据的时候进行初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); //以原子的方式获取Node数组n-1位置的node，如果未null，尝试插入新值 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //使用cas的方式设置新node的key、value值 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value))) break; // no lock when adding to empty bin &#125; //如果Node是一个ForwardingNode，即有其它线程在扩容，则一起进行扩容操作 else if ((fh = f.hash) == MOVED) //如果当前正在扩容，则当前线程加入一起帮助扩容。 tab = helpTransfer(tab, f); //当使用putIfAbsent时，如果map中存在key，则返回对应的value else if (onlyIfAbsent // check first node without acquiring lock &amp;&amp; fh == hash &amp;&amp; ((fk = f.key) == key || (fk != null &amp;&amp; key.equals(fk))) &amp;&amp; (fv = f.val) != null) return fv; else &#123; V oldVal = null; /** * currentHashMap在JDK1.8中使用synchronized对需要修改的Node加锁同步，替代了JDK1.7及之前版本采用分段锁的方式。两种方式对比： * 1、1.7采用数组+Segment+分段锁的方式实现，分段锁及将几个map分为多个类似hashmap的结构，内部是多个Entry链表数组。加锁时，使用ReentrantLock对访问的Segment加锁，其它Segment可以正常操作。缺点是寻找节点需要两次hash，一次找到Segment，一次找到Entry链表的头部。 * 2、1.8采用数组+链表或红黑树的方式实现。使用Node替代了Segment，采用了CAS及synchronized进行同步。当Node链表的长度大于阙值（默认为8）时，会将链表转化为红黑树，提升查找性能。 * */ //通过synchronized的方式，对当前Node进行加锁操作。 synchronized (f) &#123; //判断f节点是否已被其它线程修改 if (tabAt(tab, i) == f) &#123; //如果当前Node还是链表结构时 if (fh &gt;= 0) &#123; binCount = 1; //遍历Node链表，设置value for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; //如果当前节点的key与我们要设置的key相等时，则将值设置为value。 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; //设置e为Node链表中的下一个元素，继续判断key是否相等，直到找到相等的key设置值。但如果链表中没有相等的key时，则在链表尾部新增一个元素，并设置值。 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value); break; &#125; &#125; &#125; //如果当前Node为红黑树结构时 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; //设置值 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; else if (f instanceof ReservationNode) throw new IllegalStateException("Recursive update"); &#125; &#125; //如果Node链表的长度大于8时，判断是链表结构扩容，或者转为红黑树结构 if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125;/** * Copies all of the mappings from the specified map to this one. * These mappings replace any mappings that this map had for any of the * keys currently in the specified map. * * @param m mappings to be stored in this map */public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; tryPresize(m.size()); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) putVal(e.getKey(), e.getValue(), false);&#125; get1234567891011121314151617181920212223242526272829303132333435/** * Returns the value to which the specified key is mapped, * or &#123;@code null&#125; if this map contains no mapping for the key. * * &lt;p&gt;More formally, if this map contains a mapping from a key * &#123;@code k&#125; to a value &#123;@code v&#125; such that &#123;@code key.equals(k)&#125;, * then this method returns &#123;@code v&#125;; otherwise it returns * &#123;@code null&#125;. (There can be at most one such mapping.) * * @throws NullPointerException if the specified key is null */public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; //获取hash值 int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; //如果获取到的Node的hash值和key的相等，则说明是链表。 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; //如果获取Node的hash值小于0则说明是非链式结构 else if (eh &lt; 0) //不断查找Node的下一个节点，知道找到为止 return (p = e.find(h, key)) != null ? p.val : null; //不断查找Node的下一个节点，直到找到为止（感觉和find重复了。最外层的if中只需要一个Node::find方法就能搞定。知道原因的大神请指正） while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; treeifyBin扩容或将结构转为红黑树1234567891011121314151617181920212223242526272829private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n; if (tab != null) &#123; //如果当前Node数组小于64则扩容，大于64时则转换为红黑树结构 if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) //rehash：resize tryPresize(n &lt;&lt; 1); //如果是链表结构则转换为红黑树结构 else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; synchronized (b) &#123; if (tabAt(tab, index) == b) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; //创建树节点，加入红黑树中 TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; &#125; setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125;&#125; tryPresize扩容操作123456789101112131415161718192021222324252627282930313233343536373839404142/** * Tries to presize table to accommodate the given number of elements. * * @param size number of elements (doesn't need to be perfectly accurate) */private final void tryPresize(int size) &#123; //size在传入前已经翻倍，这里会再次调整，变为为：大于(1.5 * oldSize + 1)的2的幂，且小于MAXIMUM_CAPACITY的大小 int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; //当sizeCtl小于等于0时。说明已有线程在初始化或者rehash了 while ((sc = sizeCtl) &gt;= 0) &#123; Node&lt;K,V&gt;[] tab = table; int n; 如果table是空，即未初始化的话，进行初始化。 if (tab == null || (n = tab.length) == 0) &#123; n = (sc &gt; c) ? sc : c; if (U.compareAndSetInt(this, SIZECTL, sc, -1)) &#123; try &#123; if (table == tab) &#123; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; //sc = n - n / 4 = 0.75，在final中，将sizeCtl设置为当前大小的0.75倍。大于这个阙值时，会再次进行扩容。 sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; &#125; &#125; else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; //如果还未开始迁移 else if (tab == table) &#123; int rs = resizeStamp(n); if (U.compareAndSetInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) // 开始迁移 transfer(tab, null); &#125; &#125;&#125; transfer将Node迁移至新的table中123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161/** * Moves and/or copies the nodes in each bin to new table. See * above for explanation. */private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; //设置线程迁移数据的步长，单核步长为n，多核为(n &gt;&gt;&gt; 3) / NCPU， 最小为16 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range //如果要迁移的table还未初始化，则进行初始化动作 if (nextTab == null) &#123; // initiating try &#123; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; //开始迁移，为要迁移的Node创建一个ForwardingNode节点。key和value都是null，hashcode为MOVED，nextTable指向新的table ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); //表示一个节点已被迁移完毕，可以迁移下一个了。 boolean advance = true; //迁移过程是否完毕。 boolean finishing = false; // to ensure sweep before committing nextTab //i是迁移的起始位置，bound是迁移的末尾。 for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; while (advance) &#123; int nextIndex, nextBound; //其实位置大于结束位置，说明已经迁移完毕 if (--i &gt;= bound || finishing) advance = false; //如果transferIndex小于等于0，则说明节点都已有线程在迁移了 else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; else if (U.compareAndSetInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; //迁移结束 if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; //迁移完毕后，将新的table赋值给table成员变量，修改sizeCtl完成迁移 if (finishing) &#123; nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; if (U.compareAndSetInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; //不相等说明还有线程没迁移完毕 if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; //所有线程迁移完毕后，设置finishing为完成。 finishing = advance = true; i = n; // recheck before commit &#125; &#125; //如果tab[i] = null，设置为fwd else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); //如果当前节点已经迁移，则处理下一个节点 else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; //加锁同步处理 synchronized (f) &#123; //验证下是否已经被其它线程处理 if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; //如果是链表结构 if (fh &gt;= 0) &#123; //按照Node中元素hash值的第log(2)(n)位，记为runBit，是0或1将Node链表分为两个新的链表。 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; //将runBit位为0的链表记为ln，为1的设为hn。这里是标记最后一个不一致的节点，lastRun后节点的runBit都一样，因此不用新修改节点，减少消耗 if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; //将runBit位为0的链表记为ln，为1的设为hn。 if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; //将分开的两个节点设置为table的i和i+n位。 setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; //如果是红黑树结构 else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; //按照Node中元素hash值的第log(2)(n)位，记为runBit，是0或1将Node红黑树分为两颗树。 TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; else if (f instanceof ReservationNode) throw new IllegalStateException("Recursive update"); &#125; &#125; &#125; &#125;&#125; 总结本文分析了currentHashMap是如何实现线程安全并提升性能的、如何扩容、JDK1.7和1.8实现方式的区别等 分Node加synchronize锁，不影响其它node的读写 Node节点hash冲突的元素数量少于8时，使用链表结构，大于等于8时，转换为红黑树结构提升查找性能 扩容时，会将table的长度扩大为大于(1.5 * oldSize + 1)的2的幂大小，并将每个Node根据log(2)(n)位是0或1，分为两个Node，放在新table的i和i+n的位置 JDK1.8将原currentHashMap使用数组+segment+ReentrantLock的方式改为数组+Node+CAS+synchronized的方式。减少了hash次数并采用cas和红黑树等多种优化提升性能]]></content>
      <tags>
        <tag>Java</tag>
        <tag>并发编程</tag>
        <tag>线程安全</tag>
        <tag>锁机制</tag>
        <tag>同步</tag>
        <tag>synchronized</tag>
        <tag>锁</tag>
        <tag>ConcurrentHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-Java】并发编程-锁-synchronized]]></title>
    <url>%2F3b701acb.html</url>
    <content type="text"><![CDATA[简介上篇【从入门到放弃-Java】并发编程-线程安全中，我们了解到，可以通过加锁机制来保护共享对象，来实现线程安全。 synchronized是java提供的一种内置的锁机制。通过synchronized关键字同步代码块。线程在进入同步代码块之前会自动获得锁，并在退出同步代码块时自动释放锁。内置锁是一种互斥锁。 本文来深入学习下synchronized。 使用同步方法同步非静态方法1234567891011121314151617181920212223242526272829public class Synchronized &#123; private static int count; private synchronized void add1() &#123; count++; System.out.println(count); &#125; public static void main(String[] args) throws InterruptedException &#123; Synchronized sync = new Synchronized(); Thread thread1 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; sync.add1(); &#125; &#125;); Thread thread2 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; sync.add1(); &#125; &#125;); thread1.start(); thread2.start(); Thread.sleep(1000); System.out.println(count); &#125;&#125; 结果符合预期：synchronized作用于非静态方法，锁定的是实例对象，如上所示锁的是sync对象，因此线程能够正确的运行，count的结果总会是20000。 1234567891011121314151617181920212223242526272829public class Synchronized &#123; private static int count; private synchronized void add1() &#123; count++; System.out.println(count); &#125; public static void main(String[] args) throws InterruptedException &#123; Synchronized sync = new Synchronized(); Synchronized sync1 = new Synchronized(); Thread thread1 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; sync.add1(); &#125; &#125;); Thread thread2 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; sync1.add1(); &#125; &#125;); thread1.start(); thread2.start(); Thread.sleep(1000); System.out.println(count); &#125;&#125; 结果不符合预期：如上所示，作用于非静态方法，锁的是实例化对象，因此当sync和sync1同时运行时，还是会出现线程安全问题，因为锁的是两个不同的实例化对象。 同步静态方法12345678910111213141516171819202122232425262728293031323334public class Synchronized &#123; private static int count; private static synchronized void add1() &#123; count++; System.out.println(count); &#125; private static synchronized void add11() &#123; count++; System.out.println(count); &#125; public static void main(String[] args) throws InterruptedException &#123; Synchronized sync = new Synchronized(); Synchronized sync1 = new Synchronized(); Thread thread1 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; Synchronized.add1(); &#125; &#125;); Thread thread2 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; Synchronized.add11(); &#125; &#125;); thread1.start(); thread2.start(); Thread.sleep(1000); System.out.println(count); &#125;&#125; 结果符合预期：锁静态方法时，锁的是类对象。因此在不同的线程中调用add1和add11依然会得到正确的结果。 同步代码块锁当前实例对象1234567891011121314151617181920212223242526272829303132333435public class Synchronized &#123; private static int count; private void add1() &#123; synchronized (this) &#123; count++; System.out.println(count); &#125; &#125; private static synchronized void add11() &#123; count++; System.out.println(count); &#125; public static void main(String[] args) throws InterruptedException &#123; Synchronized sync = new Synchronized(); Synchronized sync1 = new Synchronized(); Thread thread1 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; sync.add1(); &#125; &#125;); Thread thread2 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; sync1.add1(); &#125; &#125;); thread1.start(); thread2.start(); Thread.sleep(1000); System.out.println(count); &#125;&#125; 结果不符合预期：当synchronized同步方法块时，锁的是实例对象时，如上示例在不同的实例中调用此方法还是会出现线程安全问题。 锁其它实例对象1234567891011121314151617181920212223242526272829303132333435363738public class Synchronized &#123; private static int count; public String lock = new String(); private void add1() &#123; synchronized (lock) &#123; count++; System.out.println(count); &#125; &#125; private static synchronized void add11() &#123; count++; System.out.println(count); &#125; public static void main(String[] args) throws InterruptedException &#123; Synchronized sync = new Synchronized(); Synchronized sync1 = new Synchronized(); Thread thread1 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; sync.add1(); &#125; &#125;); Thread thread2 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; sync1.add1(); &#125; &#125;); thread1.start(); thread2.start(); Thread.sleep(1000); System.out.println(count); System.out.println(sync.lock == sync1.lock); &#125;&#125; 结果不符合预期：当synchronized同步方法块时，锁的是其它实例对象时，如上示例在不同的实例中调用此方法还是会出现线程安全问题。 1234567891011121314151617181920212223242526272829303132333435363738public class Synchronized &#123; private static int count; public String lock = ""; private void add1() &#123; synchronized (lock) &#123; count++; System.out.println(count); &#125; &#125; private static synchronized void add11() &#123; count++; System.out.println(count); &#125; public static void main(String[] args) throws InterruptedException &#123; Synchronized sync = new Synchronized(); Synchronized sync1 = new Synchronized(); Thread thread1 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; sync.add1(); &#125; &#125;); Thread thread2 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; sync1.add1(); &#125; &#125;); thread1.start(); thread2.start(); Thread.sleep(1000); System.out.println(count); System.out.println(sync.lock == sync1.lock); &#125;&#125; 结果符合预期：当synchronized同步方法块时，锁的虽然是其它实例对象时，但已上实例中，因为String = “” 是存放在常量池中的，实际上锁的还是相同的对象，因此是线程安全的 锁类对象1234567891011121314151617181920212223242526272829303132333435public class Synchronized &#123; private static int count; private void add1() &#123; synchronized (Synchronized.class) &#123; count++; System.out.println(count); &#125; &#125; private static synchronized void add11() &#123; count++; System.out.println(count); &#125; public static void main(String[] args) throws InterruptedException &#123; Synchronized sync = new Synchronized(); Synchronized sync1 = new Synchronized(); Thread thread1 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; sync.add1(); &#125; &#125;); Thread thread2 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; sync1.add1(); &#125; &#125;); thread1.start(); thread2.start(); Thread.sleep(1000); System.out.println(count); &#125;&#125; 结果符合预期：当synchronized同步方法块时，锁的是类对象时，如上示例在不同的实例中调用此方法是线程安全的。 锁机制123456789public class Synchronized &#123; private static int count; public static void main(String[] args) throws InterruptedException &#123; synchronized (Synchronized.class) &#123; count++; &#125; &#125;&#125; 使用javap -v Synchronized.class反编译class文件。 可以看到synchronized实际上是通过monitorenter和monitorexit来实现锁机制的。同一时刻，只能有一个线程进入监视区。从而保证线程的同步。 正常情况下在指令4进入监视区，指令14退出监视区然后指令15直接跳到指令23 return 但是在异常情况下异常都会跳转到指令18，依次执行到指令20monitorexit释放锁，防止出现异常时未释放的情况。这其实也是synchronized的优点：无论代码执行情况如何，都不会忘记主动释放锁。 想了解Monitors更多的原理可以点击查看 锁升级因为monitor依赖操作系统的Mutex lock实现，是一个比较重的操作，需要切换系统至内核态，开销非常大。因此在jdk1.6引入了偏向锁和轻量级锁。synchronized有四种状态：无锁 -&gt; 偏向锁 -&gt; 轻量级锁 -&gt; 重量级锁。 无锁没有对资源进行锁定，所有线程都能访问和修改。但同时只有一个线程能修改成功 偏向锁在锁竞争不强烈的情况下，通常一个线程会多次获取同一个锁，为了减少获取锁的代价 引入了偏向锁，会在java对象头中记录获取锁的线程的threadID。 当线程发现对象头的threadID存在时。判断与当前线程是否是同一线程。 如果是则不需要再次加、解锁。 如果不是，则判断threadID是否存活。不存活：设置为无锁状态，其他线程竞争设置偏向锁。存活：查找threadID堆栈信息判断是否需要继续持有锁。需要持有则升级threadID线程的锁为轻量级锁。不需要持有则撤销锁，设置为无锁状态等待其它线程竞争。 因为偏向锁的撤销操作还是比较重的，导致进入安全点，因此在竞争比较激烈时，会影响性能，可以使用-XX:-UseBiasedLocking=false禁用偏向锁。 轻量级锁当偏向锁升级为轻量级锁时，其它线程尝试通过CAS方式设置对象头来获取锁。 会先在当前线程的栈帧中设置Lock Record，用于存储当前对象头中的mark word的拷贝。 复制mark word的内容到lock record，并尝试使用cas将mark word的指针指向lock record 如果替换成功，则获取偏向锁 替换不成功，则会自旋重试一定次数。 自旋一定次数或有新的线程来竞争锁时，轻量级锁膨胀为重量级锁。 CASCAS即compare and swap（比较并替换）。是一种乐观锁机制。通常有三个值 V：内存中的实际值 A：旧的预期值 B：要修改的新值即V与A相等时，则替换V为B。即内存中的实际值与我们的预期值相等时，则替换为新值。 CAS可能遇到ABA问题，即内存中的值为A，变为B后，又变为了A，此时A为新值，不应该替换。可以采取：A-1，B-2，A-3的方式来避免这个问题 重量级锁自旋是消耗CPU的，因此在自旋一段时间，或者一个线程在自旋时，又有新的线程来竞争锁，则轻量级锁会膨胀为重量级锁。重量级锁，通过monitor实现，monitor底层实际是依赖操作系统的mutex lock（互斥锁）实现。需要从用户态，切换为内核态，成本比较高 总结本文我们一起学习了 synchronized的几种用法：同步方法、同步代码块。实际上是同步类或同步实例对象。 锁升级：无锁、偏向锁、轻量级锁、重量级锁以及其膨胀过程。 synchronized作为内置锁，虽然帮我们解决了线程安全问题，但是带来了性能的损失，因此一定不能滥用。使用时请注意同步块的作用范围。通常，作用范围越小，对性能的影响也就越小（注意权衡获取、释放锁的成本，不能为了缩小作用范围，而频繁的获取、释放）。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>并发编程</tag>
        <tag>线程安全</tag>
        <tag>锁机制</tag>
        <tag>同步</tag>
        <tag>synchronized</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-Java】并发编程-线程安全]]></title>
    <url>%2F3567c420.html</url>
    <content type="text"><![CDATA[概述并发编程，即多条线程在同一时间段内“同时”运行。 在多处理器系统已经普及的今天，多线程能发挥出其优势，如：一个8核cpu的服务器，如果只使用单线程的话，将有7个处理器被闲置，只能发挥出服务器八分之一的能力（忽略其它资源占用情况）。同时，使用多线程，可以简化我们对复杂任务的处理逻辑，降低业务模型的复杂程度。 因此并发编程对于提高服务器的资源利用率、提高系统吞吐量、降低编码难度等方面起着至关重要的作用。 以上是并发编程的优点，但是它同样引入了一个很重要的问题：线程安全。 什么是线程安全问题线程在并发执行时，因为cpu的调度等原因，线程会交替执行。如下图例子所示1234567891011121314151617181920212223public class SelfIncremental &#123; private static int count; public static void main(String[] args) &#123; Thread thread1 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; count++; System.out.println(count); &#125; &#125;); Thread thread2 = new Thread(() -&gt; &#123; for (int i = 0; i&lt; 10000; i++) &#123; count++; System.out.println(count); &#125; &#125;); thread1.start(); thread2.start(); &#125;&#125; 执行完毕后count的值并不是每次都能等于20000，会出现小于20000的情况，原因是thread1和thread2可能会交替执行。 如图所示： t1时刻: thread1 读取到count=100 t2时刻: thread2 读取到count=100 t3时刻: thread1 对count+1 t4时刻: thread2 对count+1 t5时刻: thread1 将101写入count t5时刻: thread2 将101写入count 因为count++ 不是一个原子操作，实际上会执行三步： 1、获取count的值 2、将count加1 3、将计算结果写入count 因此在并发执行时，两个线程同时读，可能会读取到相同的值，对相同的值加一，导致结果不符合预期，这种情况就是线程不安全。 线程安全：当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且调用时不需要采用额外的同步操作，这个类都能表现出正确的行为，那么就称这个类是线程安全的。 引发原因引发线程安全性问题的原因主要是共享内存可以被多个线程读写，因为读取和修改时机存在不确定性，导致有线程读到了过期数据，并在脏数据的基础上处理后写回共享内存，产生了错误的结果。 竟态条件在并发编程中，因为不恰当的执行时序而出现不正确的结果的情况被称为竟态条件。 常见的静态条件类型： 先检查后执行：首先观察到某个条件为真。根据这个观察结果采用相应的动作，但实际上在你观察到这个结果和采用相应动作之间，观察的结果可能发生改变变得无效，导致后续的所有操作都变得不可预期。（比如延迟初始化） 读取-修改-写入：基于对象之前的状态来定义对象状态的转换。但在读取到结果和修改之间，对象可能已被更改。这样就会基于错误的数据修改得出错误的结果并被写入。（比如递增操作） 发布与逸出发布：使对象能够在当前作用域之外的代码中使用。如将该对象的引用保存到其它代码可以访问的地方、在一个非私有的方法中返回该引用，将引用传递到其它类的方法中。如：12345public static Student student；public void init() &#123; student = new Student;&#125; 这里 student对象就被发布了。 逸出：当不该被发布的对象被发布了，就称为逸出。如12345private String name = "xxx";public String getString() &#123; return name;&#125; 这里name原为private类型但是却被getString方法发布了，就可以被视为逸出。 如何避免线程封闭线程封闭的对象只能由一个线程拥有，对象被封闭在该线程中，并且只有这个对象能修改。 线程封闭即不共享数据，仅在单线程内访问数据，这是实现线程安全最简单的方式之一。实现线程封闭可以通过： Ad-hoc线程封闭：即维护线程封闭性的职责完全由成熟实现承担。 栈封闭：通过局部变量才能访问对象，该局部变量被保存在执行线程的栈中，其他线程无法访问。 ThreadLocal类：将共享的全局变量转换为ThreadLocal对象，当线程终止后，这些值会被垃圾回收。 只读共享在没有额外同步的情况下，共享的对象可以由多个线程并发访问，但是任何线程都不能修改。共享的对象包括不可变对象和事实不可变对象。 不可变对象：如果某个对象在被创建后就不能修改，那么这个对象就是不可变对象。不可变对象一定是线程安全的。 线程安全共享线程安全的对象在其内部实现同步，因此多线程可以通过对象的公有接口来进行访问而不需要自己做同步。 保护对象被保护的对象只能通过持有特定的锁来访问。即通过加锁机制，确保对象的可见性及原子性。 内置锁：即通过synchronized关键字同步代码块。线程在进入同步代码块之前会自动获得锁，并在退出同步代码块时自动释放锁。内置锁是一种互斥锁。 重入锁：当线程视图获取一个已经持有的锁时，就会给锁的计数器加一，释放锁时计数器会减一。当计数器为0时，释放锁 volatile：访问volatile变量时，不会加锁，也不会阻塞线程执行。他只确保变量的可见性，是一种比synchronized更轻量级的同步机制。 总结本文主要是记录了学习《Java并发编程实站》前几章中，并发编程相关的一些概念。简单介绍了线程安全、锁机制等，接下来 我们会深入JUC源码，来深刻学习并发编程相关知识。 备注：本文主要源自对《Java并发编程实战》的学习笔记。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>并发编程</tag>
        <tag>线程安全</tag>
        <tag>锁机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-Java】并发编程-NIO-Selector]]></title>
    <url>%2F2cdc5430.html</url>
    <content type="text"><![CDATA[前言前两篇【从入门到放弃-Java】并发编程-NIO-Channel和【从入门到放弃-Java】并发编程-NIO-Buffer中我们学习了NIO中两个重要的概念Channel和Buffer。今天我们来看下另一个重要的内容 Selector 简介Selector是多路复用器，会不断轮询已经注册了的Channel。当有注册的channel产生连接、读、写等事件时，就会被Selector发现，从而可以进行相关后续操作。 Selector的好处是，可以通过一个线程来管理多个通道，减少了创建线程的资源占用及线程切换带来的消耗 SelectorSelectableChannel可以通过SelectionKey(记录channel和selector的注册关系)注册到Selector上。Selector维护了三个SelectionKey集合： key set：存放了Selector上已经注册了的Channel的key。可以通过keys()方法获取。 selected-key set：当之前注册感兴趣的事件到达时，set中的keys会被更新或添加，set中维护了当前至少有一个可以操作的事件的channel key的集合。是key set的子集。可以使用selectedKeys()获取。 cancelled-key：存放已经调用cancel方法取消，等待下次操作时会调用deregister取消注册的channel，调用deregister后，所有的set中都没有这个channel的key了。 open12345678910111213141516/** * Opens a selector. * * &lt;p&gt; The new selector is created by invoking the &#123;@link * java.nio.channels.spi.SelectorProvider#openSelector openSelector&#125; method * of the system-wide default &#123;@link * java.nio.channels.spi.SelectorProvider&#125; object. &lt;/p&gt; * * @return A new selector * * @throws IOException * If an I/O error occurs */public static Selector open() throws IOException &#123; return SelectorProvider.provider().openSelector();&#125; 开启selector，具体的实现会根据操作系统类型创建不同的实现类，如macOS下实际上是new了一个KQueueSelectorProvider实例，低层基于操作系统的kqueue实现。 register123456789101112131415161718192021222324252627282930protected final SelectionKey register(AbstractSelectableChannel ch, int ops, Object attachment)&#123; if (!(ch instanceof SelChImpl)) throw new IllegalSelectorException(); //新建一个SelectionKey，记录channel与selector之间的注册关系 SelectionKeyImpl k = new SelectionKeyImpl((SelChImpl)ch, this); k.attach(attachment); //前置操作，这里主要是判断下selector是否还处于open状态 // register (if needed) before adding to key set implRegister(k); // 添加selectionKey至key set // add to the selector's key set, removing it immediately if the selector // is closed. The key is not in the channel's key set at this point but // it may be observed by a thread iterating over the selector's key set. keys.add(k); try &#123; // 更新注册的事件码 k.interestOps(ops); &#125; catch (ClosedSelectorException e) &#123; assert ch.keyFor(this) == null; keys.remove(k); k.cancel(); throw e; &#125; return k;&#125; 注册selector和channel之间的事件关系。 select12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// timeout超时@Overridepublic final int select(long timeout) throws IOException &#123; if (timeout &lt; 0) throw new IllegalArgumentException("Negative timeout"); return lockAndDoSelect(null, (timeout == 0) ? -1 : timeout);&#125;@Overridepublic final int select() throws IOException &#123; return lockAndDoSelect(null, -1);&#125;// 不阻塞@Overridepublic final int selectNow() throws IOException &#123; return lockAndDoSelect(null, 0);&#125;private int lockAndDoSelect(Consumer&lt;SelectionKey&gt; action, long timeout) throws IOException&#123; synchronized (this) &#123; ensureOpen(); if (inSelect) throw new IllegalStateException("select in progress"); inSelect = true; try &#123; synchronized (publicSelectedKeys) &#123; return doSelect(action, timeout); &#125; &#125; finally &#123; inSelect = false; &#125; &#125;&#125;protected int doSelect(Consumer&lt;SelectionKey&gt; action, long timeout) throws IOException&#123; assert Thread.holdsLock(this); // 如果timeout = 0时，不阻塞 long to = Math.min(timeout, Integer.MAX_VALUE); // max kqueue timeout boolean blocking = (to != 0); boolean timedPoll = (to &gt; 0); int numEntries; processUpdateQueue(); processDeregisterQueue(); try &#123; // 设置interrupt 可以处理中断信号 防止线程一直阻塞 begin(blocking); // 轮询的监听，直到有注册的事件发生或超时。 do &#123; long startTime = timedPoll ? System.nanoTime() : 0; numEntries = KQueue.poll(kqfd, pollArrayAddress, MAX_KEVENTS, to); if (numEntries == IOStatus.INTERRUPTED &amp;&amp; timedPoll) &#123; // timed poll interrupted so need to adjust timeout long adjust = System.nanoTime() - startTime; to -= TimeUnit.MILLISECONDS.convert(adjust, TimeUnit.NANOSECONDS); if (to &lt;= 0) &#123; // timeout expired so no retry numEntries = 0; &#125; &#125; &#125; while (numEntries == IOStatus.INTERRUPTED); assert IOStatus.check(numEntries); &#125; finally &#123; end(blocking); &#125; processDeregisterQueue(); return processEvents(numEntries, action);&#125; selectedKeys1234public final Set&lt;SelectionKey&gt; selectedKeys() &#123; ensureOpen(); return publicSelectedKeys;&#125; 获取被事件唤醒的key注意：当被遍历处理selectedKeys时，key被处理完需要手动remove掉，防止下次被重复消费，selectedKeys不会帮你删除已处理过的key。 close123456789101112131415161718192021222324252627282930public final void close() throws IOException &#123; boolean open = selectorOpen.getAndSet(false); if (!open) return; implCloseSelector();&#125;public final void implCloseSelector() throws IOException &#123; //通知处于阻塞的select方法立即返回 wakeup(); synchronized (this) &#123; implClose(); synchronized (publicSelectedKeys) &#123; // 遍历所有的SelectionKey，取消注册 // Deregister channels Iterator&lt;SelectionKey&gt; i = keys.iterator(); while (i.hasNext()) &#123; SelectionKeyImpl ski = (SelectionKeyImpl)i.next(); deregister(ski); SelectableChannel selch = ski.channel(); if (!selch.isOpen() &amp;&amp; !selch.isRegistered()) ((SelChImpl)selch).kill(); selectedKeys.remove(ski); i.remove(); &#125; assert selectedKeys.isEmpty() &amp;&amp; keys.isEmpty(); &#125; &#125;&#125; SelectionKeySelectionKey在channel register时创建。用来记录channel和selector之间的注册事件关系。事件主要有： OP_READ OP_WRITE OP_CONNECT OP_ACCEPT 每个SelectionKey有两个由整数表示的操作集合，用来标识channel支持的操作类型。 interest set：是在创建SelectionKey时定义的，当集合中的操作发生时，将会把channel置为ready状态ready set：检测到selector中已经就绪的操作类型集合 channel123public SelectableChannel channel() &#123; return (SelectableChannel)channel;&#125; 获取SelectionKey中的channel selector123public Selector selector() &#123; return selector;&#125; 获取SelectionKey中的selector isReadable123public final boolean isReadable() &#123; return (readyOps() &amp; OP_READ) != 0;&#125; 根据readyOps(readySet)判断channel是否是可读状态 isWritable123public final boolean isWritable() &#123; return (readyOps() &amp; OP_WRITE) != 0;&#125; 根据readyOps(readySet)判断channel是否是可写状态 isConnectable123public final boolean isConnectable() &#123; return (readyOps() &amp; OP_CONNECT) != 0;&#125; 根据readyOps(readySet)判断channel是否是connect状态，通常是客户端使用，判断连接是否建立 isReadable123public final boolean isAcceptable() &#123; return (readyOps() &amp; OP_ACCEPT) != 0;&#125; 根据readyOps(readySet)判断channel是否是accept状态，通常是服务端使用，判断是否有客户端请求建立连接 总结通过使用selector，可以使用一个线程来管理多个连接。需要注意的一点是，通常读、写操作都是比较耗时的，为了提高服务端的性能应该把Selector::select和read、write的具体处理逻辑在不同的线程中处理。即：使用一个线程来进行select，只做分发。在获取到就绪的SelectionKey后，通过线程池在不同的线程中处理读写操作。 通过学习完NIO相关的知识，我们可以很清楚的回答下面这个问题 问：基于BIO实现的server端，当建立100个连接时，需要多少个线程？基于NIO实现的呢？ 答：基于BIO实现的server端，通常需要由一个线程accept，并为每个新建立的连接创建一个线程去处理IO操作，因此需要 1个accept线程+100个IO线程基于NIO实现的server端，使用Selector多路复用机制，由一个线程进行select，为了提高并发可以使用线程池来处理IO操作，通常为了发挥CPU的性能会创建(cpu核数 x 2)个线程来处理IO操作。因此需要 1个select线程 + cpu核数 x 2 个IO线程]]></content>
      <tags>
        <tag>Java</tag>
        <tag>NIO</tag>
        <tag>buffer</tag>
        <tag>ByteBuffer</tag>
        <tag>socket</tag>
        <tag>Channel</tag>
        <tag>并发编程</tag>
        <tag>Selector</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-Java】并发编程-NIO-Buffer]]></title>
    <url>%2Fd5a7a7f5.html</url>
    <content type="text"><![CDATA[前言上篇【从入门到放弃-Java】并发编程-NIO-Channel中我们学习到channel是双向通道，数据通过channel在实体（文件、socket）和缓冲区（buffer）中可以双向传输。 本文我们就来学习下buffer 简介buffer即缓冲区，实际上是一块内存，可以用来写入、读取数据。是一个线性的、大小有限的、顺序承载基础数据类型的内存块。 buffer有三个重要的属性： capacity：缓冲池大小，是不可变的。当buffer写满时，需要先清空才能继续写入。 limit：是buffer中不可以被读或者写的第一个元素的位置，limit的大小永远不会超过capacity（在写模式下，limit等于capacity） position：是buffer中可以被读或者写的第一个元素的位置，position的大小永远不会超过limit 除了boolean外，每一个基础数据类型都有对应的buffer。如：ByteBuffer、CharBuffer、LongBuffer等 buffer不是线程安全的，如果要在多线程中使用 需要加锁控制 接下来以ByteBuffer为例开始学习。 ByteBufferallocateDirect1234public static ByteBuffer allocateDirect(int capacity) &#123; //会创建一个容量大小为capacity的DirectByteBuffer（ByteBuffer的子类） return new DirectByteBuffer(capacity);&#125; allocate123456public static ByteBuffer allocate(int capacity) &#123; if (capacity &lt; 0) throw createCapacityException(capacity); //会创建一个容量大小为capacity的HeapByteBuffer（ByteBuffer的子类） return new HeapByteBuffer(capacity, capacity);&#125; HeapByteBuffer和DirectByteBuffer的区别： DirectByteBuffer是直接调用native方法在本机os::malloc()创建堆外内存；HeapByteBuffer是直接在jvm的堆中分配内存。 当buffer中的数据和磁盘、网络等的交互都在操作系统的内核中发生时，使用DirectByteBuffer能避免从内核态-&gt;用户态-&gt;内核态的切换开销，所有的处理都在内核中进行，性能会比较好 当频繁创建操作数据量比较小的buffer时，使用HeapByteBuffer在jvm堆中分配内存能抵消掉使用DirectByteBuffer带来的好处。 wrap12345678910111213public static ByteBuffer wrap(byte[] array, int offset, int length)&#123; try &#123; return new HeapByteBuffer(array, offset, length); &#125; catch (IllegalArgumentException x) &#123; throw new IndexOutOfBoundsException(); &#125;&#125;public static ByteBuffer wrap(byte[] array) &#123; return wrap(array, 0, array.length); &#125; 将byte数组包装成一个ByteBuffer 读数据 使用get方法从Buffer中读取数据 从Buffer中读取数据到Channel即：Channel::write() (从buffer中读取数据写入到资源中，所以是write) 写数据 使用put方法直接设置Buffer中的数据 从Channel中读取数据到Buffer即：Channel::read() (从资源中读取数据写入到buffer中，所以是read) position12345678910111213//获取buffer中当前position的位置public final int position() &#123; return position;&#125;//设置buffer的position为newPosition，注意newPosition要大于0且小于limit，如果remark大于newPosition则设置为-1public Buffer position(int newPosition) &#123; if (newPosition &gt; limit | newPosition &lt; 0) throw createPositionException(newPosition); position = newPosition; if (mark &gt; position) mark = -1; return this;&#125; limit1234567891011121314//获取buffer中当前limit的位置public final int limit() &#123; return limit;&#125;//设置buffer的limit为newLimit，注意newLimit要大于0且小于capacity。如果position大于newLimit这设置为newLimit，如果remark大于newLimit则设置为-1public Buffer limit(int newLimit) &#123; if (newLimit &gt; capacity | newLimit &lt; 0) throw createLimitException(newLimit); limit = newLimit; if (position &gt; limit) position = limit; if (mark &gt; limit) mark = -1; return this;&#125; mark12345public Buffer mark() &#123; //标记mark为当前position mark = position; return this;&#125; 将当前位置做标记，在使用reset方法时，可以回到当前mark的位置 reset12345678public Buffer reset() &#123; int m = mark; if (m &lt; 0) throw new InvalidMarkException(); //设置position为当前mark position = m; return this;&#125; 回到之前设置mark的位置 clear123456789public Buffer clear() &#123; //设置position为0 position = 0; //limit设置为capacity大小 limit = capacity; //mark设置为-1（初始化） mark = -1; return this;&#125; 读取完数据后调用clear，即将buffer逻辑上清空了，可以从0开始写入数据 flip123456789public Buffer flip() &#123; //limit设置为当前位置 limit = position; //position设置为0 position = 0; //mark设置为-1（初始化） mark = -1; return this;&#125; 将buffer从写模式设置为读模式，limit设置为当前position的位置，即只能读取limit大小的数据 rewind12345public Buffer rewind() &#123; position = 0; mark = -1; return this;&#125; 将position设置为0，即从头开始读取 remaining123public final int remaining() &#123; return limit - position;&#125; 返回buffer中还有多少byte是未读的 hasRemaining123public final boolean hasRemaining() &#123; return position &lt; limit;&#125; 是否已读完 compact1234567public ByteBuffer compact() &#123; System.arraycopy(hb, ix(position()), hb, ix(0), remaining()); position(remaining()); limit(capacity()); discardMark(); return this;&#125; 将position和limit直接的数据copy到byteBuffer的起始处，将已读数据清空，并将新的position设置为当前未读数据的末尾。这样能避免clear方法会将未读数据也清空的问题 slice123456789101112131415161718192021public ByteBuffer slice() &#123; return new HeapByteBufferR(hb, -1, 0, this.remaining(), this.remaining(), this.position() + offset);&#125;ByteBuffer slice(int pos, int lim) &#123; assert (pos &gt;= 0); assert (pos &lt;= lim); int rem = lim - pos; return new HeapByteBufferR(hb, -1, 0, rem, rem, pos + offset);&#125; 新创建一个ByteBuffer，将缓存区分片，设置一个子缓冲区，实际上内存还是共享的，数据发生改变，两个缓冲区读取的数据都会是改变后的。 总结Buffer最重要的三个属性：position、limit、capacity。牢记这三个属性的含义及读写切换时，设置值是如何变化的，Buffer的核心知识点就掌握了。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>NIO</tag>
        <tag>buffer</tag>
        <tag>ByteBuffer</tag>
        <tag>socket</tag>
        <tag>Channel</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-Java】并发编程-NIO-Channel]]></title>
    <url>%2F3c79e6b3.html</url>
    <content type="text"><![CDATA[前言上篇【从入门到放弃-Java】并发编程-NIO使用简单介绍了nio的基础使用，本篇将深入源码分析nio中channel的实现。 简介channel即通道，可以用来读、写数据，它是全双工的可以同时用来读写操作。这也是它与stream流的最大区别。 channel需要与buffer配合使用，channel通道的一端是buffer，一端是数据源实体，如文件、socket等。在nio中，通过channel的不同实现来处理 不同实体与数据buffer中的数据传输。 channel接口：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package java.nio.channels;import java.io.IOException;import java.io.Closeable;/** * A nexus for I/O operations. * * &lt;p&gt; A channel represents an open connection to an entity such as a hardware * device, a file, a network socket, or a program component that is capable of * performing one or more distinct I/O operations, for example reading or * writing. * * &lt;p&gt; A channel is either open or closed. A channel is open upon creation, * and once closed it remains closed. Once a channel is closed, any attempt to * invoke an I/O operation upon it will cause a &#123;@link ClosedChannelException&#125; * to be thrown. Whether or not a channel is open may be tested by invoking * its &#123;@link #isOpen isOpen&#125; method. * * &lt;p&gt; Channels are, in general, intended to be safe for multithreaded access * as described in the specifications of the interfaces and classes that extend * and implement this interface. * * * @author Mark Reinhold * @author JSR-51 Expert Group * @since 1.4 */public interface Channel extends Closeable &#123; /** * Tells whether or not this channel is open. * * @return &lt;tt&gt;true&lt;/tt&gt; if, and only if, this channel is open */ public boolean isOpen(); /** * Closes this channel. * * &lt;p&gt; After a channel is closed, any further attempt to invoke I/O * operations upon it will cause a &#123;@link ClosedChannelException&#125; to be * thrown. * * &lt;p&gt; If this channel is already closed then invoking this method has no * effect. * * &lt;p&gt; This method may be invoked at any time. If some other thread has * already invoked it, however, then another invocation will block until * the first invocation is complete, after which it will return without * effect. &lt;/p&gt; * * @throws IOException If an I/O error occurs */ public void close() throws IOException;&#125; 常见的channel实现有： FileChannel：文件读写数据通道 SocketChannel：TCP读写网络数据通道 ServerSocketChannel：服务端网络数据读写通道，可以监听TCP连接。对每一个新进来的连接都会创建一个SocketChannel。 DatagramChannel：UDP读写网络数据通道 FileChannel FileChannel是一个抽象类，它继承了AbstractInterruptibleChannel类，并实现了 SeekableByteChannel, GatheringByteChannel, ScatteringByteChannel接口。具体的实现类主要是sun.nio.ch.FileChannelImpl。下面详细分析下FileChannelImpl中每个方法的具体实现。 open1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374private FileChannelImpl(FileDescriptor var1, String var2, boolean var3, boolean var4, boolean var5, Object var6) &#123; //主要记载操作系统维护的文件描述符 this.fd = var1; //是否可读 this.readable = var3; //是否可写 this.writable = var4; //是否以追加的方式打开 this.append = var5; this.parent = var6; this.path = var2; //底层使用native的read和write来处理文件的 this.nd = new FileDispatcherImpl(var5);&#125;//FileInputStream::getChannel 调用 FileChannelImpl.open(fd, path, true, false, this) 获取只读channelpublic static FileChannel open(FileDescriptor var0, String var1, boolean var2, boolean var3, Object var4) &#123; return new FileChannelImpl(var0, var1, var2, var3, false, var4);&#125;//FileOutputStream::getChannel 调用 FileChannelImpl.open(fd, path, false, true, append, this) 获取只写channelpublic static FileChannel open(FileDescriptor var0, String var1, boolean var2, boolean var3, boolean var4, Object var5) &#123; return new FileChannelImpl(var0, var1, var2, var3, var4, var5);&#125;private FileChannelImpl(FileDescriptor fd, String path, boolean readable, boolean writable, boolean direct, Object parent)&#123; this.fd = fd; //是否可读 this.readable = readable; //是否可写 this.writable = writable; //对于从流创建的channel，在结束时要做不同的清理动作，（openJDK中才有，sun的jdk中没有） this.parent = parent; //源文件的path this.path = path; //是否使用DirectIO this.direct = direct; this.nd = new FileDispatcherImpl(); if (direct) &#123; assert path != null; this.alignment = nd.setDirectIO(fd, path); &#125; else &#123; this.alignment = -1; &#125; //当parent不存在时，则注册一个cleaner，否则交由parent做清理动作。 // Register a cleaning action if and only if there is no parent // as the parent will take care of closing the file descriptor. // FileChannel is used by the LambdaMetaFactory so a lambda cannot // be used here hence we use a nested class instead. this.closer = parent != null ? null : CleanerFactory.cleaner().register(this, new Closer(fd));&#125;// Used by FileInputStream.getChannel(), FileOutputStream.getChannel// and RandomAccessFile.getChannel()public static FileChannel open(FileDescriptor fd, String path, boolean readable, boolean writable, boolean direct, Object parent)&#123; return new FileChannelImpl(fd, path, readable, writable, direct, parent);&#125; open方法主要是返回一个新new的FileChannelImpl对象，初始化时设置fileDescriptor、readable、writable、append、parent、path等属性，看变量名很容易理解，在此不赘述变量含义。 read123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081//实现自SeekableByteChannel接口的方法，将文件中的内容读取到给定的byteBuffer中public int read(ByteBuffer dst) throws IOException &#123; //保证读写时，channel处于开启状态 ensureOpen(); //判断是否可读 if (!readable) throw new NonReadableChannelException(); synchronized (positionLock) &#123; if (direct) Util.checkChannelPositionAligned(position(), alignment); int n = 0; int ti = -1; try &#123; //开始阻塞，并注册为Interruptible，可以被中断 beginBlocking(); //将当前线程添加到NativeThreadSet中，并返回索引，方便后续操作。 //NativeThreadSet是一个线程安全的本地线程集合，方便管理，用来发送信号 ti = threads.add(); if (!isOpen()) return 0; do &#123; //当未被系统中断（即读取完毕）或channel未被关闭，则一直读，将内容写入到byteBuffer（dst）中 n = IOUtil.read(fd, dst, -1, direct, alignment, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; //把当前线程从set中移出 threads.remove(ti); //结束，释放锁 endBlocking(n &gt; 0); assert IOStatus.check(n); &#125; &#125;&#125;//实现自ScatteringByteChannel接口的方法，将文件中的内容依次读取到给定的byteBuffer数组中。public long read(ByteBuffer[] dsts, int offset, int length) throws IOException&#123; if ((offset &lt; 0) || (length &lt; 0) || (offset &gt; dsts.length - length)) throw new IndexOutOfBoundsException(); //保证读写时，channel处于开启状态 ensureOpen(); //判断是否可读 if (!readable) throw new NonReadableChannelException(); synchronized (positionLock) &#123; if (direct) Util.checkChannelPositionAligned(position(), alignment); long n = 0; int ti = -1; try &#123; //开始阻塞，并注册为Interruptible，可以被中断 beginBlocking(); //将当前线程添加到NativeThreadSet中，并返回索引，方便后续操作。 //NativeThreadSet是一个线程安全的本地线程集合，方便管理，用来发送信号 ti = threads.add(); if (!isOpen()) return 0; do &#123; //当未被系统中断（即读取完毕）或channel未被关闭，则一直读，将内容写入到byteBuffer（dst）中 n = IOUtil.read(fd, dsts, offset, length, direct, alignment, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; //把当前线程从set中移出 threads.remove(ti); //结束，释放锁 endBlocking(n &gt; 0); assert IOStatus.check(n); &#125; &#125;&#125; write123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778//实现自SeekableByteChannel接口的方法，将byteBuffer中的内容写入到文件中public int write(ByteBuffer src) throws IOException &#123; //保证写时，channel处于开启状态 ensureOpen(); //判断是否可写 if (!writable) throw new NonWritableChannelException(); synchronized (positionLock) &#123; if (direct) Util.checkChannelPositionAligned(position(), alignment); int n = 0; int ti = -1; try &#123; //开始阻塞，并注册为Interruptible，可以被中断 beginBlocking(); //将当前线程添加到NativeThreadSet中，并返回索引，方便后续操作。 //NativeThreadSet是一个线程安全的本地线程集合，方便管理，用来发送信号 ti = threads.add(); if (!isOpen()) return 0; do &#123; //当未被系统中断（即写入完毕）或channel未被关闭，则一直写，将内容写入到文件中 n = IOUtil.write(fd, src, -1, direct, alignment, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; //把当前线程从set中移出 threads.remove(ti); //结束，释放锁 assert IOStatus.check(n); &#125; &#125;&#125;//实现自GatheringByteChannel接口的方法，将byteBuffer数组中的内容依次写入到文件中public long write(ByteBuffer[] srcs, int offset, int length) throws IOException&#123; if ((offset &lt; 0) || (length &lt; 0) || (offset &gt; srcs.length - length)) throw new IndexOutOfBoundsException(); //保证写时，channel处于开启状态 ensureOpen(); //判断是否可写 if (!writable) throw new NonWritableChannelException(); synchronized (positionLock) &#123; if (direct) Util.checkChannelPositionAligned(position(), alignment); long n = 0; int ti = -1; try &#123; //开始阻塞，并注册为Interruptible，可以被中断 beginBlocking(); //将当前线程添加到NativeThreadSet中，并返回索引，方便后续操作。 //NativeThreadSet是一个线程安全的本地线程集合，方便管理，用来发送信号 ti = threads.add(); if (!isOpen()) return 0; do &#123; //当未被系统中断（即写入完毕）或channel未被关闭，则一直写，将内容写入到文件中 n = IOUtil.write(fd, srcs, offset, length, direct, alignment, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(n); &#125; finally &#123; //把当前线程从set中移出 threads.remove(ti); //结束，释放锁 assert IOStatus.check(n); &#125; &#125;&#125; position123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//实现自SeekableByteChannel接口的方法，获取当前channel的positionpublic long position() throws IOException &#123; ensureOpen(); synchronized (positionLock) &#123; long p = -1; int ti = -1; try &#123; beginBlocking(); ti = threads.add(); if (!isOpen()) return 0; boolean append = fdAccess.getAppend(fd); do &#123; //append模式下，position在channel的末尾 // in append-mode then position is advanced to end before writing p = (append) ? nd.size(fd) : nd.seek(fd, -1); &#125; while ((p == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return IOStatus.normalize(p); &#125; finally &#123; threads.remove(ti); endBlocking(p &gt; -1); assert IOStatus.check(p); &#125; &#125;&#125;//实现自SeekableByteChannel接口的方法，设置当前channel的position为newPositionpublic FileChannel position(long newPosition) throws IOException &#123; ensureOpen(); if (newPosition &lt; 0) throw new IllegalArgumentException(); synchronized (positionLock) &#123; long p = -1; int ti = -1; try &#123; beginBlocking(); ti = threads.add(); if (!isOpen()) return null; do &#123; //设置当前position为newPosition p = nd.seek(fd, newPosition); &#125; while ((p == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); return this; &#125; finally &#123; threads.remove(ti); endBlocking(p &gt; -1); assert IOStatus.check(p); &#125; &#125;&#125; size实现自SeekableByteChannel接口的方法，返回当前实体（文件）的大小 truncate实现自SeekableByteChannel接口的方法，用来截取文件至newSize大小 force实现自SeekableByteChannel接口的方法，用来将channel中尚未写入磁盘的数据强制落盘 transferTo将fileChannel中的数据传递至另一个channel transferFrom从其它channel读取数据至fileChannel SocketChannel open12345678910111213141516/** * Opens a socket channel. * * &lt;p&gt; The new channel is created by invoking the &#123;@link * java.nio.channels.spi.SelectorProvider#openSocketChannel * openSocketChannel&#125; method of the system-wide default &#123;@link * java.nio.channels.spi.SelectorProvider&#125; object. &lt;/p&gt; * * @return A new socket channel * * @throws IOException * If an I/O error occurs */public static SocketChannel open() throws IOException &#123; return SelectorProvider.provider().openSocketChannel();&#125; open方法是调用SelectorProvider中实现了java.nio.channels.spi.SelectorProvider#openSocketChannel的方法，底层实际是new SocketChannelImpl，调用native方法创建socket connect12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public boolean connect(SocketAddress sa) throws IOException &#123; //校验Address是否合法 InetSocketAddress isa = Net.checkAddress(sa); //获取系统安全管理器 SecurityManager sm = System.getSecurityManager(); if (sm != null) //校验IP和端口是否被允许连接 sm.checkConnect(isa.getAddress().getHostAddress(), isa.getPort()); InetAddress ia = isa.getAddress(); //如果是本机地址，则获取本机的host if (ia.isAnyLocalAddress()) ia = InetAddress.getLocalHost(); try &#123; //加读锁 readLock.lock(); try &#123; //加写锁 writeLock.lock(); try &#123; int n = 0; //是否阻塞 boolean blocking = isBlocking(); try &#123; //开启connect前的校验并设置为ST_CONNECTIONPENDING，如果blocking是true 即阻塞模式，则记录当前线程的ID，以便接收信号处理。 beginConnect(blocking, isa); do &#123; //调用native connect方法 n = Net.connect(fd, ia, isa.getPort()); &#125; while (n == IOStatus.INTERRUPTED &amp;&amp; isOpen()); &#125; finally &#123; //结束连接 endConnect(blocking, (n &gt; 0)); &#125; assert IOStatus.check(n); return n &gt; 0; &#125; finally &#123; //释放写锁 writeLock.unlock(); &#125; &#125; finally &#123; //释放读锁 readLock.unlock(); &#125; &#125; catch (IOException ioe) &#123; // connect failed, close the channel close(); throw SocketExceptions.of(ioe, isa); &#125;&#125; configureBlocking实现自SelectableChannel的接口方法，调用native方法设置socket的阻塞状态 register在AbstractSelectableChannel中定义，注册要监听的事件。12345678910111213141516171819202122232425262728public final SelectionKey register(Selector sel, int ops, Object att) throws ClosedChannelException&#123; if ((ops &amp; ~validOps()) != 0) throw new IllegalArgumentException(); if (!isOpen()) throw new ClosedChannelException(); synchronized (regLock) &#123; if (isBlocking()) throw new IllegalBlockingModeException(); synchronized (keyLock) &#123; // re-check if channel has been closed if (!isOpen()) throw new ClosedChannelException(); SelectionKey k = findKey(sel); if (k != null) &#123; k.attach(att); k.interestOps(ops); &#125; else &#123; // 向Selector中注册事件 // New registration k = ((AbstractSelector)sel).register(this, ops, att); addKey(k); &#125; return k; &#125; &#125;&#125; read123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//实现自ReadableByteChannel接口的方法，从socket中读取数据至ByteBuffer@Overridepublic int read(ByteBuffer buf) throws IOException &#123; Objects.requireNonNull(buf); readLock.lock(); try &#123; boolean blocking = isBlocking(); int n = 0; try &#123; //检查channel是否开启并已经是connected的状态。如果blocking是true 即阻塞模式，则记录当前线程的ID，以便接收信号处理。 beginRead(blocking); // check if input is shutdown if (isInputClosed) return IOStatus.EOF; //如果是阻塞模式，则一直读取直到数据读取完毕；非阻塞模式则直接调用native方法不需要等待。 if (blocking) &#123; do &#123; n = IOUtil.read(fd, buf, -1, nd); &#125; while (n == IOStatus.INTERRUPTED &amp;&amp; isOpen()); &#125; else &#123; n = IOUtil.read(fd, buf, -1, nd); &#125; &#125; finally &#123; endRead(blocking, n &gt; 0); if (n &lt;= 0 &amp;&amp; isInputClosed) return IOStatus.EOF; &#125; return IOStatus.normalize(n); &#125; finally &#123; readLock.unlock(); &#125;&#125;//实现自ScatteringByteChannel接口的方法，从socket中依次读取数据至ByteBuffer数组@Overridepublic long read(ByteBuffer[] dsts, int offset, int length) throws IOException&#123; Objects.checkFromIndexSize(offset, length, dsts.length); readLock.lock(); try &#123; boolean blocking = isBlocking(); long n = 0; try &#123; beginRead(blocking); // check if input is shutdown if (isInputClosed) return IOStatus.EOF; //如果是阻塞模式，则一直读取直到数据读取完毕；非阻塞模式则直接调用native方法不需要等待。 if (blocking) &#123; do &#123; n = IOUtil.read(fd, dsts, offset, length, nd); &#125; while (n == IOStatus.INTERRUPTED &amp;&amp; isOpen()); &#125; else &#123; n = IOUtil.read(fd, dsts, offset, length, nd); &#125; &#125; finally &#123; endRead(blocking, n &gt; 0); if (n &lt;= 0 &amp;&amp; isInputClosed) return IOStatus.EOF; &#125; return IOStatus.normalize(n); &#125; finally &#123; readLock.unlock(); &#125;&#125; write123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990//实现自ReadableByteChannel接口的方法，将ByteBuffer中的数据写入socket@Overridepublic int write(ByteBuffer buf) throws IOException &#123; Objects.requireNonNull(buf); writeLock.lock(); try &#123; boolean blocking = isBlocking(); int n = 0; try &#123; beginWrite(blocking); //如果是阻塞模式，则一直读取直到数据读取完毕；非阻塞模式则直接调用native方法不需要等待。 if (blocking) &#123; do &#123; n = IOUtil.write(fd, buf, -1, nd); &#125; while (n == IOStatus.INTERRUPTED &amp;&amp; isOpen()); &#125; else &#123; n = IOUtil.write(fd, buf, -1, nd); &#125; &#125; finally &#123; endWrite(blocking, n &gt; 0); if (n &lt;= 0 &amp;&amp; isOutputClosed) throw new AsynchronousCloseException(); &#125; return IOStatus.normalize(n); &#125; finally &#123; writeLock.unlock(); &#125;&#125;@Overridepublic long write(ByteBuffer[] srcs, int offset, int length) throws IOException&#123; Objects.checkFromIndexSize(offset, length, srcs.length); writeLock.lock(); try &#123; boolean blocking = isBlocking(); long n = 0; try &#123; beginWrite(blocking); //如果是阻塞模式，则一直等待直到数据写入完毕；非阻塞模式则直接调用native方法不需要等待。 if (blocking) &#123; do &#123; n = IOUtil.write(fd, srcs, offset, length, nd); &#125; while (n == IOStatus.INTERRUPTED &amp;&amp; isOpen()); &#125; else &#123; n = IOUtil.write(fd, srcs, offset, length, nd); &#125; &#125; finally &#123; endWrite(blocking, n &gt; 0); if (n &lt;= 0 &amp;&amp; isOutputClosed) throw new AsynchronousCloseException(); &#125; return IOStatus.normalize(n); &#125; finally &#123; writeLock.unlock(); &#125;&#125;//实现自ReadableByteChannel接口的方法，将ByteBuffer数组中的数据依次写入socket/** * Writes a byte of out of band data. */int sendOutOfBandData(byte b) throws IOException &#123; writeLock.lock(); try &#123; boolean blocking = isBlocking(); int n = 0; try &#123; beginWrite(blocking); //如果是阻塞模式，则一直等待直到数据写入完毕；非阻塞模式则直接调用native方法不需要等待。 if (blocking) &#123; do &#123; n = sendOutOfBandData(fd, b); &#125; while (n == IOStatus.INTERRUPTED &amp;&amp; isOpen()); &#125; else &#123; n = sendOutOfBandData(fd, b); &#125; &#125; finally &#123; endWrite(blocking, n &gt; 0); if (n &lt;= 0 &amp;&amp; isOutputClosed) throw new AsynchronousCloseException(); &#125; return IOStatus.normalize(n); &#125; finally &#123; writeLock.unlock(); &#125;&#125; ServerSocketChannel socket12345678@Overridepublic ServerSocket socket() &#123; synchronized (stateLock) &#123; if (socket == null) socket = ServerSocketAdaptor.create(this); return socket; &#125;&#125; bind1234567891011121314151617181920212223242526@Overridepublic ServerSocketChannel bind(SocketAddress local, int backlog) throws IOException &#123; synchronized (stateLock) &#123; ensureOpen(); if (localAddress != null) throw new AlreadyBoundException(); InetSocketAddress isa = (local == null) ? new InetSocketAddress(0) : Net.checkAddress(local); SecurityManager sm = System.getSecurityManager(); if (sm != null) sm.checkListen(isa.getPort()); //绑定前做一些前置处理，如将tcp socket文件描述符转换成SDP NetHooks.beforeTcpBind(fd, isa.getAddress(), isa.getPort()); //绑定IP和地址 Net.bind(fd, isa.getAddress(), isa.getPort()); //开始监听，设置socket上最多可以挂起backlog个连接，若backlog小于1 则默认设置50个 Net.listen(fd, backlog &lt; 1 ? 50 : backlog); localAddress = Net.localAddress(fd); &#125; return this;&#125; accept123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Overridepublic SocketChannel accept() throws IOException &#123; acceptLock.lock(); try &#123; int n = 0; FileDescriptor newfd = new FileDescriptor(); InetSocketAddress[] isaa = new InetSocketAddress[1]; boolean blocking = isBlocking(); try &#123; begin(blocking); do &#123; //阻塞等待接收客户端链接 n = accept(this.fd, newfd, isaa); &#125; while (n == IOStatus.INTERRUPTED &amp;&amp; isOpen()); &#125; finally &#123; end(blocking, n &gt; 0); assert IOStatus.check(n); &#125; if (n &lt; 1) return null; //新接收的socket初始设置为阻塞模式（因此非阻塞模式的每次需要显示设置） // newly accepted socket is initially in blocking mode IOUtil.configureBlocking(newfd, true); InetSocketAddress isa = isaa[0]; //用新接收的socket创建SocketChannel SocketChannel sc = new SocketChannelImpl(provider(), newfd, isa); // check permitted to accept connections from the remote address SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; try &#123; sm.checkAccept(isa.getAddress().getHostAddress(), isa.getPort()); &#125; catch (SecurityException x) &#123; sc.close(); throw x; &#125; &#125; return sc; &#125; finally &#123; acceptLock.unlock(); &#125;&#125; ServerSocketChannel并没有read和write方法，只是继承了AbstractSelectableChannel，以便在selector中使用 DatagramChannel open12345678910111213141516171819public DatagramChannelImpl(SelectorProvider sp) throws IOException&#123; super(sp); ResourceManager.beforeUdpCreate(); try &#123; //如果不支持IPv6则使用IPv4 this.family = Net.isIPv6Available() ? StandardProtocolFamily.INET6 : StandardProtocolFamily.INET; //设置非流式的socket（tcp是流模式协议，udp是数据报模式协议） this.fd = Net.socket(family, false); this.fdVal = IOUtil.fdVal(fd); &#125; catch (IOException ioe) &#123; ResourceManager.afterUdpClose(); throw ioe; &#125;&#125; receive1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public SocketAddress receive(ByteBuffer dst) throws IOException &#123; if (dst.isReadOnly()) throw new IllegalArgumentException("Read-only buffer"); readLock.lock(); try &#123; boolean blocking = isBlocking(); int n = 0; ByteBuffer bb = null; try &#123; SocketAddress remote = beginRead(blocking, false); boolean connected = (remote != null); SecurityManager sm = System.getSecurityManager(); if (connected || (sm == null)) &#123; // connected or no security manager do &#123; n = receive(fd, dst, connected); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); if (n == IOStatus.UNAVAILABLE) return null; &#125; else &#123; // Cannot receive into user's buffer when running with a // security manager and not connected bb = Util.getTemporaryDirectBuffer(dst.remaining()); for (;;) &#123; do &#123; n = receive(fd, bb, connected); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); if (n == IOStatus.UNAVAILABLE) return null; InetSocketAddress isa = (InetSocketAddress)sender; try &#123; sm.checkAccept(isa.getAddress().getHostAddress(), isa.getPort()); &#125; catch (SecurityException se) &#123; // Ignore packet bb.clear(); n = 0; continue; &#125; bb.flip(); dst.put(bb); break; &#125; &#125; //sender:发送方地址， Set by receive0 (## ugh) assert sender != null; return sender; &#125; finally &#123; if (bb != null) Util.releaseTemporaryDirectBuffer(bb); endRead(blocking, n &gt; 0); assert IOStatus.check(n); &#125; &#125; finally &#123; readLock.unlock(); &#125;&#125; send123456789101112131415161718192021222324252627282930313233343536373839404142434445public int send(ByteBuffer src, SocketAddress target) throws IOException&#123; Objects.requireNonNull(src); InetSocketAddress isa = Net.checkAddress(target, family); writeLock.lock(); try &#123; boolean blocking = isBlocking(); int n = 0; try &#123; //当connect后，remote会设置为连接的地址 SocketAddress remote = beginWrite(blocking, false); if (remote != null) &#123; // connected if (!target.equals(remote)) &#123; throw new AlreadyConnectedException(); &#125; do &#123; n = IOUtil.write(fd, src, -1, nd); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); &#125; else &#123; // not connected SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; InetAddress ia = isa.getAddress(); if (ia.isMulticastAddress()) &#123; sm.checkMulticast(ia); &#125; else &#123; sm.checkConnect(ia.getHostAddress(), isa.getPort()); &#125; &#125; do &#123; n = send(fd, src, isa); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); &#125; &#125; finally &#123; endWrite(blocking, n &gt; 0); assert IOStatus.check(n); &#125; return IOStatus.normalize(n); &#125; finally &#123; writeLock.unlock(); &#125;&#125; connect12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@Overridepublic DatagramChannel connect(SocketAddress sa) throws IOException &#123; InetSocketAddress isa = Net.checkAddress(sa, family); SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; InetAddress ia = isa.getAddress(); if (ia.isMulticastAddress()) &#123; sm.checkMulticast(ia); &#125; else &#123; sm.checkConnect(ia.getHostAddress(), isa.getPort()); sm.checkAccept(ia.getHostAddress(), isa.getPort()); &#125; &#125; readLock.lock(); try &#123; writeLock.lock(); try &#123; synchronized (stateLock) &#123; ensureOpen(); if (state == ST_CONNECTED) throw new AlreadyConnectedException(); int n = Net.connect(family, fd, isa.getAddress(), isa.getPort()); if (n &lt;= 0) throw new Error(); // Can't happen // connected remoteAddress = isa; state = ST_CONNECTED; // refresh local address localAddress = Net.localAddress(fd); // flush any packets already received. boolean blocking = isBlocking(); if (blocking) &#123; IOUtil.configureBlocking(fd, false); &#125; try &#123; ByteBuffer buf = ByteBuffer.allocate(100); while (receive(buf) != null) &#123; buf.clear(); &#125; &#125; finally &#123; if (blocking) &#123; IOUtil.configureBlocking(fd, true); &#125; &#125; &#125; &#125; finally &#123; writeLock.unlock(); &#125; &#125; finally &#123; readLock.unlock(); &#125; return this;&#125; udp是数据报模式的协议，是没有connect的。这里的connect实际上是在底层忽略了与其他地址的数据传输。在connect后，就可以像socketChannel似得使用read和write了 总结本文学习了各种channel的实现，主要是对底层native方法的一些封装，针对不同属性的实体（文件、socket），使用对应的channel与byteBuffer传输数据。再通过byteBuffer与byte数据进行转换。channel的实现中，封装了大量的native方法，重要的底层实现全在native中，后续可以深入学习下。 本文中出现的byteBuffer和selector将在接下来的文章中，单独分析。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>NIO</tag>
        <tag>socket</tag>
        <tag>并发编程</tag>
        <tag>channel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-Java】并发编程-NIO使用]]></title>
    <url>%2Fe57ab61.html</url>
    <content type="text"><![CDATA[前言上文【从入门到放弃-SpringBoot】SpringBoot源码分析-请求过程中我们了解到，tomcat接收、返回请求的过程都是基于NIO实现的。日常工作中有很多基于NIO的使用，我们知道NIO可以提高系统的并发度，接下来的系列我们来深入学习下NIO，本文先从使用上简单概述。 NIO概述NIO即non-blocking（New IO），是指jdk1.4 及以上版本里提供的新api。 NIO和IO最大的区别：IO是以流的方式处理数据，而NIO是以块的方式处理数据；IO对事件的处理是阻塞的，NIO是非阻塞的 NIO的核心部分： Channel Buffer Selector NIO主要分为标准输入输出和网络请求 标准输入输出NIO读取1234567891011121314151617181920212223242526272829private static void readNio() &#123; try &#123; //1、开启文件读取流 FileInputStream fileInputStream = new FileInputStream("/Users/my/Desktop/123.txt"); //2、获取fileChannel FileChannel channel = fileInputStream.getChannel(); //3、设置ByteBuffer大小，一次能容纳capacity字节 int capacity = 9; ByteBuffer bf = ByteBuffer.allocate(capacity); //4、当read返回-1时，表示文件读取完毕 int length = -1; while ((length = channel.read(bf)) != -1) &#123; byte[] bytes = bf.array(); System.out.println(new String(bytes, 0, length)); //4、将bf position置为0，方便下次读取 bf.clear(); &#125; channel.close(); fileInputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 写入123456789101112131415161718192021222324252627282930313233343536private static void writeNio() &#123; try &#123; //1、打开文件写入流 FileOutputStream fileOutputStream = new FileOutputStream("/Users/my/Desktop/123.txt"); //2、获取fileChannel FileChannel channel = fileOutputStream.getChannel(); //3、初始化byteBuffer String str = "萨达案发生大大sdada34;sdds'"; ByteBuffer bf = ByteBuffer.allocate(1024); //4、将bf position置为0，方便下次读取 bf.clear(); //5、从byteBuffer的position位置填充byte bf.put(str.getBytes()); //6、将bf position置为0，limit设置为position避免写入内容过多 bf.flip(); int length = 0; //7、如果position小于limit即未写入完毕 while (bf.hasRemaining()) &#123; //8、将buffer内容写入channel length = channel.write(bf); System.out.println(bf); &#125; channel.close(); fileOutputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 网络NIO服务端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105package com.my.tools.nio;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.util.Iterator;public class ServerSocket &#123; private static ServerSocket serverSocket; private Selector selector; public static void main(String[] args) throws Exception &#123; ServerSocket.getInstance().init(8001).listen(); &#125; public static ServerSocket getInstance() &#123; if (serverSocket == null) &#123; synchronized (ServerSocket.class) &#123; if (serverSocket == null) &#123; serverSocket = new ServerSocket(); &#125; &#125; &#125; return serverSocket; &#125; public ServerSocket init(int port) throws IOException &#123; //初始化channel ServerSocketChannel server = ServerSocketChannel.open(); //绑定本机8001端口 server.socket().bind(new InetSocketAddress(8001)); //设置为非阻塞模式 server.configureBlocking(false); //开启selector管理器 selector = Selector.open(); //将selector注册至server，并设置只处理accept事件 server.register(selector, SelectionKey.OP_ACCEPT); return this; &#125; public void listen() throws Exception &#123; System.out.println("server start"); //无限循环持续监听 while (true) &#123; //会阻塞 直到监听到注册的事件 selector.select(); //获取唤醒的事件 Iterator&lt;SelectionKey&gt; selectorKeys = selector.selectedKeys().iterator(); while (selectorKeys.hasNext()) &#123; SelectionKey key = selectorKeys.next(); //将已取出的SelectionKey删除，防止重复处理 selectorKeys.remove(); if (key.isAcceptable()) &#123; //获取到服务端的socket ServerSocketChannel serverSocketChannel = (ServerSocketChannel) key.channel(); //获取接收到的客户端socket SocketChannel socketChannel = serverSocketChannel.accept(); socketChannel.configureBlocking(false); //向客户端写消息 socketChannel.write(ByteBuffer.wrap(new String("hello, this is server").getBytes())); //注册监听read事件 socketChannel.register(selector, SelectionKey.OP_READ); System.out.println("accept"); &#125; else if (key.isReadable()) &#123; //使用selector获取channel SocketChannel socketChannel = (SocketChannel) key.channel(); socketChannel.configureBlocking(false); ByteBuffer buffer = ByteBuffer.allocate(1024); //读消息 int length = socketChannel.read(buffer); String string = new String(buffer.array(), 0 , length); System.out.println("read:" + socketChannel + string); //写消息 socketChannel.write(ByteBuffer.wrap(("server " + System.currentTimeMillis()).getBytes())); Thread.sleep(10000); &#125; &#125; &#125; &#125;&#125; 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package com.my.tools.nio;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.SocketChannel;import java.util.Iterator;public class ClientSocket &#123; public static ClientSocket clientSocket; private static Selector selector; public static void main(String[] args) throws Exception &#123; ClientSocket.getInstance().init("localhost", 8001).listen(); &#125; public static ClientSocket getInstance() &#123; if (clientSocket == null) &#123; synchronized (ClientSocket.class) &#123; if (clientSocket == null) &#123; clientSocket = new ClientSocket(); &#125; &#125; &#125; return clientSocket; &#125; public ClientSocket init(String ip, int port) throws IOException &#123; SocketChannel socketChannel = SocketChannel.open(); socketChannel.connect(new InetSocketAddress(ip, port)); socketChannel.configureBlocking(false); selector = Selector.open(); socketChannel.register(selector, SelectionKey.OP_CONNECT | SelectionKey.OP_READ); return this; &#125; public void listen() throws Exception &#123; System.out.println("client start"); while (true) &#123; selector.select(); Iterator&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys().iterator(); while (selectionKeys.hasNext()) &#123; SelectionKey selectionKey = selectionKeys.next(); selectionKeys.remove(); if (selectionKey.isConnectable()) &#123; SocketChannel socketChannel = (SocketChannel) selectionKey.channel(); socketChannel.configureBlocking(false); ByteBuffer buffer = ByteBuffer.wrap(new String("hello, this is client").getBytes()); socketChannel.write(buffer); socketChannel.register(selector, SelectionKey.OP_READ); System.out.println("client write"); &#125; else if (selectionKey.isReadable()) &#123; SocketChannel socketChannel = (SocketChannel) selectionKey.channel(); socketChannel.configureBlocking(false); ByteBuffer buffer = ByteBuffer.allocate(1024); int length = socketChannel.read(buffer); System.out.println("client read: " + socketChannel + new String(buffer.array(), 0, length)); socketChannel.write(ByteBuffer.wrap(("client " + System.currentTimeMillis()).getBytes())); Thread.sleep(10000); &#125; &#125; &#125; &#125;&#125; 总结上述示例展示了最简单的文件NIO和网络NIO用法，接下来会深入分析每个方法的源码，并对性能进行调优。]]></content>
      <tags>
        <tag>Java</tag>
        <tag>NIO</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-SpringBoot】SpringBoot源码分析-请求过程]]></title>
    <url>%2F788cd0c2.html</url>
    <content type="text"><![CDATA[前言前文【从入门到放弃-SpringBoot】SpringBoot源码分析-WebServer中以SpringBoot中内嵌的Tomcat为例了解了webserver的启动过程。 本文将分析下一条请求在SpringBoot中，从接受到返回都经历了那些过程。 Acceptor 在上文最后的connector启动时，会开始acceptor线程等待接收请求。 Acceptor::run123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public void run() &#123; int errorDelay = 0; // Loop until we receive a shutdown command while (endpoint.isRunning()) &#123; // Loop if endpoint is paused while (endpoint.isPaused() &amp;&amp; endpoint.isRunning()) &#123; state = AcceptorState.PAUSED; try &#123; Thread.sleep(50); &#125; catch (InterruptedException e) &#123; // Ignore &#125; &#125; if (!endpoint.isRunning()) &#123; break; &#125; state = AcceptorState.RUNNING; try &#123; //if we have reached max connections, wait endpoint.countUpOrAwaitConnection(); // Endpoint might have been paused while waiting for latch // If that is the case, don't accept new connections if (endpoint.isPaused()) &#123; continue; &#125; U socket = null; try &#123; // Accept the next incoming connection from the server // socket socket = endpoint.serverSocketAccept(); &#125; catch (Exception ioe) &#123; // We didn't get a socket endpoint.countDownConnection(); if (endpoint.isRunning()) &#123; // Introduce delay if necessary errorDelay = handleExceptionWithDelay(errorDelay); // re-throw throw ioe; &#125; else &#123; break; &#125; &#125; // Successful accept, reset the error delay errorDelay = 0; // Configure the socket if (endpoint.isRunning() &amp;&amp; !endpoint.isPaused()) &#123; // setSocketOptions() will hand the socket off to // an appropriate processor if successful if (!endpoint.setSocketOptions(socket)) &#123; endpoint.closeSocket(socket); &#125; &#125; else &#123; endpoint.destroySocket(socket); &#125; &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); String msg = sm.getString("endpoint.accept.fail"); // APR specific. // Could push this down but not sure it is worth the trouble. if (t instanceof Error) &#123; Error e = (Error) t; if (e.getError() == 233) &#123; // Not an error on HP-UX so log as a warning // so it can be filtered out on that platform // See bug 50273 log.warn(msg, t); &#125; else &#123; log.error(msg, t); &#125; &#125; else &#123; log.error(msg, t); &#125; &#125; &#125; state = AcceptorState.ENDED;&#125; acceptor会一直监听端口，等待连接 setSocketOptions12345678910111213141516171819202122232425262728293031323334353637@Overrideprotected boolean setSocketOptions(SocketChannel socket) &#123; // Process the connection try &#123; //disable blocking, APR style, we are gonna be polling it socket.configureBlocking(false); Socket sock = socket.socket(); socketProperties.setProperties(sock); NioChannel channel = nioChannels.pop(); if (channel == null) &#123; SocketBufferHandler bufhandler = new SocketBufferHandler( socketProperties.getAppReadBufSize(), socketProperties.getAppWriteBufSize(), socketProperties.getDirectBuffer()); if (isSSLEnabled()) &#123; channel = new SecureNioChannel(socket, bufhandler, selectorPool, this); &#125; else &#123; channel = new NioChannel(socket, bufhandler); &#125; &#125; else &#123; channel.setIOChannel(socket); channel.reset(); &#125; getPoller0().register(channel); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); try &#123; log.error(sm.getString("endpoint.socketOptionsError"), t); &#125; catch (Throwable tt) &#123; ExceptionUtils.handleThrowable(tt); &#125; // Tell to close the socket return false; &#125; return true;&#125; NioChannel：将捕获到的socket封装成NioChannel register123456789101112131415public void register(final NioChannel socket) &#123; socket.setPoller(this); NioSocketWrapper ka = new NioSocketWrapper(socket, NioEndpoint.this); socket.setSocketWrapper(ka); ka.setPoller(this); ka.setReadTimeout(getConnectionTimeout()); ka.setWriteTimeout(getConnectionTimeout()); ka.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests()); ka.setSecure(isSSLEnabled()); PollerEvent r = eventCache.pop(); ka.interestOps(SelectionKey.OP_READ);//this is what OP_REGISTER turns into. if ( r==null) r = new PollerEvent(socket,ka,OP_REGISTER); else r.reset(socket,ka,OP_REGISTER); addEvent(r);&#125; 将channel封装成一个PollerEvent投递到SynchronizedQueue队列中，等待poller进行消费 Poller::run123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Overridepublic void run() &#123; // Loop until destroy() is called while (true) &#123; boolean hasEvents = false; try &#123; if (!close) &#123; hasEvents = events(); if (wakeupCounter.getAndSet(-1) &gt; 0) &#123; //if we are here, means we have other stuff to do //do a non blocking select keyCount = selector.selectNow(); &#125; else &#123; keyCount = selector.select(selectorTimeout); &#125; wakeupCounter.set(0); &#125; if (close) &#123; events(); timeout(0, false); try &#123; selector.close(); &#125; catch (IOException ioe) &#123; log.error(sm.getString("endpoint.nio.selectorCloseFail"), ioe); &#125; break; &#125; &#125; catch (Throwable x) &#123; ExceptionUtils.handleThrowable(x); log.error(sm.getString("endpoint.nio.selectorLoopError"), x); continue; &#125; //either we timed out or we woke up, process events first if ( keyCount == 0 ) hasEvents = (hasEvents | events()); Iterator&lt;SelectionKey&gt; iterator = keyCount &gt; 0 ? selector.selectedKeys().iterator() : null; // Walk through the collection of ready keys and dispatch // any active event. while (iterator != null &amp;&amp; iterator.hasNext()) &#123; SelectionKey sk = iterator.next(); NioSocketWrapper attachment = (NioSocketWrapper)sk.attachment(); // Attachment may be null if another thread has called // cancelledKey() if (attachment == null) &#123; iterator.remove(); &#125; else &#123; iterator.remove(); processKey(sk, attachment); &#125; &#125;//while //process timeouts timeout(keyCount,hasEvents); &#125;//while getStopLatch().countDown();&#125; events：处理队列中的Poller Event，直接调用PollerEvent::run。如果返回true 则说明事件已经被处理，返回false说明队列是空的 processKey：请求处理的逻辑，将socket交给processSocket处理。 SocketProcessor：继承自SocketProcessorBase，调用run方法开始请求的处理逻辑。 图片来源：https://blog.csdn.net/TVwR8OfV0P/article/details/78851949 SocketProcessorBase的run方法是不是非常眼熟？在【从入门到放弃-MySQL】数据库连接过程分析-客户端中，我们断点调试一次查询请求的处理过程，调用栈入口就是这个方法。 SocketProcessor::run1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071@Overrideprotected void doRun() &#123; NioChannel socket = socketWrapper.getSocket(); SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector()); try &#123; int handshake = -1; try &#123; if (key != null) &#123; if (socket.isHandshakeComplete()) &#123; // No TLS handshaking required. Let the handler // process this socket / event combination. handshake = 0; &#125; else if (event == SocketEvent.STOP || event == SocketEvent.DISCONNECT || event == SocketEvent.ERROR) &#123; // Unable to complete the TLS handshake. Treat it as // if the handshake failed. handshake = -1; &#125; else &#123; handshake = socket.handshake(key.isReadable(), key.isWritable()); // The handshake process reads/writes from/to the // socket. status may therefore be OPEN_WRITE once // the handshake completes. However, the handshake // happens when the socket is opened so the status // must always be OPEN_READ after it completes. It // is OK to always set this as it is only used if // the handshake completes. event = SocketEvent.OPEN_READ; &#125; &#125; &#125; catch (IOException x) &#123; handshake = -1; if (log.isDebugEnabled()) log.debug("Error during SSL handshake",x); &#125; catch (CancelledKeyException ckx) &#123; handshake = -1; &#125; if (handshake == 0) &#123; SocketState state = SocketState.OPEN; // Process the request from this socket if (event == null) &#123; state = getHandler().process(socketWrapper, SocketEvent.OPEN_READ); &#125; else &#123; state = getHandler().process(socketWrapper, event); &#125; if (state == SocketState.CLOSED) &#123; close(socket, key); &#125; &#125; else if (handshake == -1 ) &#123; close(socket, key); &#125; else if (handshake == SelectionKey.OP_READ)&#123; socketWrapper.registerReadInterest(); &#125; else if (handshake == SelectionKey.OP_WRITE)&#123; socketWrapper.registerWriteInterest(); &#125; &#125; catch (CancelledKeyException cx) &#123; socket.getPoller().cancelledKey(key); &#125; catch (VirtualMachineError vme) &#123; ExceptionUtils.handleThrowable(vme); &#125; catch (Throwable t) &#123; log.error(sm.getString("endpoint.processing.fail"), t); socket.getPoller().cancelledKey(key); &#125; finally &#123; socketWrapper = null; event = null; //return to cache if (running &amp;&amp; !paused) &#123; processorCache.push(this); &#125; &#125;&#125; 判断socket是否握手完毕并根据socket的状态处理请求或关闭链接 ConnectionHandler::process：调用AbstractProcessorLight::process，判断socket的状态及协议是否需要upgrade（如HTTP 2，websocket等基于HTTP的协议），选择对应的Processor处理请求。 Http11Processor::service123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232public SocketState service(SocketWrapperBase&lt;?&gt; socketWrapper) throws IOException &#123; RequestInfo rp = request.getRequestProcessor(); rp.setStage(org.apache.coyote.Constants.STAGE_PARSE); // Setting up the I/O setSocketWrapper(socketWrapper); inputBuffer.init(socketWrapper); outputBuffer.init(socketWrapper); // Flags keepAlive = true; openSocket = false; readComplete = true; boolean keptAlive = false; SendfileState sendfileState = SendfileState.DONE; while (!getErrorState().isError() &amp;&amp; keepAlive &amp;&amp; !isAsync() &amp;&amp; upgradeToken == null &amp;&amp; sendfileState == SendfileState.DONE &amp;&amp; !protocol.isPaused()) &#123; // Parsing the request header try &#123; if (!inputBuffer.parseRequestLine(keptAlive, protocol.getConnectionTimeout(), protocol.getKeepAliveTimeout())) &#123; if (inputBuffer.getParsingRequestLinePhase() == -1) &#123; return SocketState.UPGRADING; &#125; else if (handleIncompleteRequestLineRead()) &#123; break; &#125; &#125; if (protocol.isPaused()) &#123; // 503 - Service unavailable response.setStatus(503); setErrorState(ErrorState.CLOSE_CLEAN, null); &#125; else &#123; keptAlive = true; // Set this every time in case limit has been changed via JMX request.getMimeHeaders().setLimit(protocol.getMaxHeaderCount()); if (!inputBuffer.parseHeaders()) &#123; // We've read part of the request, don't recycle it // instead associate it with the socket openSocket = true; readComplete = false; break; &#125; if (!protocol.getDisableUploadTimeout()) &#123; socketWrapper.setReadTimeout(protocol.getConnectionUploadTimeout()); &#125; &#125; &#125; catch (IOException e) &#123; if (log.isDebugEnabled()) &#123; log.debug(sm.getString("http11processor.header.parse"), e); &#125; setErrorState(ErrorState.CLOSE_CONNECTION_NOW, e); break; &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); UserDataHelper.Mode logMode = userDataHelper.getNextMode(); if (logMode != null) &#123; String message = sm.getString("http11processor.header.parse"); switch (logMode) &#123; case INFO_THEN_DEBUG: message += sm.getString("http11processor.fallToDebug"); //$FALL-THROUGH$ case INFO: log.info(message, t); break; case DEBUG: log.debug(message, t); &#125; &#125; // 400 - Bad Request response.setStatus(400); setErrorState(ErrorState.CLOSE_CLEAN, t); &#125; // Has an upgrade been requested? Enumeration&lt;String&gt; connectionValues = request.getMimeHeaders().values("Connection"); boolean foundUpgrade = false; while (connectionValues.hasMoreElements() &amp;&amp; !foundUpgrade) &#123; foundUpgrade = connectionValues.nextElement().toLowerCase( Locale.ENGLISH).contains("upgrade"); &#125; if (foundUpgrade) &#123; // Check the protocol String requestedProtocol = request.getHeader("Upgrade"); UpgradeProtocol upgradeProtocol = protocol.getUpgradeProtocol(requestedProtocol); if (upgradeProtocol != null) &#123; if (upgradeProtocol.accept(request)) &#123; response.setStatus(HttpServletResponse.SC_SWITCHING_PROTOCOLS); response.setHeader("Connection", "Upgrade"); response.setHeader("Upgrade", requestedProtocol); action(ActionCode.CLOSE, null); getAdapter().log(request, response, 0); InternalHttpUpgradeHandler upgradeHandler = upgradeProtocol.getInternalUpgradeHandler( socketWrapper, getAdapter(), cloneRequest(request)); UpgradeToken upgradeToken = new UpgradeToken(upgradeHandler, null, null); action(ActionCode.UPGRADE, upgradeToken); return SocketState.UPGRADING; &#125; &#125; &#125; if (getErrorState().isIoAllowed()) &#123; // Setting up filters, and parse some request headers rp.setStage(org.apache.coyote.Constants.STAGE_PREPARE); try &#123; prepareRequest(); &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); if (log.isDebugEnabled()) &#123; log.debug(sm.getString("http11processor.request.prepare"), t); &#125; // 500 - Internal Server Error response.setStatus(500); setErrorState(ErrorState.CLOSE_CLEAN, t); &#125; &#125; int maxKeepAliveRequests = protocol.getMaxKeepAliveRequests(); if (maxKeepAliveRequests == 1) &#123; keepAlive = false; &#125; else if (maxKeepAliveRequests &gt; 0 &amp;&amp; socketWrapper.decrementKeepAlive() &lt;= 0) &#123; keepAlive = false; &#125; // Process the request in the adapter if (getErrorState().isIoAllowed()) &#123; try &#123; rp.setStage(org.apache.coyote.Constants.STAGE_SERVICE); getAdapter().service(request, response); // Handle when the response was committed before a serious // error occurred. Throwing a ServletException should both // set the status to 500 and set the errorException. // If we fail here, then the response is likely already // committed, so we can't try and set headers. if(keepAlive &amp;&amp; !getErrorState().isError() &amp;&amp; !isAsync() &amp;&amp; statusDropsConnection(response.getStatus())) &#123; setErrorState(ErrorState.CLOSE_CLEAN, null); &#125; &#125; catch (InterruptedIOException e) &#123; setErrorState(ErrorState.CLOSE_CONNECTION_NOW, e); &#125; catch (HeadersTooLargeException e) &#123; log.error(sm.getString("http11processor.request.process"), e); // The response should not have been committed but check it // anyway to be safe if (response.isCommitted()) &#123; setErrorState(ErrorState.CLOSE_NOW, e); &#125; else &#123; response.reset(); response.setStatus(500); setErrorState(ErrorState.CLOSE_CLEAN, e); response.setHeader("Connection", "close"); // TODO: Remove &#125; &#125; catch (Throwable t) &#123; ExceptionUtils.handleThrowable(t); log.error(sm.getString("http11processor.request.process"), t); // 500 - Internal Server Error response.setStatus(500); setErrorState(ErrorState.CLOSE_CLEAN, t); getAdapter().log(request, response, 0); &#125; &#125; // Finish the handling of the request rp.setStage(org.apache.coyote.Constants.STAGE_ENDINPUT); if (!isAsync()) &#123; // If this is an async request then the request ends when it has // been completed. The AsyncContext is responsible for calling // endRequest() in that case. endRequest(); &#125; rp.setStage(org.apache.coyote.Constants.STAGE_ENDOUTPUT); // If there was an error, make sure the request is counted as // and error, and update the statistics counter if (getErrorState().isError()) &#123; response.setStatus(500); &#125; if (!isAsync() || getErrorState().isError()) &#123; request.updateCounters(); if (getErrorState().isIoAllowed()) &#123; inputBuffer.nextRequest(); outputBuffer.nextRequest(); &#125; &#125; if (!protocol.getDisableUploadTimeout()) &#123; int connectionTimeout = protocol.getConnectionTimeout(); if(connectionTimeout &gt; 0) &#123; socketWrapper.setReadTimeout(connectionTimeout); &#125; else &#123; socketWrapper.setReadTimeout(0); &#125; &#125; rp.setStage(org.apache.coyote.Constants.STAGE_KEEPALIVE); sendfileState = processSendfile(socketWrapper); &#125; rp.setStage(org.apache.coyote.Constants.STAGE_ENDED); if (getErrorState().isError() || protocol.isPaused()) &#123; return SocketState.CLOSED; &#125; else if (isAsync()) &#123; return SocketState.LONG; &#125; else if (isUpgrade()) &#123; return SocketState.UPGRADING; &#125; else &#123; if (sendfileState == SendfileState.PENDING) &#123; return SocketState.SENDFILE; &#125; else &#123; if (openSocket) &#123; if (readComplete) &#123; return SocketState.OPEN; &#125; else &#123; return SocketState.LONG; &#125; &#125; else &#123; return SocketState.CLOSED; &#125; &#125; &#125;&#125; 初始化各项配置及初始值 解析request的header信息，判断是否是upgrade协议，是的话设置http header信息 prepareRequest：校验协议、校验header（如user-agent、Connection、host等）设置filters getAdapter().service：getAdapter获取的是在Connector::initInternal中设置的CoyoteAdapter CoyoteAdapter::service123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128public void service(org.apache.coyote.Request req, org.apache.coyote.Response res) throws Exception &#123; Request request = (Request) req.getNote(ADAPTER_NOTES); Response response = (Response) res.getNote(ADAPTER_NOTES); if (request == null) &#123; // Create objects request = connector.createRequest(); request.setCoyoteRequest(req); response = connector.createResponse(); response.setCoyoteResponse(res); // Link objects request.setResponse(response); response.setRequest(request); // Set as notes req.setNote(ADAPTER_NOTES, request); res.setNote(ADAPTER_NOTES, response); // Set query string encoding req.getParameters().setQueryStringCharset(connector.getURICharset()); &#125; if (connector.getXpoweredBy()) &#123; response.addHeader("X-Powered-By", POWERED_BY); &#125; boolean async = false; boolean postParseSuccess = false; req.getRequestProcessor().setWorkerThreadName(THREAD_NAME.get()); try &#123; // Parse and set Catalina and configuration specific // request parameters postParseSuccess = postParseRequest(req, request, res, response); if (postParseSuccess) &#123; //check valves if we support async request.setAsyncSupported( connector.getService().getContainer().getPipeline().isAsyncSupported()); // Calling the container connector.getService().getContainer().getPipeline().getFirst().invoke( request, response); &#125; if (request.isAsync()) &#123; async = true; ReadListener readListener = req.getReadListener(); if (readListener != null &amp;&amp; request.isFinished()) &#123; // Possible the all data may have been read during service() // method so this needs to be checked here ClassLoader oldCL = null; try &#123; oldCL = request.getContext().bind(false, null); if (req.sendAllDataReadEvent()) &#123; req.getReadListener().onAllDataRead(); &#125; &#125; finally &#123; request.getContext().unbind(false, oldCL); &#125; &#125; Throwable throwable = (Throwable) request.getAttribute(RequestDispatcher.ERROR_EXCEPTION); // If an async request was started, is not going to end once // this container thread finishes and an error occurred, trigger // the async error process if (!request.isAsyncCompleting() &amp;&amp; throwable != null) &#123; request.getAsyncContextInternal().setErrorState(throwable, true); &#125; &#125; else &#123; request.finishRequest(); response.finishResponse(); &#125; &#125; catch (IOException e) &#123; // Ignore &#125; finally &#123; AtomicBoolean error = new AtomicBoolean(false); res.action(ActionCode.IS_ERROR, error); if (request.isAsyncCompleting() &amp;&amp; error.get()) &#123; // Connection will be forcibly closed which will prevent // completion happening at the usual point. Need to trigger // call to onComplete() here. res.action(ActionCode.ASYNC_POST_PROCESS, null); async = false; &#125; // Access log if (!async &amp;&amp; postParseSuccess) &#123; // Log only if processing was invoked. // If postParseRequest() failed, it has already logged it. Context context = request.getContext(); Host host = request.getHost(); // If the context is null, it is likely that the endpoint was // shutdown, this connection closed and the request recycled in // a different thread. That thread will have updated the access // log so it is OK not to update the access log here in that // case. // The other possibility is that an error occurred early in // processing and the request could not be mapped to a Context. // Log via the host or engine in that case. long time = System.currentTimeMillis() - req.getStartTime(); if (context != null) &#123; context.logAccess(request, response, time, false); &#125; else if (response.isError()) &#123; if (host != null) &#123; host.logAccess(request, response, time, false); &#125; else &#123; connector.getService().getContainer().logAccess( request, response, time, false); &#125; &#125; &#125; req.getRequestProcessor().setWorkerThreadName(null); // Recycle the wrapper request and response if (!async) &#123; updateWrapperErrorCount(request, response); request.recycle(); response.recycle(); &#125; &#125;&#125; 初始化request和response，如果没有则新new postParseRequest：保证在header解析后的request能被Container正常解析、使用。比如权限认证、字符编码、版本、session等的转换和校验 invoke：逐级调用StandardEngineValve、StandardHostValve、StandardHostValve、StandardWrapperValve的invoke实现 doFilter：StandardWrapperValve调用doFilter，会执行定义的Filter过滤器，执行完毕后执行HttpServlet::service HttpServlet::service12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String method = req.getMethod(); if (method.equals(METHOD_GET)) &#123; long lastModified = getLastModified(req); if (lastModified == -1) &#123; // servlet doesn't support if-modified-since, no reason // to go through further expensive logic doGet(req, resp); &#125; else &#123; long ifModifiedSince; try &#123; ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); &#125; catch (IllegalArgumentException iae) &#123; // Invalid date header - proceed as if none was set ifModifiedSince = -1; &#125; if (ifModifiedSince &lt; (lastModified / 1000 * 1000)) &#123; // If the servlet mod time is later, call doGet() // Round down to the nearest second for a proper compare // A ifModifiedSince of -1 will always be less maybeSetLastModified(resp, lastModified); doGet(req, resp); &#125; else &#123; resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); &#125; &#125; &#125; else if (method.equals(METHOD_HEAD)) &#123; long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); &#125; else if (method.equals(METHOD_POST)) &#123; doPost(req, resp); &#125; else if (method.equals(METHOD_PUT)) &#123; doPut(req, resp); &#125; else if (method.equals(METHOD_DELETE)) &#123; doDelete(req, resp); &#125; else if (method.equals(METHOD_OPTIONS)) &#123; doOptions(req,resp); &#125; else if (method.equals(METHOD_TRACE)) &#123; doTrace(req,resp); &#125; else &#123; // // Note that this means NO servlet supports whatever // method was requested, anywhere on this server. // String errMsg = lStrings.getString("http.method_not_implemented"); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); &#125;&#125; 根据请求的method做对应的处理逻辑，其实doXXX底层都是调用的SpringMVC的FrameworkServlet::processRequest FrameworkServlet::processRequest对request做简单处理后，调用了doService，实现类为DispatcherServlet DispatcherServlet::doService123456789101112131415161718192021222324252627282930313233343536373839404142434445@Overrideprotected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; logRequest(request); // Keep a snapshot of the request attributes in case of an include, // to be able to restore the original attributes after the include. Map&lt;String, Object&gt; attributesSnapshot = null; if (WebUtils.isIncludeRequest(request)) &#123; attributesSnapshot = new HashMap&lt;&gt;(); Enumeration&lt;?&gt; attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) &#123; String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith(DEFAULT_STRATEGIES_PREFIX)) &#123; attributesSnapshot.put(attrName, request.getAttribute(attrName)); &#125; &#125; &#125; // Make framework objects available to handlers and view objects. request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); if (this.flashMapManager != null) &#123; FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); &#125; request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); &#125; try &#123; doDispatch(request, response); &#125; finally &#123; if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) &#123; restoreAttributesAfterInclude(request, attributesSnapshot); &#125; &#125; &#125;&#125; 主要调用方法为doDispatch DispatcherServlet::doDispatch123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // Determine handler adapter for the current request. HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. String method = request.getMethod(); boolean isGet = "GET".equals(method); if (isGet || "HEAD".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // Actually invoke the handler. mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we're processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException("Handler dispatch failed", err); &#125; processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException("Handler processing failed", err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125;&#125; getHandler：根据requestURI通过HandlerMapping(这里是requestMappingHandlerMapping)获取到处理此请求的handler以及拦截器（requestMapping对应的类和方法） getHandlerAdapter：获取能执行这个Handler的Adapter applyPreHandle：处理拦截器的前置拦截。 ha.handle：通过获取到的Adapter（这里是RequestMappingHandlerAdapter）执行Controller方法，得到ModelAndView processDispatchResult：直接调用render方法，将返回的ModelAndView交给ViewResolver视图解析器找到指定的视图（view），赋值给response返回给客户端显示。 RequestMappingHandlerAdapter::handleInternal123456789101112131415161718192021222324252627282930313233343536protected ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; ModelAndView mav; checkRequest(request); // Execute invokeHandlerMethod in synchronized block if required. if (this.synchronizeOnSession) &#123; HttpSession session = request.getSession(false); if (session != null) &#123; Object mutex = WebUtils.getSessionMutex(session); synchronized (mutex) &#123; mav = invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; // No HttpSession available -&gt; no mutex necessary mav = invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; // No synchronization on session demanded at all... mav = invokeHandlerMethod(request, response, handlerMethod); &#125; if (!response.containsHeader(HEADER_CACHE_CONTROL)) &#123; if (getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) &#123; applyCacheSeconds(response, this.cacheSecondsForSessionAttributeHandlers); &#125; else &#123; prepareResponse(response); &#125; &#125; return mav;&#125; invokeHandlerMethod：执行Handler方法获取到ModelAndView，调用ServletInvocableHandlerMethod::invokeAndHandle ServletInvocableHandlerMethod::invokeAndHandle123456789101112131415161718192021222324252627282930public void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); setResponseStatus(webRequest); if (returnValue == null) &#123; if (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) &#123; mavContainer.setRequestHandled(true); return; &#125; &#125; else if (StringUtils.hasText(getResponseStatusReason())) &#123; mavContainer.setRequestHandled(true); return; &#125; mavContainer.setRequestHandled(false); Assert.state(this.returnValueHandlers != null, "No return value handlers"); try &#123; this.returnValueHandlers.handleReturnValue( returnValue, getReturnValueType(returnValue), mavContainer, webRequest); &#125; catch (Exception ex) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(formatErrorForReturnValue(returnValue), ex); &#125; throw ex; &#125;&#125; invokeForRequest: 调用InvocableHandlerMethod::doInvoke 通过反射的方式执行requestMapping对应的Controller方法 this.returnValueHandlers.handleReturnValue：将执行完的returnValue设置到response中，我们常用的json返回值就是在这里设置的。 总结通过对源码的分析我们了解了请求在Tomcat中的流转情况，以及SpringMVC如何完成一个请求的处理。一个请求在SpringMVC中的生命周期如下图所示： 1、用户发送请求，浏览器acceptor监听到请求，投递至PollerEvent队列，Poller进行消费，交给SocketProcessor（DispatcherServlet）处理。 2、分发器DispatcherServlet向映射器HandlerMapping发请求，根据requestURL获取Handler 3、映射器返回HandlerExecutionChain，包含了需要处理的Handler及HandlerInterceptor拦截器 4、根据Handler获取对应的适配器 5、适配器执行具体的Handler（即Controller的方法） 6、Handler执行完返回ModelAndModel 7、HandlerAdapter将ModelAndModel返回给分发器DispatcherServlet 8、DispatcherServlet将ModelAndView传给ViewReslover视图解析器 9、ViewReslover解析后返回具体的View模板 10、渲染视图，将数据填充至视图中 11、将渲染好的视图返回给用户，在浏览器客户端展现 参考：https://www.cnblogs.com/xiaoxi/p/6164383.html]]></content>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>Spring</tag>
        <tag>Tomcat</tag>
        <tag>SpringMvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-SpringBoot】SpringBoot源码分析-WebServer]]></title>
    <url>%2F9707c128.html</url>
    <content type="text"><![CDATA[前言前文【从入门到放弃-SpringBoot】SpringBoot源码分析-启动中，我们分析了springboot的启动过程，在refreshContext中调用了onRefresh。在SERVLET类型应用中，实际实例化的应用上下文为ServletWebServerApplicationContext。其onRefresh中调用了createWebServer。我们在本文中一起分析下是一个web应用是如何启动的。 ServletWebServerApplicationContext::createWebServer123456789101112131415161718private void createWebServer() &#123; WebServer webServer = this.webServer; ServletContext servletContext = getServletContext(); if (webServer == null &amp;&amp; servletContext == null) &#123; ServletWebServerFactory factory = getWebServerFactory(); this.webServer = factory.getWebServer(getSelfInitializer()); &#125; else if (servletContext != null) &#123; try &#123; getSelfInitializer().onStartup(servletContext); &#125; catch (ServletException ex) &#123; throw new ApplicationContextException("Cannot initialize servlet context", ex); &#125; &#125; initPropertySources(); &#125; getWebServerFactory1234567891011121314151617protected ServletWebServerFactory getWebServerFactory() &#123; // Use bean names so that we don't consider the hierarchy String[] beanNames = getBeanFactory() .getBeanNamesForType(ServletWebServerFactory.class); if (beanNames.length == 0) &#123; throw new ApplicationContextException( "Unable to start ServletWebServerApplicationContext due to missing " + "ServletWebServerFactory bean."); &#125; if (beanNames.length &gt; 1) &#123; throw new ApplicationContextException( "Unable to start ServletWebServerApplicationContext due to multiple " + "ServletWebServerFactory beans : " + StringUtils.arrayToCommaDelimitedString(beanNames)); &#125; return getBeanFactory().getBean(beanNames[0], ServletWebServerFactory.class);&#125; 根据ServletWebServerFactory获取此类型的bean，默认获取的是TomcatServletWebServerFactory，是在ServletWebServerFactoryConfiguration中根据条件加载的。可以通过排除引入Tomcat包等方式切换使用Jetty或Undertow ServletWebServerApplicationContext::selfInitialize123456789private void selfInitialize(ServletContext servletContext) throws ServletException &#123; prepareWebApplicationContext(servletContext); registerApplicationScope(servletContext); WebApplicationContextUtils.registerEnvironmentBeans(getBeanFactory(), servletContext); for (ServletContextInitializer beans : getServletContextInitializerBeans()) &#123; beans.onStartup(servletContext); &#125;&#125; 配置servlet启动相关的filter、listener、属性、配置等各项bean。在server启动的时候一起启动 TomcatServletWebServerFactory::getWebServer1234567891011121314151617public WebServer getWebServer(ServletContextInitializer... initializers) &#123; Tomcat tomcat = new Tomcat(); File baseDir = (this.baseDirectory != null) ? this.baseDirectory : createTempDir("tomcat"); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); return getTomcatWebServer(tomcat);&#125; 实际上就是启动了一个Tomcat作为webserver，为了便于理解启动过程，可以先简单了解下Tomcat的架构设计，如下图 Servertomcat的顶级结构，Tomcat的所有动作都是运行在server中，一个JVM进程中只能启动一个server实例，负责管理整个Service的生命周期。 Service一个server可以创建多个service，但通常只创建一个。由service对外提供服务一个service由一个Container和多个Connector构成。通过Connector接收请求交给Container处理 Connector用于接收请求并封装成request和response的模块。底层用socket进行连接，可以在初始化时，自定义选择使用的协议如http、ajp等 Container是基础容器接口类，它的子类有Engine、Host、Context和Wrapper，从左到右依次是一对多的父子关系。 Engine是一个顶级容器，可以包含一个或多个Host，接收到Connector转发的请求后，根据请求头信息找到需要处理的Host，交给它处理 Host虚拟主机，接收对应host的请求发给context进行处理 Contentweb应用上下文，根据请求找到对应的servlet类 Warpper管理servlet实例，负责其装载、初始化、执行、回收等。一个warpper对应一个servlet实例 prepareContext12345678910111213141516171819202122232425262728293031323334353637protected void prepareContext(Host host, ServletContextInitializer[] initializers) &#123; File documentRoot = getValidDocumentRoot(); TomcatEmbeddedContext context = new TomcatEmbeddedContext(); if (documentRoot != null) &#123; context.setResources(new LoaderHidingResourceRoot(context)); &#125; context.setName(getContextPath()); context.setDisplayName(getDisplayName()); context.setPath(getContextPath()); File docBase = (documentRoot != null) ? documentRoot : createTempDir("tomcat-docbase"); context.setDocBase(docBase.getAbsolutePath()); context.addLifecycleListener(new FixContextListener()); context.setParentClassLoader( (this.resourceLoader != null) ? this.resourceLoader.getClassLoader() : ClassUtils.getDefaultClassLoader()); resetDefaultLocaleMapping(context); addLocaleMappings(context); context.setUseRelativeRedirects(false); configureTldSkipPatterns(context); WebappLoader loader = new WebappLoader(context.getParentClassLoader()); loader.setLoaderClass(TomcatEmbeddedWebappClassLoader.class.getName()); loader.setDelegate(true); context.setLoader(loader); if (isRegisterDefaultServlet()) &#123; addDefaultServlet(context); &#125; if (shouldRegisterJspServlet()) &#123; addJspServlet(context); addJasperInitializer(context); &#125; context.addLifecycleListener(new StaticResourceConfigurer(context)); ServletContextInitializer[] initializersToUse = mergeInitializers(initializers); host.addChild(context); configureContext(context, initializersToUse); postProcessContext(context);&#125; 初始化配置host 设置父加载器 设置默认的servlet 设置jsp的servlet（默认是空） 将Content添加至Host configureContext：配置Content的默认错误页面、MimeMap、session等内容 TomcatWebServer::initialize12345678910111213141516171819202122232425262728293031323334353637383940private void initialize() throws WebServerException &#123; logger.info("Tomcat initialized with port(s): " + getPortsDescription(false)); synchronized (this.monitor) &#123; try &#123; addInstanceIdToEngineName(); Context context = findContext(); context.addLifecycleListener((event) -&gt; &#123; if (context.equals(event.getSource()) &amp;&amp; Lifecycle.START_EVENT.equals(event.getType())) &#123; // Remove service connectors so that protocol binding doesn't // happen when the service is started. removeServiceConnectors(); &#125; &#125;); // Start the server to trigger initialization listeners this.tomcat.start(); // We can re-throw failure exception directly in the main thread rethrowDeferredStartupExceptions(); try &#123; ContextBindings.bindClassLoader(context, context.getNamingToken(), getClass().getClassLoader()); &#125; catch (NamingException ex) &#123; // Naming is not enabled. Continue &#125; // Unlike Jetty, all Tomcat threads are daemon threads. We create a // blocking non-daemon to stop immediate shutdown startDaemonAwaitThread(); &#125; catch (Exception ex) &#123; stopSilently(); throw new WebServerException("Unable to start embedded Tomcat", ex); &#125; &#125;&#125; 获取service绑定的Connector,保存后删除，这是删除的原因是：在下面start后，Connector就能接收请求了，但还service还未启动，因此先删除Connector达到延后启动的效果 启动Server/Service/Engine/Host/Context/Wrapper各级容器 之前配置的各项filter、listener等也都在此时启动 TomcatWebServer::startDaemonAwaitThread12345678910111213private void startDaemonAwaitThread() &#123; Thread awaitThread = new Thread("container-" + (containerCounter.get())) &#123; @Override public void run() &#123; TomcatWebServer.this.tomcat.getServer().await(); &#125; &#125;; awaitThread.setContextClassLoader(getClass().getClassLoader()); awaitThread.setDaemon(false); awaitThread.start();&#125; jvm虚拟机在所有的线程都是守护线程时，就会退出。因此需要创建一个用户线程（非守护线程），一直处于监听状态，当接收到关闭信号时，用户线程退出。仅剩下全部守护线程，整个jvm关闭。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127public void await() &#123; // Negative values - don't wait on port - tomcat is embedded or we just don't like ports if (getPortWithOffset() == -2) &#123; // undocumented yet - for embedding apps that are around, alive. return; &#125; if (getPortWithOffset() == -1) &#123; try &#123; awaitThread = Thread.currentThread(); while(!stopAwait) &#123; try &#123; Thread.sleep( 10000 ); &#125; catch( InterruptedException ex ) &#123; // continue and check the flag &#125; &#125; &#125; finally &#123; awaitThread = null; &#125; return; &#125; // Set up a server socket to wait on try &#123; awaitSocket = new ServerSocket(getPortWithOffset(), 1, InetAddress.getByName(address)); &#125; catch (IOException e) &#123; log.error(sm.getString("standardServer.awaitSocket.fail", address, String.valueOf(getPortWithOffset()), String.valueOf(getPort()), String.valueOf(getPortOffset())), e); return; &#125; try &#123; awaitThread = Thread.currentThread(); // Loop waiting for a connection and a valid command while (!stopAwait) &#123; ServerSocket serverSocket = awaitSocket; if (serverSocket == null) &#123; break; &#125; // Wait for the next connection Socket socket = null; StringBuilder command = new StringBuilder(); try &#123; InputStream stream; long acceptStartTime = System.currentTimeMillis(); try &#123; socket = serverSocket.accept(); socket.setSoTimeout(10 * 1000); // Ten seconds stream = socket.getInputStream(); &#125; catch (SocketTimeoutException ste) &#123; // This should never happen but bug 56684 suggests that // it does. log.warn(sm.getString("standardServer.accept.timeout", Long.valueOf(System.currentTimeMillis() - acceptStartTime)), ste); continue; &#125; catch (AccessControlException ace) &#123; log.warn(sm.getString("standardServer.accept.security"), ace); continue; &#125; catch (IOException e) &#123; if (stopAwait) &#123; // Wait was aborted with socket.close() break; &#125; log.error(sm.getString("standardServer.accept.error"), e); break; &#125; // Read a set of characters from the socket int expected = 1024; // Cut off to avoid DoS attack while (expected &lt; shutdown.length()) &#123; if (random == null) random = new Random(); expected += (random.nextInt() % 1024); &#125; while (expected &gt; 0) &#123; int ch = -1; try &#123; ch = stream.read(); &#125; catch (IOException e) &#123; log.warn(sm.getString("standardServer.accept.readError"), e); ch = -1; &#125; // Control character or EOF (-1) terminates loop if (ch &lt; 32 || ch == 127) &#123; break; &#125; command.append((char) ch); expected--; &#125; &#125; finally &#123; // Close the socket now that we are done with it try &#123; if (socket != null) &#123; socket.close(); &#125; &#125; catch (IOException e) &#123; // Ignore &#125; &#125; // Match against our command string boolean match = command.toString().equals(shutdown); if (match) &#123; log.info(sm.getString("standardServer.shutdownViaPort")); break; &#125; else log.warn(sm.getString("standardServer.invalidShutdownCommand", command.toString())); &#125; &#125; finally &#123; ServerSocket serverSocket = awaitSocket; awaitThread = null; awaitSocket = null; // Close the server socket and return if (serverSocket != null) &#123; try &#123; serverSocket.close(); &#125; catch (IOException e) &#123; // Ignore &#125; &#125; &#125;&#125; 用户线程创建一个socket，持续监听Tomcat状态，每十秒进行一次检测，如果接收到关闭信号则此线程关闭，整个Tomcat关闭。 TomcatWebServer::start12345678910111213141516171819202122232425262728293031public void start() throws WebServerException &#123; synchronized (this.monitor) &#123; if (this.started) &#123; return; &#125; try &#123; addPreviouslyRemovedConnectors(); Connector connector = this.tomcat.getConnector(); if (connector != null &amp;&amp; this.autoStart) &#123; performDeferredLoadOnStartup(); &#125; checkThatConnectorsHaveStarted(); this.started = true; logger.info("Tomcat started on port(s): " + getPortsDescription(true) + " with context path '" + getContextPath() + "'"); &#125; catch (ConnectorStartFailedException ex) &#123; stopSilently(); throw ex; &#125; catch (Exception ex) &#123; throw new WebServerException("Unable to start embedded Tomcat server", ex); &#125; finally &#123; Context context = findContext(); ContextBindings.unbindClassLoader(context, context.getNamingToken(), getClass().getClassLoader()); &#125; &#125;&#125; 还记得【从入门到放弃-SpringBoot】SpringBoot源码分析-启动中的finishRefresh吗？ServletWebServerApplicationContext重写了finishRefresh方法，在里面增加调用了startWebServer。 如上将之前删除并保存的connector添加回来并启动。 创建socket并绑定监听的端口（默认8080） 创建线程池开始接收并处理请求。 总结至此，springboot中webserver的启动过程我们已经大概清楚了，Tomcat还有很深的内容可以挖，下面可以学习下。]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>Spring</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-SpringBoot】SpringBoot源码分析-启动]]></title>
    <url>%2F97473183.html</url>
    <content type="text"><![CDATA[前言上一篇我们一起简单了解了【从入门到放弃-MySQL】数据库连接过程分析-客户端，写完之后通读一遍，感觉分析的不是很透彻。有很多地方都没搞通，因此决定从Springboot源码开始从头研究下。 main 入口分析12345678910111213141516171819package com.springboot.demo;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import org.springframework.scheduling.annotation.EnableScheduling;@MapperScan("com.springboot.demo.repository.dao")@SpringBootApplication@EnableSchedulingpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 一个简单的springboot项目启动文件中 一行代码就能搞定。我们从这一行代码开始看起。 SpringApplication::SpringApplication12345678910public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, "PrimarySources must not be null"); this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass();&#125; 主要是初始化成员变量，比如参数列表，应用类型、监听器等。 getSpringFactoriesInstances1234567891011private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) &#123; ClassLoader classLoader = getClassLoader(); // Use names and ensure unique to protect against duplicates Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;( SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances;&#125; 这个方法主要是根据type类型获取配置中默认的类列表，并进行初始化。 loadFactoryNames：从META-INF/spring.factories中获取type对应的配置类名称列表。 createSpringFactoriesInstances：校验获取到的类是否是parameterTypes类的子类，并将获取到的类通过反射机制实例化， SpringApplication::run123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Run the Spring application, creating and refreshing a new * &#123;@link ApplicationContext&#125;. * @param args the application arguments (usually passed from a Java main method) * @return a running &#123;@link ApplicationContext&#125; */public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances( SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; return context;&#125; StopWatch是一个计时器工具类，这里先记录了项目的启动时间 变量初始化各种变量初始化，用法在后面具体分析 configureHeadlessProperty设置系统java.awt.headless属性，为true的话是告知系统不要指望显示器、鼠标、键盘等可以正常运行，这是一个服务端程序，用到这些外设的时候需要靠自己模拟 getRunListeners获取SpringApplicationRunListeners各项监听器并实例化，这些监听器配置在spring.factories资源文件中。 prepareEnvironment配置环境，如配置文件、系统变量等并通过监听器广播环境变量准备完毕事件。 printBanner打印启动显示的banner。 createApplicationContext根据webApplicationType初始化spring上下文 exceptionReporters初始化配置的异常报告类 prepareContext123456789101112131415161718192021222324252627private void prepareContext(ConfigurableApplicationContext context, ConfigurableEnvironment environment, SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments, Banner printedBanner) &#123; context.setEnvironment(environment); postProcessApplicationContext(context); applyInitializers(context); listeners.contextPrepared(context); if (this.logStartupInfo) &#123; logStartupInfo(context.getParent() == null); logStartupProfileInfo(context); &#125; // Add boot specific singleton beans ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); beanFactory.registerSingleton("springApplicationArguments", applicationArguments); if (printedBanner != null) &#123; beanFactory.registerSingleton("springBootBanner", printedBanner); &#125; if (beanFactory instanceof DefaultListableBeanFactory) &#123; ((DefaultListableBeanFactory) beanFactory) .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; // Load the sources Set&lt;Object&gt; sources = getAllSources(); Assert.notEmpty(sources, "Sources must not be empty"); load(context, sources.toArray(new Object[0])); listeners.contextLoaded(context);&#125; setEnvironment：设置上下文环境 postProcessApplicationContext：上下文后置处理，默认没做什么事。 applyInitializers：调用之前实例化的几个ApplicationContextInitializer类的initialize方法 contextPrepared：向listeners发送上下文已准备完毕的通知。 load：BeanDefinitionLoader可以加载各种bean，比如注解、XML、package等多种类型的bean，在后面利用BeanDefinitionLoader将这些beans都加载进上下文中。 contextLoaded：向listeners发送上下文已加载完毕的通知。 refreshContext12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Overridepublic void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; prepareRefresh：一些准备工作，比如设置启动时间、初始化资源、必须属性校验等。 obtainFreshBeanFactory：通知子类刷新内置的beanFactory prepareBeanFactory：对容器的beanFactory做一些准备工作，比如设置classloader、设置&amp;取消设置一些类的bean invokeBeanFactoryPostProcessors： 主要看invokeBeanDefinitionRegistryPostProcessors方法，会调用ConfigurationClassPostProcessor::processConfigBeanDefinitions。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) &#123; List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;(); String[] candidateNames = registry.getBeanDefinitionNames(); for (String beanName : candidateNames) &#123; BeanDefinition beanDef = registry.getBeanDefinition(beanName); if (ConfigurationClassUtils.isFullConfigurationClass(beanDef) || ConfigurationClassUtils.isLiteConfigurationClass(beanDef)) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Bean definition has already been processed as a configuration class: " + beanDef); &#125; &#125; else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) &#123; configCandidates.add(new BeanDefinitionHolder(beanDef, beanName)); &#125; &#125; // Return immediately if no @Configuration classes were found if (configCandidates.isEmpty()) &#123; return; &#125; // Sort by previously determined @Order value, if applicable configCandidates.sort((bd1, bd2) -&gt; &#123; int i1 = ConfigurationClassUtils.getOrder(bd1.getBeanDefinition()); int i2 = ConfigurationClassUtils.getOrder(bd2.getBeanDefinition()); return Integer.compare(i1, i2); &#125;); // Detect any custom bean name generation strategy supplied through the enclosing application context SingletonBeanRegistry sbr = null; if (registry instanceof SingletonBeanRegistry) &#123; sbr = (SingletonBeanRegistry) registry; if (!this.localBeanNameGeneratorSet) &#123; BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(CONFIGURATION_BEAN_NAME_GENERATOR); if (generator != null) &#123; this.componentScanBeanNameGenerator = generator; this.importBeanNameGenerator = generator; &#125; &#125; &#125; if (this.environment == null) &#123; this.environment = new StandardEnvironment(); &#125; // Parse each @Configuration class ConfigurationClassParser parser = new ConfigurationClassParser( this.metadataReaderFactory, this.problemReporter, this.environment, this.resourceLoader, this.componentScanBeanNameGenerator, registry); Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;&gt;(configCandidates); Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;&gt;(configCandidates.size()); do &#123; parser.parse(candidates); parser.validate(); Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;&gt;(parser.getConfigurationClasses()); configClasses.removeAll(alreadyParsed); // Read the model and create bean definitions based on its content if (this.reader == null) &#123; this.reader = new ConfigurationClassBeanDefinitionReader( registry, this.sourceExtractor, this.resourceLoader, this.environment, this.importBeanNameGenerator, parser.getImportRegistry()); &#125; this.reader.loadBeanDefinitions(configClasses); alreadyParsed.addAll(configClasses); candidates.clear(); if (registry.getBeanDefinitionCount() &gt; candidateNames.length) &#123; String[] newCandidateNames = registry.getBeanDefinitionNames(); Set&lt;String&gt; oldCandidateNames = new HashSet&lt;&gt;(Arrays.asList(candidateNames)); Set&lt;String&gt; alreadyParsedClasses = new HashSet&lt;&gt;(); for (ConfigurationClass configurationClass : alreadyParsed) &#123; alreadyParsedClasses.add(configurationClass.getMetadata().getClassName()); &#125; for (String candidateName : newCandidateNames) &#123; if (!oldCandidateNames.contains(candidateName)) &#123; BeanDefinition bd = registry.getBeanDefinition(candidateName); if (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, this.metadataReaderFactory) &amp;&amp; !alreadyParsedClasses.contains(bd.getBeanClassName())) &#123; candidates.add(new BeanDefinitionHolder(bd, candidateName)); &#125; &#125; &#125; candidateNames = newCandidateNames; &#125; &#125; while (!candidates.isEmpty()); // Register the ImportRegistry as a bean in order to support ImportAware @Configuration classes if (sbr != null &amp;&amp; !sbr.containsSingleton(IMPORT_REGISTRY_BEAN_NAME)) &#123; sbr.registerSingleton(IMPORT_REGISTRY_BEAN_NAME, parser.getImportRegistry()); &#125; if (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) &#123; // Clear cache in externally provided MetadataReaderFactory; this is a no-op // for a shared cache since it'll be cleared by the ApplicationContext. ((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache(); &#125;&#125; ConfigurationClassParser：处理@Configuration/@Component等注解，扫描、注册包下的类 ConfigurationClassBeanDefinitionReader：处理@Import/@ImportResource/@Bean等注解。 将所有扫描到的bean都装载至registry invokeBeanDefinitionRegistryPostProcessors：执行invokeBeanDefinitionRegistryPostProcessors回调 invokeBeanFactoryPostProcessors：执行invokeBeanFactoryPostProcessors回调 registerBeanPostProcessors：注册拦截创建bean的bean处理器 initMessageSource：初始化消息源 initApplicationEventMulticaster：初始化事件广播 onRefresh：对一些特殊子类上下文中初始化一些特殊的bean，比如在ServletWebServerApplicationContext中就做了createWebServer的操作 registerListeners：注册bean监听器 finishBeanFactoryInitialization：实例化所有单例bean，比如我们之前分析的【从入门到放弃-MySQL】数据库连接过程分析-客户端dataSource就是在这一步实例化的。 finishRefresh结束上下文更新，并发布事件。 callRunners如果有ApplicationRunner或者CommandLineRunner类型的bean，则触发run函数，启动任务。 总结至此，springboot就已经启动完毕。概述下主要的启动过程就是 初始化环境 初始化默认配置 初始化各类监听器、事件 创建上下文 在上下文中添加默认的bean 扫描文件、注解等各种类型的bean添加在上下文中 实例化各个bean 启动完毕]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-MySQL】数据库连接过程分析-客户端]]></title>
    <url>%2F2dcf5558.html</url>
    <content type="text"><![CDATA[前言上文分析了【从入门到放弃-MySQL】数据库连接过程分析。本文我们一起来追一下客户端和服务端建联的过程。这里客户端使用JDBC8.0，在SpringBoot2.1.3下验证。 请求流程初始化SpringBoot2.1.3默认使用的HickriCP连接池 应用启动时，会先注册spring.datasource.driver-class-name配置的驱动，这里我们使用com.mysql.cj.jdbc.Driver 启动后，我们直接通过一个查询操作的http请求来验证一次查询操作中，客户端与服务端连接的过程 首次请求当使用到Dao请求时，开始建立连接调用堆栈如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101checkErrorMessage:752, NativeProtocol (com.mysql.cj.protocol.a)checkErrorMessage:741, NativeProtocol (com.mysql.cj.protocol.a)checkErrorMessage:709, NativeProtocol (com.mysql.cj.protocol.a)checkErrorMessage:132, NativeProtocol (com.mysql.cj.protocol.a)proceedHandshakeWithPluggableAuthentication:540, NativeAuthenticationProvider (com.mysql.cj.protocol.a)connect:202, NativeAuthenticationProvider (com.mysql.cj.protocol.a)connect:1449, NativeProtocol (com.mysql.cj.protocol.a)connect:165, NativeSession (com.mysql.cj)connectOneTryOnly:955, ConnectionImpl (com.mysql.cj.jdbc)createNewIO:825, ConnectionImpl (com.mysql.cj.jdbc)&lt;init&gt;:455, ConnectionImpl (com.mysql.cj.jdbc)getInstance:240, ConnectionImpl (com.mysql.cj.jdbc)connect:199, NonRegisteringDriver (com.mysql.cj.jdbc)getConnection:136, DriverDataSource (com.zaxxer.hikari.util)newConnection:369, PoolBase (com.zaxxer.hikari.pool)newPoolEntry:198, PoolBase (com.zaxxer.hikari.pool)createPoolEntry:467, HikariPool (com.zaxxer.hikari.pool)checkFailFast:541, HikariPool (com.zaxxer.hikari.pool)&lt;init&gt;:115, HikariPool (com.zaxxer.hikari.pool)getConnection:112, HikariDataSource (com.zaxxer.hikari)fetchConnection:157, DataSourceUtils (org.springframework.jdbc.datasource)doGetConnection:115, DataSourceUtils (org.springframework.jdbc.datasource)getConnection:78, DataSourceUtils (org.springframework.jdbc.datasource)openConnection:82, SpringManagedTransaction (org.mybatis.spring.transaction)getConnection:68, SpringManagedTransaction (org.mybatis.spring.transaction)getConnection:336, BaseExecutor (org.apache.ibatis.executor)prepareStatement:85, SimpleExecutor (org.apache.ibatis.executor)doQuery:62, SimpleExecutor (org.apache.ibatis.executor)queryFromDatabase:324, BaseExecutor (org.apache.ibatis.executor)query:156, BaseExecutor (org.apache.ibatis.executor)query:109, CachingExecutor (org.apache.ibatis.executor)query:83, CachingExecutor (org.apache.ibatis.executor)selectList:148, DefaultSqlSession (org.apache.ibatis.session.defaults)selectList:141, DefaultSqlSession (org.apache.ibatis.session.defaults)invoke0:-1, NativeMethodAccessorImpl (sun.reflect)invoke:62, NativeMethodAccessorImpl (sun.reflect)invoke:43, DelegatingMethodAccessorImpl (sun.reflect)invoke:498, Method (java.lang.reflect)invoke:433, SqlSessionTemplate$SqlSessionInterceptor (org.mybatis.spring)selectList:-1, $Proxy59 (com.sun.proxy)selectList:230, SqlSessionTemplate (org.mybatis.spring)executeForMany:144, MapperMethod (org.apache.ibatis.binding)execute:77, MapperMethod (org.apache.ibatis.binding)invoke:58, MapperProxy (org.apache.ibatis.binding)selectByCondition:-1, $Proxy60 (com.sun.proxy)getUserByCondition:40, UsersServiceImpl (com.springboot.demo.service.impl)getUsersByCondition:74, IndexController (com.springboot.demo.controller)invoke0:-1, NativeMethodAccessorImpl (sun.reflect)invoke:62, NativeMethodAccessorImpl (sun.reflect)invoke:43, DelegatingMethodAccessorImpl (sun.reflect)invoke:498, Method (java.lang.reflect)doInvoke:189, InvocableHandlerMethod (org.springframework.web.method.support)invokeForRequest:138, InvocableHandlerMethod (org.springframework.web.method.support)invokeAndHandle:102, ServletInvocableHandlerMethod (org.springframework.web.servlet.mvc.method.annotation)invokeHandlerMethod:895, RequestMappingHandlerAdapter (org.springframework.web.servlet.mvc.method.annotation)handleInternal:800, RequestMappingHandlerAdapter (org.springframework.web.servlet.mvc.method.annotation)handle:87, AbstractHandlerMethodAdapter (org.springframework.web.servlet.mvc.method)doDispatch:1038, DispatcherServlet (org.springframework.web.servlet)doService:942, DispatcherServlet (org.springframework.web.servlet)processRequest:1005, FrameworkServlet (org.springframework.web.servlet)doGet:897, FrameworkServlet (org.springframework.web.servlet)service:634, HttpServlet (javax.servlet.http)service:882, FrameworkServlet (org.springframework.web.servlet)service:741, HttpServlet (javax.servlet.http)internalDoFilter:231, ApplicationFilterChain (org.apache.catalina.core)doFilter:166, ApplicationFilterChain (org.apache.catalina.core)doFilter:53, WsFilter (org.apache.tomcat.websocket.server)internalDoFilter:193, ApplicationFilterChain (org.apache.catalina.core)doFilter:166, ApplicationFilterChain (org.apache.catalina.core)doFilterInternal:99, RequestContextFilter (org.springframework.web.filter)doFilter:107, OncePerRequestFilter (org.springframework.web.filter)internalDoFilter:193, ApplicationFilterChain (org.apache.catalina.core)doFilter:166, ApplicationFilterChain (org.apache.catalina.core)doFilterInternal:92, FormContentFilter (org.springframework.web.filter)doFilter:107, OncePerRequestFilter (org.springframework.web.filter)internalDoFilter:193, ApplicationFilterChain (org.apache.catalina.core)doFilter:166, ApplicationFilterChain (org.apache.catalina.core)doFilterInternal:93, HiddenHttpMethodFilter (org.springframework.web.filter)doFilter:107, OncePerRequestFilter (org.springframework.web.filter)internalDoFilter:193, ApplicationFilterChain (org.apache.catalina.core)doFilter:166, ApplicationFilterChain (org.apache.catalina.core)doFilterInternal:200, CharacterEncodingFilter (org.springframework.web.filter)doFilter:107, OncePerRequestFilter (org.springframework.web.filter)internalDoFilter:193, ApplicationFilterChain (org.apache.catalina.core)doFilter:166, ApplicationFilterChain (org.apache.catalina.core)invoke:200, StandardWrapperValve (org.apache.catalina.core)invoke:96, StandardContextValve (org.apache.catalina.core)invoke:490, AuthenticatorBase (org.apache.catalina.authenticator)invoke:139, StandardHostValve (org.apache.catalina.core)invoke:92, ErrorReportValve (org.apache.catalina.valves)invoke:74, StandardEngineValve (org.apache.catalina.core)service:343, CoyoteAdapter (org.apache.catalina.connector)service:408, Http11Processor (org.apache.coyote.http11)process:66, AbstractProcessorLight (org.apache.coyote)process:834, AbstractProtocol$ConnectionHandler (org.apache.coyote)doRun:1415, NioEndpoint$SocketProcessor (org.apache.tomcat.util.net)run:49, SocketProcessorBase (org.apache.tomcat.util.net)runWorker:1149, ThreadPoolExecutor (java.util.concurrent)run:624, ThreadPoolExecutor$Worker (java.util.concurrent)run:61, TaskThread$WrappingRunnable (org.apache.tomcat.util.threads)run:748, Thread (java.lang) 再次请求连接建立后，再次请求的调用栈 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485createProxyConnection:97, PoolEntry (com.zaxxer.hikari.pool)getConnection:185, HikariPool (com.zaxxer.hikari.pool)getConnection:155, HikariPool (com.zaxxer.hikari.pool)getConnection:128, HikariDataSource (com.zaxxer.hikari)fetchConnection:157, DataSourceUtils (org.springframework.jdbc.datasource)doGetConnection:115, DataSourceUtils (org.springframework.jdbc.datasource)getConnection:78, DataSourceUtils (org.springframework.jdbc.datasource)openConnection:82, SpringManagedTransaction (org.mybatis.spring.transaction)getConnection:68, SpringManagedTransaction (org.mybatis.spring.transaction)getConnection:336, BaseExecutor (org.apache.ibatis.executor)prepareStatement:85, SimpleExecutor (org.apache.ibatis.executor)doQuery:62, SimpleExecutor (org.apache.ibatis.executor)queryFromDatabase:324, BaseExecutor (org.apache.ibatis.executor)query:156, BaseExecutor (org.apache.ibatis.executor)query:109, CachingExecutor (org.apache.ibatis.executor)query:83, CachingExecutor (org.apache.ibatis.executor)selectList:148, DefaultSqlSession (org.apache.ibatis.session.defaults)selectList:141, DefaultSqlSession (org.apache.ibatis.session.defaults)invoke0:-1, NativeMethodAccessorImpl (sun.reflect)invoke:62, NativeMethodAccessorImpl (sun.reflect)invoke:43, DelegatingMethodAccessorImpl (sun.reflect)invoke:498, Method (java.lang.reflect)invoke:433, SqlSessionTemplate$SqlSessionInterceptor (org.mybatis.spring)selectList:-1, $Proxy59 (com.sun.proxy)selectList:230, SqlSessionTemplate (org.mybatis.spring)executeForMany:144, MapperMethod (org.apache.ibatis.binding)execute:77, MapperMethod (org.apache.ibatis.binding)invoke:58, MapperProxy (org.apache.ibatis.binding)selectByCondition:-1, $Proxy60 (com.sun.proxy)getUserByCondition:40, UsersServiceImpl (com.springboot.demo.service.impl)getUsersByCondition:74, IndexController (com.springboot.demo.controller)invoke0:-1, NativeMethodAccessorImpl (sun.reflect)invoke:62, NativeMethodAccessorImpl (sun.reflect)invoke:43, DelegatingMethodAccessorImpl (sun.reflect)invoke:498, Method (java.lang.reflect)doInvoke:189, InvocableHandlerMethod (org.springframework.web.method.support)invokeForRequest:138, InvocableHandlerMethod (org.springframework.web.method.support)invokeAndHandle:102, ServletInvocableHandlerMethod (org.springframework.web.servlet.mvc.method.annotation)invokeHandlerMethod:895, RequestMappingHandlerAdapter (org.springframework.web.servlet.mvc.method.annotation)handleInternal:800, RequestMappingHandlerAdapter (org.springframework.web.servlet.mvc.method.annotation)handle:87, AbstractHandlerMethodAdapter (org.springframework.web.servlet.mvc.method)doDispatch:1038, DispatcherServlet (org.springframework.web.servlet)doService:942, DispatcherServlet (org.springframework.web.servlet)processRequest:1005, FrameworkServlet (org.springframework.web.servlet)doGet:897, FrameworkServlet (org.springframework.web.servlet)service:634, HttpServlet (javax.servlet.http)service:882, FrameworkServlet (org.springframework.web.servlet)service:741, HttpServlet (javax.servlet.http)internalDoFilter:231, ApplicationFilterChain (org.apache.catalina.core)doFilter:166, ApplicationFilterChain (org.apache.catalina.core)doFilter:53, WsFilter (org.apache.tomcat.websocket.server)internalDoFilter:193, ApplicationFilterChain (org.apache.catalina.core)doFilter:166, ApplicationFilterChain (org.apache.catalina.core)doFilterInternal:99, RequestContextFilter (org.springframework.web.filter)doFilter:107, OncePerRequestFilter (org.springframework.web.filter)internalDoFilter:193, ApplicationFilterChain (org.apache.catalina.core)doFilter:166, ApplicationFilterChain (org.apache.catalina.core)doFilterInternal:92, FormContentFilter (org.springframework.web.filter)doFilter:107, OncePerRequestFilter (org.springframework.web.filter)internalDoFilter:193, ApplicationFilterChain (org.apache.catalina.core)doFilter:166, ApplicationFilterChain (org.apache.catalina.core)doFilterInternal:93, HiddenHttpMethodFilter (org.springframework.web.filter)doFilter:107, OncePerRequestFilter (org.springframework.web.filter)internalDoFilter:193, ApplicationFilterChain (org.apache.catalina.core)doFilter:166, ApplicationFilterChain (org.apache.catalina.core)doFilterInternal:200, CharacterEncodingFilter (org.springframework.web.filter)doFilter:107, OncePerRequestFilter (org.springframework.web.filter)internalDoFilter:193, ApplicationFilterChain (org.apache.catalina.core)doFilter:166, ApplicationFilterChain (org.apache.catalina.core)invoke:200, StandardWrapperValve (org.apache.catalina.core)invoke:96, StandardContextValve (org.apache.catalina.core)invoke:490, AuthenticatorBase (org.apache.catalina.authenticator)invoke:139, StandardHostValve (org.apache.catalina.core)invoke:92, ErrorReportValve (org.apache.catalina.valves)invoke:74, StandardEngineValve (org.apache.catalina.core)service:343, CoyoteAdapter (org.apache.catalina.connector)service:408, Http11Processor (org.apache.coyote.http11)process:66, AbstractProcessorLight (org.apache.coyote)process:834, AbstractProtocol$ConnectionHandler (org.apache.coyote)doRun:1415, NioEndpoint$SocketProcessor (org.apache.tomcat.util.net)run:49, SocketProcessorBase (org.apache.tomcat.util.net)runWorker:1149, ThreadPoolExecutor (java.util.concurrent)run:624, ThreadPoolExecutor$Worker (java.util.concurrent)run:61, TaskThread$WrappingRunnable (org.apache.tomcat.util.threads)run:748, Thread (java.lang) 因为两次请求的调用栈都比较深且有很大一部分重合路径，我们使用Beyond Compare将两次调用栈对比来看。 Mybatis处理如上图所示 selectByCondition 是请求中dao层的调用方法，这个方法调用之前是spring对http请求的处理动作，处理的流程暂不分析。直接看selectByCondition之后处理流程。 MyBatis通过SqlSessionFactoryBuilder对mybatis-config.xml进行解析，从中构建出SqlSessionFactory， 再创建出SqlSession实例， SqlSession调用Executor生成StatementHandler对象。 然后通过Spring框架的DataSourceUtils::getConnection方法获取连接。 连接对比两次请求不同的地方，对比HikariDataSource源码。 首次请求会调用112行，第二次会调用128行。 可以看到Hikari连接池使用了双重检查锁的方式来实现单例，避免重复创建连接池。 一次请求结束后，连接会放在连接池中，在连接池中，使用connectionBag控制一个连接“借出”、“归还”。详细信息可参考Hikari的线程池的生命周期 我们分析下首次调用建立连接的过程。 Hikari会先创建一个连接池，然后使用我们在启动时注册的驱动（com.mysql.cj.jdbc.Driver）创建连接。 可以从NonRegisteringDriver::connect一直追下去，可以看到com.mysql.cj.NativeSession::connect方法实现如下：123456789101112131415161718192021222324252627282930public void connect(HostInfo hi, String user, String password, String database, int loginTimeout, TransactionEventHandler transactionManager) throws IOException &#123; this.hostInfo = hi; // reset max-rows to default value this.setSessionMaxRows(-1); // TODO do we need different types of physical connections? SocketConnection socketConnection = new NativeSocketConnection(); socketConnection.connect(this.hostInfo.getHost(), this.hostInfo.getPort(), this.propertySet, getExceptionInterceptor(), this.log, loginTimeout); // we use physical connection to create a -&gt; protocol // this configuration places no knowledge of protocol or session on physical connection. // physical connection is responsible *only* for I/O streams if (this.protocol == null) &#123; this.protocol = NativeProtocol.getInstance(this, socketConnection, this.propertySet, this.log, transactionManager); &#125; else &#123; this.protocol.init(this, socketConnection, this.propertySet, transactionManager); &#125; // use protocol to create a -&gt; session // protocol is responsible for building a session and authenticating (using AuthenticationProvider) internally this.protocol.connect(user, password, database); // error messages are returned according to character_set_results which, at this point, is set from the response packet this.protocol.getServerSession().setErrorMessageEncoding(this.protocol.getAuthenticationProvider().getEncodingForHandshake()); this.isClosed = false;&#125; 先创建一个socket与服务端建立连接 通过NativeProtocol.getInstance初始化MySQL协议相关信息 调用NativeProtocol::connect方法根据MySQL账号、密码、使用数据库等信息向服务端请求认证。 使用proceedHandshakeWithPluggableAuthentication对返回的数据包根据MySQL协议进行解析。 调用NativeProtocol::checkErrorMessage对解析后的内容做判断，如果没问题则正常连接，如果返回错误信息则抛出异常。 连接建立后，通过Hikari连接池保存，下次使用直接用（如对比文件所示）。MySQL协议详解可参考：http://hutaow.com/blog/2013/11/06/mysql-protocol-analysis/ 事务处理org.springframework.jdbc.datasource.DataSourceTransactionManager会维护一个DataSourceTransactionObject。里面存放事务请求的连接。保证事务里的所有请求都是同一个连接在执行。 总结通过对数据库连接过程的分析，对数据库服务端、客户端的连接过程有了一个初步的认识，脑海中有个大概的体系，但还是不够深入，如MySQL协议的具体协议内容、连接鉴权的细节、Hikari连接池、Jdbc。。。都需要大量时间去深入研究，接下来要逐步去学习、沉淀下来。]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-MySQL】数据库连接过程分析]]></title>
    <url>%2F6c0fa14d.html</url>
    <content type="text"><![CDATA[前言上周出现了几次连接超时、连接池满还有dbc连接事务模板失败的问题。所以有必要深入了解下MySQL的连接过程。 正好，上周研究了怎么用Clion调试MySQL源码，接下来通过调试来研究一下吧。 服务端启动sql/main.cc123extern int mysqld_main(int argc, char **argv);int main(int argc, char **argv) &#123; return mysqld_main(argc, argv); &#125; main：入口文件，仅调用了mysqld_main函数 sql/mysqld.cc12345678910111213141516int mysqld_main(int argc, char **argv)#endif&#123;if (my_init()) // init my_sys library &amp; pthreads &#123; ... &#125; ... if (load_defaults(MYSQL_CONFIG_NAME, load_default_groups, &amp;argc, &amp;argv, &amp;argv_alloc)) &#123; ... &#125; mysqld_socket_acceptor-&gt;connection_event_loop(); mysqld_exit(signal_hand_thr_exit_code);&#125; mysql_main：MySQL服务端启动逻辑的主要处理函数 my_init：系统库和线程初始化 load_defaults：加载my.cnf各参数 connection_event_loop：循环监听套接字。 sql/conn_handler/connection_acceptor.h1234567891011/** Connection acceptor loop to accept connections from clients.*/void connection_event_loop() &#123; Connection_handler_manager *mgr = Connection_handler_manager::get_instance(); while (!connection_events_loop_aborted()) &#123; Channel_info *channel_info = m_listener-&gt;listen_for_connection_event(); if (channel_info != NULL) mgr-&gt;process_new_connection(channel_info); &#125;&#125; connection_event_loop：通过socket_connection.cc::listen_for_connection_event循环监听，直到有新的连接，开始connection_handler_manager.cc::process_new_connection新连接的处理过程。新连接服务端一直处于监听状态，当有新连接请求时，调用process_new_connection处理新连接。 sql/conn_handler/connection_handler_manager.cc1234567891011121314void Connection_handler_manager::process_new_connection( Channel_info *channel_info) &#123; if (connection_events_loop_aborted() || !check_and_incr_conn_count(channel_info-&gt;is_admin_connection())) &#123; channel_info-&gt;send_error_and_close_channel(ER_CON_COUNT_ERROR, 0, true); delete channel_info; return; &#125; if (m_connection_handler-&gt;add_connection(channel_info)) &#123; inc_aborted_connects(); delete channel_info; &#125;&#125; connection_events_loop_aborted：先判断是否已取消监听 check_and_incr_conn_count：再判断（会加锁）是否现有连接数是否大于连接最大值（连接池满），未满，则将线程数加一，满了则拒绝连接。（注意，这里的判断逻辑使MySQL的实际最大连接数是max_connections + 1） add_connection：调用add_connection添加连接 sql/conn_handler/connection_handler_pre_thread.cc123456789101112131415161718192021222324252627282930313233bool Per_thread_connection_handler::add_connection(Channel_info *channel_info) &#123; int error = 0; my_thread_handle id; DBUG_ENTER("Per_thread_connection_handler::add_connection"); // Simulate thread creation for test case before we check thread cache DBUG_EXECUTE_IF("fail_thread_create", error = 1; goto handle_error;); if (!check_idle_thread_and_enqueue_connection(channel_info)) DBUG_RETURN(false); /* There are no idle threads avaliable to take up the new connection. Create a new thread to handle the connection */ channel_info-&gt;set_prior_thr_create_utime(); error = mysql_thread_create(key_thread_one_connection, &amp;id, &amp;connection_attrib, handle_connection, (void *)channel_info);#ifndef DBUG_OFFhandle_error:#endif // !DBUG_OFF if (error) &#123; ... //错误处理，略 &#125; Global_THD_manager::get_instance()-&gt;inc_thread_created(); DBUG_PRINT("info", ("Thread created")); DBUG_RETURN(false);&#125; 调用check_idle_thread_and_enqueue_connection查看是否有空闲的线程，有则将本次连接信息加入等待队列，并给空闲线程发送唤醒信号；否则新建线程处理本次连接 在新线程中，调用handle_connection函数开始进行逻辑处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687static void *handle_connection(void *arg) &#123; Global_THD_manager *thd_manager = Global_THD_manager::get_instance(); Connection_handler_manager *handler_manager = Connection_handler_manager::get_instance(); Channel_info *channel_info = static_cast&lt;Channel_info *&gt;(arg); bool pthread_reused MY_ATTRIBUTE((unused)) = false; if (my_thread_init()) &#123; ... //错误处理，略 &#125; for (;;) &#123; THD *thd = init_new_thd(channel_info); if (thd == NULL) &#123; ... //错误处理，略 &#125;#ifdef HAVE_PSI_THREAD_INTERFACE if (pthread_reused) &#123; ... //错误处理，略 &#125;#endif#ifdef HAVE_PSI_THREAD_INTERFACE /* Find the instrumented thread */ PSI_thread *psi = PSI_THREAD_CALL(get_thread)(); /* Save it within THD, so it can be inspected */ thd-&gt;set_psi(psi);#endif /* HAVE_PSI_THREAD_INTERFACE */ mysql_thread_set_psi_id(thd-&gt;thread_id()); mysql_thread_set_psi_THD(thd); mysql_socket_set_thread_owner( thd-&gt;get_protocol_classic()-&gt;get_vio()-&gt;mysql_socket); thd_manager-&gt;add_thd(thd); if (thd_prepare_connection(thd)) handler_manager-&gt;inc_aborted_connects(); else &#123; while (thd_connection_alive(thd)) &#123; if (do_command(thd)) break; &#125; end_connection(thd); &#125; close_connection(thd, 0, false, false); thd-&gt;get_stmt_da()-&gt;reset_diagnostics_area(); thd-&gt;release_resources(); // Clean up errors now, before possibly waiting for a new connection.#ifndef HAVE_WOLFSSL#if OPENSSL_VERSION_NUMBER &lt; 0x10100000L ERR_remove_thread_state(0);#endif /* OPENSSL_VERSION_NUMBER &lt; 0x10100000L */#endif thd_manager-&gt;remove_thd(thd); Connection_handler_manager::dec_connection_count();#ifdef HAVE_PSI_THREAD_INTERFACE /* Delete the instrumentation for the job that just completed. */ thd-&gt;set_psi(NULL); PSI_THREAD_CALL(delete_current_thread)();#endif /* HAVE_PSI_THREAD_INTERFACE */ delete thd; // Server is shutting down so end the pthread. if (connection_events_loop_aborted()) break; channel_info = Per_thread_connection_handler::block_until_new_connection(); if (channel_info == NULL) break; pthread_reused = true; if (connection_events_loop_aborted()) &#123; ... //错误处理，略 &#125; &#125; my_thread_end(); my_thread_exit(0); return NULL;&#125; 会对连接进行thd_prepare_connection预处理操作，没问题后继续下面的逻辑。 当连接未被关闭，就会一直do_command处理请求。 当连接关闭，则走下面关闭逻辑 执行sql/sql_parse.cc12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697bool do_command(THD *thd) &#123; bool return_value; int rc; NET *net = NULL; enum enum_server_command command; COM_DATA com_data; DBUG_ENTER("do_command"); DBUG_ASSERT(thd-&gt;is_classic_protocol()); /* indicator of uninitialized lex =&gt; normal flow of errors handling (see my_message_sql) */ thd-&gt;lex-&gt;set_current_select(0); /* XXX: this code is here only to clear possible errors of init_connect. Consider moving to prepare_new_connection_state() instead. That requires making sure the DA is cleared before non-parsing statements such as COM_QUIT. */ thd-&gt;clear_error(); // Clear error message thd-&gt;get_stmt_da()-&gt;reset_diagnostics_area(); /* This thread will do a blocking read from the client which will be interrupted when the next command is received from the client, the connection is closed or "net_wait_timeout" number of seconds has passed. */ net = thd-&gt;get_protocol_classic()-&gt;get_net(); my_net_set_read_timeout(net, thd-&gt;variables.net_wait_timeout); net_new_transaction(net); /* Synchronization point for testing of KILL_CONNECTION. This sync point can wait here, to simulate slow code execution between the last test of thd-&gt;killed and blocking in read(). The goal of this test is to verify that a connection does not hang, if it is killed at this point of execution. (Bug#37780 - main.kill fails randomly) Note that the sync point wait itself will be terminated by a kill. In this case it consumes a condition broadcast, but does not change anything else. The consumed broadcast should not matter here, because the read/recv() below doesn't use it. */ DEBUG_SYNC(thd, "before_do_command_net_read"); /* Because of networking layer callbacks in place, this call will maintain the following instrumentation: - IDLE events - SOCKET events - STATEMENT events - STAGE events when reading a new network packet. In particular, a new instrumented statement is started. See init_net_server_extension() */ thd-&gt;m_server_idle = true; rc = thd-&gt;get_protocol()-&gt;get_command(&amp;com_data, &amp;command); thd-&gt;m_server_idle = false; if (rc) &#123; ... //错误处理，略 &#125; char desc[VIO_DESCRIPTION_SIZE]; vio_description(net-&gt;vio, desc); DBUG_PRINT("info", ("Command on %s = %d (%s)", desc, command, command_name[command].str)); DBUG_PRINT("info", ("packet: '%*.s'; command: %d", thd-&gt;get_protocol_classic()-&gt;get_packet_length(), thd-&gt;get_protocol_classic()-&gt;get_raw_packet(), command)); if (thd-&gt;get_protocol_classic()-&gt;bad_packet) DBUG_ASSERT(0); // Should be caught earlier // Reclaim some memory thd-&gt;get_protocol_classic()-&gt;get_output_packet()-&gt;shrink( thd-&gt;variables.net_buffer_length); /* Restore read timeout value */ my_net_set_read_timeout(net, thd-&gt;variables.net_read_timeout); return_value = dispatch_command(thd, &amp;com_data, command); thd-&gt;get_protocol_classic()-&gt;get_output_packet()-&gt;shrink( thd-&gt;variables.net_buffer_length);out: /* The statement instrumentation must be closed in all cases. */ DBUG_ASSERT(thd-&gt;m_digest == NULL); DBUG_ASSERT(thd-&gt;m_statement_psi == NULL); DBUG_RETURN(return_value);&#125; 主要的处理逻辑为dispatch_command，根据不同的command类型进行分发。 123456789101112131415161718192021222324252627282930313233343536373839/** Perform one connection-level (COM_XXXX) command. @param thd connection handle @param command type of command to perform @param com_data com_data union to store the generated command @todo set thd-&gt;lex-&gt;sql_command to SQLCOM_END here. @todo The following has to be changed to an 8 byte integer @retval 0 ok @retval 1 request of thread shutdown, i. e. if command is COM_QUIT*/bool dispatch_command(THD *thd, const COM_DATA *com_data, enum enum_server_command command) &#123; ... //太长不看 switch (command) &#123; case ... //太长不看 case COM_QUERY: &#123; ... //太长不看 mysql_parse(thd, &amp;parser_state); ... //太长不看 DBUG_PRINT("info", ("query ready")); break; &#125; case ... //太长不看 default: my_error(ER_UNKNOWN_COM_ERROR, MYF(0)); break; &#125;&#125; 主要看COM_QUERY这个逻辑，我们要用到的DDL、DML都会走这个流程，这个流程中主要是调用mysql_parse方法 123456789101112131415161718192021222324252627282930/** Parse a query. @param thd Current session. @param parser_state Parser state.*/void mysql_parse(THD *thd, Parser_state *parser_state) &#123; ... //太长不看 mysql_reset_thd_for_next_command(thd); if (!err) &#123; err = parse_sql(thd, parser_state, NULL); ... //太长不看 &#125; if (!err) &#123; mysql_rewrite_query(thd); ... //太长不看 &#125; if (!err) &#123; ... error = mysql_execute_command(thd, true); ... &#125;&#125; 主要是SQL语法解析和执行 mysql_reset_thd_for_next_command是对下一次执行做准备，重置线程各变量 mysql_rewrite_query看着像是SQL优化？待定 还没追进去，记个TODO 词法解析前不应该有缓存吗？没有找到缓存的逻辑，记个TODO（后续：原来MySQL8.0取消了query cache，详见：https://mysqlserverteam.com/mysql-8-0-retiring-support-for-the-query-cache/） 关闭连接sql/conn_handler/connection_handler_pre_thread.cc123456789101112131415161718192021222324252627282930313233343536373839Channel_info *Per_thread_connection_handler::block_until_new_connection() &#123; Channel_info *new_conn = NULL; mysql_mutex_lock(&amp;LOCK_thread_cache); if (blocked_pthread_count &lt; max_blocked_pthreads &amp;&amp; !shrink_cache) &#123; /* Don't kill the pthread, just block it for reuse */ DBUG_PRINT("info", ("Blocking pthread for reuse")); /* mysys_var is bound to the physical thread, so make sure mysys_var-&gt;dbug is reset to a clean state before picking another session in the thread cache. */ DBUG_POP(); DBUG_ASSERT(!_db_is_pushed_()); // Block pthread blocked_pthread_count++; while (!connection_events_loop_aborted() &amp;&amp; !wake_pthread &amp;&amp; !shrink_cache) mysql_cond_wait(&amp;COND_thread_cache, &amp;LOCK_thread_cache); blocked_pthread_count--; if (shrink_cache &amp;&amp; blocked_pthread_count &lt;= max_blocked_pthreads) &#123; mysql_cond_signal(&amp;COND_flush_thread_cache); &#125; if (wake_pthread) &#123; wake_pthread--; if (!waiting_channel_info_list-&gt;empty()) &#123; new_conn = waiting_channel_info_list-&gt;front(); waiting_channel_info_list-&gt;pop_front(); DBUG_PRINT("info", ("waiting_channel_info_list-&gt;pop %p", new_conn)); &#125; else &#123; DBUG_ASSERT(0); // We should not get here. &#125; &#125; &#125; mysql_mutex_unlock(&amp;LOCK_thread_cache); return new_conn;&#125; 如果阻塞的线程数小于最大阻塞线程数，则此线程不回收，而是进入阻塞状态（等待），等待新连接来的时候重复使用。 否则关闭线程。 客户端【从入门到放弃-MySQL】数据库连接过程分析-客户端 参考文献：https://www.cnblogs.com/FateTHarlaown/p/8676166.html]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-PHP】答题助手 PHP SWOOLE WebSocket 实战]]></title>
    <url>%2Fd59cfb42.html</url>
    <content type="text"><![CDATA[前言2018年伊始，各种答题赚钱热流席卷了朋友圈，先有百万英雄、冲顶大会成为风口浪尖，又有全民答题推波助澜。 公司适时推出了 《XX答题助手》采用“真人工 · 智能“的方式在直播答题的同时为大家提供参考答案，帮助大家稳、准、快的答对12道题目，分得真金白银。接下来我们以xx答题助手为例聊一聊websocket的应用 背景介绍 答题助手目前的planA如上 客户端采用轮询的方式每秒向服务器发送2次http请求，若有正确答案返回则展示在页面上。这种方式给服务器带来了很大的压力 答题直播时，每一个使用答题助手的用户会给服务器带来2qps的压力。经过优化目前每台服务器能抗约1w/qps的并发，当用户数上来后只能加机器。 分析业务场景，其实大多数的请求是无效的，客户端只需要在答题结果出来后，接收答案并展示即可。因此完全可以采用websocket的方法，在服务端获取到答案时，主动push消息到客户端即可。 Websocket协议Websocket协议是基于tcp协议的应用层协议 主要是为了实现客户端与服务端的全双工通信。 Websocket与HTTPWebsocket与HTTP都是基于TCP协议的应用层协议，Websocket在建立连接时需要先发送HTTP请求与服务器握手，待服务器返回101进行协议转换，从HTTP切成Websocket协议进行通信 握手过程如上：一、客户端：申请协议升级 客户端发起协议升级请求。采用HTTP报文，且仅支持GET方式 含义： Request Method: GET 使用get的方式 Connection: Upgrade 表示要升级协议 Upgrade: websocket 表示要升级的协议是websocket Sec-WebScoket-Version: 13 websocket协议支持的版本号。如果服务端不支持该版本，服务端需要返回一个Sec-WebScoket-Version Header，里面包含支持的版本号 Sec-WebSocket-Key: 7PMYxFH/jxrVsZvKeSTW1Q== 采用base64编码的随机16字节长的字符序列 Sec-WebScocket-Extensions: permessage-deflate; client_max_window_bits 希望采用的扩展协议 二、服务端：响应协议升级 Connection: upgrade 同意升级 Sec-WebSocket-Accept: E1rL2SuyYrDeuDYc5kUQApGBsyg= 服务端根据请求首部的Sec-WebSocket-Key计算出来的 计算方式如下： 1、将Sec-WebSocket-Key和 258EAFA5-E914-47DA-95CA-C5AB0DC85B11 进行拼接 2、经过SHA1计算并转成base64 Sec-WebSocket-Version: 13 升级版本为13 Upgrade: websocket 升级的协议是websocket 三、客户端验证客户端同样通过将Sec-WebSocket-Key和258EAFA5-E914-47DA-95CA-C5AB0DC85B11 拼接经过SHA1计算，转为base64后与Sec-WebSocket-Accept对比，相等则验证成功 至此连接建立，由HTTP协议切换为WebSocket协议 技术方案在了解WebSocket协议原理后 可基于TCP socket通过处理协议及数据帧搭建WebSocket服务。因swoole扩展已经对WebSocket进行了很好的封装以及进程的管理，同时是以C来实现的WebSocket，性能及稳定性都经过了很多大公司的检验，最终选用Swoole进行开发 Swoole扩展安装：下载swoole-2.0.12 table版 解压 进入解压目录 按以下步骤安装 (swoole2.0.12版本起不再支持php5，扩展编译需gcc-4.4+版本) 安装完毕在php.ini配置文件中加上extension=swoole.so即可启用swoole扩展 可使用下面几行代码实现一个最简单的WebSocket Server: 在on方法中注册事件以及其对应的回调函数进行处理。其中onMessage回调函数为必选，否则服务不会启动。用户可以onHandShake回调自定义握手协议，否则将使用Swoole默认的协议握手 广播：直接发http请求能触发onRequest回调，可在回调中遍历connections属性广播请求 注意：connections是一个迭代器对象 并且依赖pcre库，若编译时为安装prce库，此属性无法使用。需yum install pcre-devel 后重新编译swoole扩展使用 动态路由：搭建通用服务，使用一个websocket server提供多种类型的服务，需要根据路由动态选择服务类型和处理逻辑 可在onOpen时获取request对象的request_uri属性来根据url选择不同的路由做处理 onMessage时，无法获取request 需要在消息体内指定request_uri选择路由 性能压测主要测试WebSocket Server能抗住多少长连接和并发，以及push消息时的速度和消息到达率 fork N个进程使用异步非阻塞客户端进行压测 在32核 128G机器上测得部分数据如下： 并发数为55000时，cpu的idle峰值约为87%，链接建立后保持连接时约为99% push消息时97% push55000条消息平均需要200ms，消息送达率为100% 可见WebSocket长连接对机器资源的消耗非常小。 监控为了能在系统负载过大、无法申请到内存、程序被误杀等情况下 能重新拉起server需要有脚本监测 自动启动主进程，脚本如下 停止脚本 需要在Server启动后设置进程名称 至此WebSocket服务的搭建及压测监控都已完成。接下来在完成服务的稳定性、上下线等运维相关的工作后会计划灰度上线 后期结论会继续同步]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>WebSocket</tag>
        <tag>Swoole</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-Hadoop】Hadoop基础学习]]></title>
    <url>%2F76483f54.html</url>
    <content type="text"><![CDATA[前言目前人工智能和大数据火热，使用的场景也越来越广，日常开发中也逐渐接触了更多与大数据相关的开发需求。因此对大数据知识也有必要进行一些学习理解 基础概念大数据的本质一、数据的存储：分布式文件系统（分布式存储） 二、数据的计算：分部署计算 基础知识学习大数据需要具备Java知识基础及Linux知识基础 学习路线Java基础和Linux基础Hadoop的学习：体系结构、原理、编程第一阶段： HDFS、MapReduce、HBase（NoSQL数据库） 第二阶段： 数据分析引擎 -&gt; Hive、Pig 数据采集引擎 -&gt; Sqoop、Flume 第三阶段： HUE：Web管理工具 ZooKeeper：实现Hadoop的HA Oozie：工作流引擎 Spark的学习第一阶段：Scala编程语言 第二阶段：Spark Core -&gt; 基于内存、数据的计算 第三阶段：Spark SQL -&gt; 类似于mysql 的sql语句 第四阶段：Spark Streaming -&gt;进行流式计算：比如：自来水厂 Apache Storm 类似Spark Streaming -&gt;进行流式计算 NoSQLRedis基于内存的数据库 HDFS分布式文件系统 解决以下问题： 1、硬盘不够大：多几块硬盘，理论上可以无限大 2、数据不够安全：冗余度，hdfs默认冗余为3 ，用水平复制提高效率，传输按照数据库为单位：Hadoop1.x 64M，Hadoop2.x 128M 管理员：NameNode 硬盘：DataNode MapReduce基础编程模型：把一个大任务拆分成小任务，再进行汇总 MR任务：Job = Map + Reduce Map的输出是Reduce的输入、MR的输入和输出都是在HDFS MapReduce数据流程分析： Map的输出是Reduce的输入，Reduce的输入是Map的集合 HBase什么是BigTable？: 把所有的数据保存到一张表中，采用冗余 —&gt; 好处：提高效率 1、因为有了bigtable的思想：NoSQL：HBase数据库 2、HBase基于Hadoop的HDFS的 3、描述HBase的表结构 核心思想是：利用空间换效率 Hadoop环境搭建环境准备Linux环境、JDK、http://mirrors.shu.edu.cn/apache/hadoop/common/hadoop-3.0.0/hadoop-3.0.0-src.tar.gz 安装1、安装jdk、并配置环境变量 vim /etc/profile 末尾添加 2、解压hadoop-3.0.0.tar.gz、并配置环境变量 tar -zxvf hadoop-3.0.0.tar.gz -C /usr/local/ mv hadoop-3.0.0/ hadoop vim /etc/profile 末尾添加 配置Hadoop有三种安装模式： 本地模式 ： 1台主机 不具备HDFS，只能测试MapReduce程序 伪分布模式： 1台主机 具备Hadoop的所有功能，在单机上模拟一个分布式的环境 （1）HDFS：主：NameNode，数据节点：DataNode （2）Yarn：容器，运行MapReduce程序 主节点：ResourceManager 从节点：NodeManager 全分布模式： 至少3台 我们以伪分布模式为例配置： 修改hdfs-site.xml：冗余度1、权限检查false&lt;!--配置冗余度为1--&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;!--配置权限检查为false--&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; 修改core-site.xml&lt;!--配置HDFS的NameNode--&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://192.168.56.102:9000&lt;/value&gt; &lt;/property&gt; &lt;!--配置DataNode保存数据的位置--&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt; &lt;/property&gt; 修改mapred-site.xml&lt;!--配置MR运行的框架--&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yar&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.map.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.reduce.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.application.classpath&lt;/name&gt; &lt;value&gt; /usr/local/hadoop/etc/hadoop, /usr/local/hadoop/share/hadoop/common/*, /usr/local/hadoop/share/hadoop/common/lib/*, /usr/local/hadoop/share/hadoop/hdfs/*, /usr/local/hadoop/share/hadoop/hdfs/lib/*, /usr/local/hadoop/share/hadoop/mapreduce/*, /usr/local/hadoop/share/hadoop/mapreduce/lib/*, /usr/local/hadoop/share/hadoop/yarn/*, /usr/local/hadoop/share/hadoop/yarn/lib/*, &lt;/value&gt; &lt;/property&gt; 修改yarn-site.xml&lt;!--配置ResourceManager地址--&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;192.168.56.102&lt;/value&gt; &lt;/property&gt; &lt;!--配置NodeManager执行任务的方式--&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-service&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; 格式化NameNodehdfs namenode -format 看到common.Storage: Storage directory /usr/local/hadoop/tmp/dfs/name has been successfully formatted表示格式化成功 启动start-all.sh HDFS：存储数据 YARN： 访问 命令行 Java Api WEB Console HDFS: http://192.168.56.102:50070 Yarn: http://192.168.56.102:8088 查看HDFS管理界面和yarn资源管理系统 基本操作：HDFS相关命令-mkdir 在HDFD创建目录 hdfs dfs -mkdir /data -ls 查看目录 hdfs dfs -ls -ls -R 查看目录与子目录 hdfs dfs -ls -R -put 上传一个文件 hdfs dfs -put data.txt /data/input -copyFromLocal 上传一个文件 与-put一样 -moveFromLocal 上传一个文件并删除本地文件 -copyToLocal 下载文件 hdfs dfs -copyTolocal /data/input/data.txt -put 下载文件 hdfs dfs -put/data/input/data.txt -rm 删除文件 hdfs dfs -rm -getmerge 将目录所有文件先合并再下载 -cp 拷贝 -mv 移动 -count 统计目录下的文件个数 -text、-cat 查看文件 -balancer 平衡操作 MapReduce示例 结果： 如上 一个最简单的MapReduce示例就执行成功了 思考Hadoop是基于Java语言的，日常开发是用的PHP(写文章时，博主主要是用PHP，现在已经转Java了)，在使用、查找错误时还是蛮吃力的。工作之余还是需要多补充点其它语言的相关知识，编程语言是我们开发、学习的工具，而不应成为限制我们技术成长的瓶颈]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-PHP】foreach 引用的坑]]></title>
    <url>%2F76b41bca.html</url>
    <content type="text"><![CDATA[背景描述先看一段代码。1234567891011121314151617181920212223242526272829&lt;?php/*$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];$b = &amp;$arr['jack'];$a = $arr;$b = 30;var_dump($a);$str = '20';$c = &amp;$str;$d = $str;$c = 30;var_dump($d);*/$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];foreach ($arr as &amp;$val) &#123; echo $val;&#125;foreach ($arr as $val) &#123; echo $val;&#125;print_r($arr); 想一下应该输出什么呢？ 运行一下脚本，真实结果和你想的是否一致呢？ 在foreach中使用了引用后再次foreach发现$arr[‘less’]的值变成了54，常规理解应该是23才对。 猜测可能是因为使用引用导致该值变为54 但本着知其然更要知其所以然 我们一起追一下php源码 是什么原因导致的 环境准备工欲善其事必先利其器，先下载调试工具及源码 下载Visual Studio 2017，并安装下载地址：https://www.visualstudio.com/zh-hans/downloads/ 下载php源码http://cn2.php.net/distributions/php-7.0.27.tar.bz2 从文件夹创建解决方案创建成功后如下图所示 源码追踪先搜索关键字foreach 可以在zend_language_parser.c 中看到， 语法解析时 foreach会当做T_FOREACH 在zend_language_parser.y可以看到语法解析的具体方式 ZEND_AST_FOREACH 查找zend_ast_create zend_ast.c中： zend_ast_create 函数是创建一个抽象语法树（abstract syntax tree）返回的zend_ast结构如下： 具体的赋值操作如下： 接下来在zend_compile.c中根据抽象语法树生成opcode： 通过上图及语法解析的分析可知，foreach在编译阶段会生成如上图的四个zend_ast节点，分别表示：要遍历的数组或对象expr_ast，要遍历的value value_ast，要遍历的key key_ast，循环体stmt_ast如： 12345$arr = [1, 2, 3];foreach ($arr as $key =&gt; $val) &#123; echo $val;&#125; expr_ast 是可理解为是$arr编译时对应的ast结构 value_ast对应$val key_ast对应$key stmt_ast对应”echo $val;” copy一份要遍历的数组或对象，如果是引用则把原数组或对象设为引用类型如：123foreach ($arr as $k =&gt; $v) &#123; echo $v;&#125; copy一份$arr用于遍历，从arData的首元素起，把bucket.zval.value赋值给$v,把bucket.h或key赋值给$k，然后将下一个元素的位置记录在zval.u2.fe_iter_idx中，下次遍历从该位置开始 当u2.fe_iter_idex到了arData的末尾则遍历结束并销毁copy的$arr副本 如果$v是引用 则在循环前，将原$arr设置为引用类型 即：123foreach ($arr as $k =&gt; &amp;$v) &#123; echo $v;&#125; 编译copy的数组、对象操作的指令：增加一条opcode指令 ZEND_FE_RESET_R（如果value是引用则用ZEND_FE_RESET_RW） 。执行时如果发现遍历的不是数组、对象 则抛出一个warning，然后跳出循环。 编译fetch数组、对象当前单元key 、value的opcode : ZEND_FE_FETCH_R（如果value是引用则用ZEND_FE_FETCH_RW）。此opcode需要知道当遍历到达数组末尾时跳出遍历的位置。此外还会对key和value分配他们在内存中的位置，如果value不是一CV个变量，还会编译其它操作的opcode 如果定义了key，则会编译一条opcode，对key进行赋值 编译循环体statement 编译跳回遍历开始时的opcode，一次遍历结束后跳到步骤2编译的opcode进行下次遍历 设置步骤1、2两条opcode如果出错要跳到的opcode 结束循环 编译ZEND_FE_FREE用于释放1中copy的数组或对象结论分析编译后的结构： 运行时步骤： (1) 执行ZEND_FE_RESET_R，过程上面已经介绍了； (2) 执行ZEND_FE_FETCH_R，此opcode的操作主要有三个：检查遍历位置是否到达末尾、将数组元素的value赋值给$value、将数组元素的key赋值给一个临时变量(注意与value不同)； (3) 如果定义了key则执行ZEND_ASSIGN，将key的值从临时变量赋值给$key，否则跳到步骤(4)； (4) 执行循环体的statement； (5) 执行ZEND_JMPNZ跳回步骤(2)； (6) 遍历结束后执行ZEND_FE_FREE释放数组。 因此根据上面的分析：赋值的核心操作是ZEND_FE_FETCH_RW 上面的例子可等价于123456789101112131415$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];$val = &amp;$arr['jack'];$val = &amp;$arr['tom'];$val = &amp;$arr['marry'];$val = &amp;$arr['less'];$val = $arr['jack'];$val = $arr['tom'];$val = $arr['marry'];$val = $arr['less'];print_r($arr); 等价于：12345678910$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];$val = &amp;$arr['less']; (23)$val = $arr['marry']; (54，并且此时因为引用 $arr['less']也变为54了)$val = $arr['less']; (54)print_r($arr); 因此 为了避免出现不必要的错误，建议在使用完&amp;后，unset掉变量以取消对地址的引用 思维发散：针对以上情况，如果不取消对变量的引用，而是将数组赋值给一个新的变量再foreach。是否可行？ 先看一段代码：123456&lt;?php$str = '20';$c = &amp;$str;$a = $str;$c = 30;var_dump($a); 输出20 没有任何问题如果换成数组：1234567891011&lt;?php$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];$b = &amp;$arr;$a = $arr;$b['jack'] = 30;var_dump($a); 还是20 符合预期但如果这样呢：1234567891011&lt;?php$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];$b = &amp;$arr['jack'];$a = $arr;$b = 30;var_dump($a) 值却变成了30我们加上xdebug_debug_zval看看发生了什么12345678910111213&lt;?php$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];$b = &amp;$arr;$a = $arr;$b['jack'] = 30;var_dump($a);xdebug_debug_zval('a');xdebug_debug_zval('arr'); 可以看出，直接引用数组， $b = &amp;$arr, $arr 的is_ref是1，refcount是2, 给$a = $arr时，发生分离，$a 与$arr指向不同的zval，$b 与 $arr指向相同的zval，因此给$b[‘jack’] = 30, $a的值不会发生改变12345678910111213&lt;?php$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];$b = &amp;$arr['jack'];$a = $arr;$b = 30;var_dump($a);xdebug_debug_zval('a');xdebug_debug_zval('arr') 可以看出，对数组中一个元素引用时，数组的is_ref是0，因为$a = $arr 因此refcount是2 ，指向同一个zval，改变$b的值时，因为$arr[‘jack’]是一个引用，zval的值改变，$a和$arr的zval相同，$a[‘jack’]也变为30同理可以回答最开始提出的疑问：如果我不取消对变量的引用，而是将数组赋值给一个新的变量再foreach。是否可行？答：不行。123456789101112131415&lt;?php$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];foreach ($arr as &amp;$val) &#123; echo $val;&#125;$a = $arr;foreach ($a as $val) &#123; echo $val;&#125;print_r($a); 因为$arr与$a指向同一份zval，还是会出现$a[‘less’] = 54的结果。因此，在foreach使用完&amp;后，还是unset掉变量 取消对地址的引用再进行下一步操作吧 参考文献：https://github.com/pangudashu/php7-internal/blob/master/4/loop.md]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-MySQL】mysql 数据恢复实战&踩坑记录]]></title>
    <url>%2F6e2383f1.html</url>
    <content type="text"><![CDATA[背景介绍线下环境的两个mysql实例安装部署在同一台测试机器上使用不同端口，某天，机器硬盘故障无法启动、并且无法重装系统，需要将重要数据备份重新部署mysql并恢复 操作步骤备份数据首先联系pe同学通过带外方式启动故障主机并将硬盘挂载，通过scp方式将两个mysql实例的data目录下所有文件copy备份注意 切勿仅copy MYD，MYI，frm及ibd文件 准备环境原主机硬盘故障无法重装系统，需要到现场维修。所以新申请了一台主机使用安装与原mysql版本一致的mysql历史原因原主机安装的版本分别为5.1.40 和5.6.26主机自带5.1.40版本的mysql不需要自己再安装，直接将备份的data目录覆盖copy新机器的data目录 并修改好文件权限即可 安装mysql高版本的mysql需要重新安装 。步骤如下 下载glibc版wget https://cdn.mysql.com/archives/mysql-5.6/mysql-5.6.26-linux-glibc2.5-x86_64.tar.gz 解压并移动tar -zxvf mysql-5.6.26-linux-glibc2.5-x86_64.tar.gzmv mysql-5.6.26-linux-glibc2.5-x86_64.tar.gz /usr/local/mysql 修改权限并初始化1234chown -R mysql:mysql /usr/local/mysql cd /usr/local/mysql/bin# 修改/usr/local/mysql/my.cnf 修改启动端口和文件存放路径 1234sudo ./mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --lc_messages_dir=/usr/local/mysql/share --lc_messages=en_US --defaults-file=/usr/local/mysql/my.cnf #（如忘记密码可执行以下操作免密码登录）sudo /usr/bin/mysqld_safe --skip-grant-tables &amp; 将原数据data目录覆盖并修改权限登录验证至此 mysql数据恢复工作已经完成 踩坑记录背景之前两台测试环境mysql分别安装在不同的主机上，其中一台为虚拟主机，硬盘容量只有50G，出现过数据不断累积导致硬盘容量不足的情况，同时因为测试机器资源紧张，考虑将两个mysql实例安装在同一台物理主机上因物理主机上使用的mysql版本过低 所以新的mysql实例决定升级为高版本 安装时出现的问题在mysql官网现在了最新的稳定版mysql，解压、进行安装出现以下报错123456sudo ./mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --lc_messages_dir=/usr/local/mysql/share --lc_messages=en_US --defaults-file=/usr/local/mysql/my.cnf ./mysqld: /usr/lib64/libnuma.so.1: no version information available (required by ./mysqld)./mysqld: /usr/lib64/libnuma.so.1: no version information available (required by ./mysqld)./mysqld: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.11&apos; not found (required by ./mysqld)./mysqld: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.9&apos; not found (required by ./mysqld)./mysqld: /lib64/libc.so.6: version `GLIBC_2.10&apos; not found (required by ./mysqld) 看报错内容是一些依赖库版本过低导致，当时准备升级版本库在网上找到了 高版本的libstdc++ 、glibc等进行编译升级成功安装好了高版本 libstdc++后继续编译安装glibc编译安装好后，在删除原libc-2.5.so 更改软链为高版本libc时，悲剧出现了！因缺少libc库，所有的ls、ln、cp、sudo等命令全都无法使用了在网上找解决办法，可以在执行命令前使用LD_PRELOAD=/lib64/libc-2.5.so提前载入链接库来执行命令，ls、cp等命令可以用了但是使用ln命令时，发现权限不够ok，没关系 我们在sudo前 也提前载入链接库不就行了？执行：？？？ 尴尬了 竟然不行！查阅资料发现 sudo命令因为安全原因 不能使用LD_PRELOAD的方式 。我当时是在admin用户下 也无法sudo su切换到root 用户陷入了死循环、不切换到root用户就没权限恢复libc-2.5.so库 不恢复libc-2.5.so就没办法切换到root用户。。。无解，只能找pe同学帮忙，通过带外的方式恢复libc-2.5.so 解决方式系统恢复正常了，但是我们高版本的mysql还是没装上，系统库是不敢随便乱动了，那咋办呢？查看下glibc库版本天无绝人之路，发现有https://cdn.mysql.com/archives/mysql-5.6/mysql-5.6.26-linux-glibc2.5-x86_64.tar.gz glibc2.5版本的glibc版mysql安装包安装试试？通过上文 “安装mysql”中的方式 安装成功接下来修改用户密码、权限，通过mysqldump将原虚拟机中数据库的数据导入到5.6.26版本的数据库中 一台虚拟机上运行两个不同版本实例数据库大功告成~ mysql数据文件介绍表结构 .frm.frm文件：存储数据表的框架结构，文件名与表名相同，每个表对应一个同名frm文件，与操作系统和存储引擎无关 MyISAM数据文件.MYD文件：即MY Data，表数据文件.MYI文件：即MY Index，索引文件.log文件：日志文件 InnoDB数据文件ibdata1、ibdata2等：系统表空间文件，存储InnoDB系统信息和用户数据库表数据和索引，所有表共用.ibd文件：单表表空间文件，每个表使用一个表空间文件（file per table），存放用户数据库表数据和索引日志文件： ib_logfile1、ib_logfile2在备份和恢复数据时，我发现两个不同版本的数据库，ibdata1文件的大小相差很大查阅资料后发现原来InnoDB有两种不同的数据存储方式：共享表空间: 某一个数据库的所有的表数据，索引文件全部放在一个文件中，默认这个共享表空间的文件路径在data目录下。 默认的文件名为:ibdata1 初始化为10M。独占表空间: 每一个表都将会生成以独立的文件方式来进行存储（.ibd文件，这个文件包括了单独一个表的数据内容以及索引内容)。 存储内容比较使用独占表空间之后：每个表对应的数据、索引和插入缓冲 存放在独占表空间（.idb文件）每个表对应的撤销（undo）信息，系统事务信息，二次写缓冲等还是存放在了原来的共享表空间内（ibdata1文件） 特点比较具体的共享表空间和独立表空间优缺点如下：共享表空间：优点：可以放表空间分成多个文件存放到各个磁盘上（表空间文件大小不受表大小的限制，如一个表可以分布在不同的文件上）。数据和文件放在一起方便管理。缺点：所有的数据和索引存放到一个文件中，则将有一个很常大的文件，虽然可以把一个大文件分成多个小文件，但是多个表及索引在表空间中混合存储，这样对于一个表做了大量删除操作后表空间中将会有大量的空隙，特别是对于统计分析，日志系统这类应用最不适合用共享表空间。独立表空间：（在配置文件（my.cnf）中设置 innodb_file_per_table）优点：每个表都有自已独立的表空间。每个表的数据和索引都会存在自已的表空间中。可以实现单表在不同的数据库中移动。空间可以回收对于使用独立表空间的表，不管怎么删除，表空间的碎片不会太严重的影响性能，而且还有机会处理。a)Drop table操作自动回收表空间b）如果对于统计分析或是日值表，删除大量数据后可以通过:alter table TableName engine=innodb;回缩不用的空间。c) 对于使innodb-plugin的Innodb使用truncate table也会使空间收缩。5、在服务器资源有限,单表数据不是特别多的情况下, 独立表空间明显比共享方式效率更高 . 但是MySQL 默认是共享表空间 。缺点：单表体积可能过大，如超过100个G。查看innodb_file_per_table配置可以看到两个mysql的配置不一样，一个使用的共享表空间，一个使用的独占表空间，这就是为什么两个ibdata1文件大小相差很大注意：因为.frm、.ibd、.MYD、.MYI文件都存在于与database同名的文件夹下，我们通常会注意到而ibdata1文件是直接在data目录下，不理解其是什么文件的情况下很容易被忽略，所以 这就是在上文备份和恢复数据中提到需要注意的地方 参考文献http://www.jb51.net/article/134901.htm]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-MySQL】mysql中要避免使用大事务]]></title>
    <url>%2Fb382ba8d.html</url>
    <content type="text"><![CDATA[前言在日常工作中经常会使用一些比较“大”的数据库查询和操作，这里的“大”主要是指 执行时间长：含有较多的逻辑处理、存在较耗时操作等 操作数据多：需要查询或更新操作的数量记录较多，会锁定大量数据造成阻塞和锁超时等。 本文会和大家一起探讨下，为什么 在数据库中要避免使用这些大查询。 事务大家都清楚事务具备ACID特性（即原子性、一致性、隔离性、持久性），针对隔离性，在数据库事务隔离标准中，定义了四种隔离级别：读未提交、读提交、可重复读、串行化。MySQL默认的事务隔离级别是可重复读，我们以此来展开分析 事务隔离的实现多版本并发控制（MMVC）每行记录后面会有两个隐藏列，记录创建版本号及删除版本号。创建本本号记为row trx_id 对于一个事务来说，启动时（申请完事务id后），MySQL会给此事务创建一个活跃事务（即已启动但还未提交的事务）id数组。数组中的最小值记为minTid，最大值记为maxTid。 如果minTid &gt; row trx_id，则数据是可见的。 如果maxTid &lt; row trx_id，则数据是不可见的。 如果minTid &lt;= row trx_id &lt;= maxTid，且： row trx_id在数组中，则说明启动时，此事务未提交，数据不可见 row trx_id不在数组中，则说明启动是，此事务已提交，数据可见 如：当前事务id为50，活跃id数组为[35, 43, 44, 45, 46, 50, 51, 52]则 row trx_id小于35的数据为可见 row trx_id大于52的数据不可见 35 &lt;= row trx_id &lt;= 52且在数组中的数据不可见，不在数组中的数据可见。 对于不可见的数据，则需要依次去数据上一个版本查询，直到查询到可用版本数据为止。 只有在新的RW事务建立的时候 才会新建一个视图 否则继续使用上次创建的视图。 回滚日志（undo log）上面提到对于不可见数据需要依次查询上一版本来获取到可用数据。我们知道数据库的数据更新是非常频繁的，不可能将每一版本的数据都存下来，那样数据量会巨大查询也会非常的缓慢。MySQL通过undo log来获取历史版本的数据。undo log不会记录每个版本的最终数据，它是一个逻辑日志，是反向将之前的操作取消掉。比如对insert的会进行执行delete，delete的执行insert，对于update的数据会执行一个反向update，将之前修改的内容改回去。 例如： S1时刻，事务34启动，进行insert i = 5 操作后，commit，数据记录为D1：i = 5，row_id为34； S2时刻，事务36启动； S3时刻，事务37启动，进行update i + 3 操作后，commit，数据记录为D3：i = 8，row_id为37； S4时刻，事务42启动 S5时刻，事务54启动，进行update i * 2 操作后，commit，数据记录为D5：i = 16，row_id为54 此时，如果事务42需要查询i的数据，因为当前i = 16，row_id为54，数据不可见，因此需要根据undo log查询上一版本的数据。update i / 2，得到row_id为37。可见，获取i = 8如果事务36需要查询i的数据，需要update i / 2, 查到row_id = 37,不可见，继续回滚 update i - 3，查到row_id = 34，可见，获取到i = 5 只有当回滚日志不再需要时，才会删除。系统会判断，当没有事务再需要这些回滚日志的时候，才会删除。 所以长事务意味着系统里面会存在很多非常老的事务视图，因为这些事务可能会访问数据库中的任何数据，所以在这个事务提交之前，系统不得不保留它之后可能用到的所有回滚记录。这就会占用大量的存储空间。 事务启动autocommit参数控制事务是否自动提交，MySQL默认set autocommit=1，开启自动提交，即每条select、update都会自动提交。所以我们日常使用的SQL语句其实等价于123begin;select * from table where xxx;commit; 但有些客户端连接框架默认会在连接成功后执行一条set autocommit = 0，这样会导致你只有执行一条select语句其实就开启了事务。这样会意外导致长事务的出现。因此还是建议set autocommit = 1配合begin来显示的启动事务。 锁大事务还会长时间、大量占用锁资源，阻塞DML、DDL操作、造成锁超时影响系统并发能力，并且很容易引发死锁问题。 连接数大事务会长时间占用数据库连接，并发情况下容易造成连接数满的问题 拖垮整个应用 主备延迟MySQL主备复制只会在事务执行完毕后才会进行，即binlog在事务commit后才会生成（两阶段提交）。大事务执行多久就会造成多长时间的主备延迟，主备延迟的时间越长带来的风险也就越高 缓存MySQL的buffer pool对查询具有缓存效果，对于很多高频查询可以直接从缓存返回不需要查找磁盘文件。但是当有大量数据需要返回时通常有很多顺序查询，记录在同一磁盘页中就会命中缓存机制 对缓存造成一定影响MySQL buffer pool的缓存机制是使用的改良LRU算法（主要增加了访问时间控制） 内存&amp;CPUMySQL数据返回默认是边取边发，因此数据较多，传输时间较长也也会引发长事务带来的问题。还有如果返回大量数据给客户端处理，对客户端的内存及CPU也会带来较大的压力。 超时和超出大小限制容易引起超时的问题和超出max_binlog_cache_size导致执行失败。（还要注意，避免出现为了让主库大事务顺利进行，临时调大主库max_binlog_cache_size，忽略备库导致的服务宕掉等严重后果） 回滚回滚大事务也是非常耗时和占用内存的，需要注意 总结应该尽量避免使用大事务，开发时要注意尽量 如果可以，将一个大事务拆分成多个小事务执行 将事务中可以提出的select查询放在事务外执行]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-MySQL】CLion调试MySQL8.0源码]]></title>
    <url>%2Fc4ec5dd3.html</url>
    <content type="text"><![CDATA[前言想对的MySQL底层实现做一些了解，奈何没有用过C++不知道怎么调试一个大型项目，一日和大神交流时大神扔给我了一份《XCode调试MySQL8秘籍》。于是在几经波折（主要是因为菜）之后终于打开了MySQL的调试大门。 环境搭建准备MacOS： 10.14.5：因为根据大神秘籍，要使用Xcode，但Xcode下载目前只支持10.14.3，因此在10.13.6下强升的系统版本，Xcode下MySQL成功编译运行成功，但是遇到了诡异的调试无法的问题，排查无果最后转用CLionCLion：2019.1.3mysql源码：https://github.com/mysql/mysql-servercmake和boost：brew install cmake boost 编译MySQL源码目录：/var/workspace/mysql/mysql-8.0.16/boost目录：/usr/local/Cellar/boost/1.68.0_1 12345678910111213cd /var/workspace/mysql/mysql-8.0.16/mkdir workcd workcmake . -DWITH_DEBUG=1 -DCMAKE_INSTALL_PREFIX=/var/workspace/mysql/mysql-8.0.16/work -DMYSQL_DATADIR=/var/workspace/mysql/mysql-8.0.16/work/data -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_ARCHIVE_STORAGE_ENGINE=1 -DWITH_ARCHIVE_STORAGE_ENGINE=1 -DWITH_READLINE=1 -DWITH_LIBWRAP=0 -DMYSQL_UNIX_ADDR=/tmp/mysql.sock -DENABLED_LOCAL_INFILE=1 -DENABLED_LOCAL_INFILE=1 -DENABLE_DOWNLOADS=1 -DDOWNLOAD_BOOST=1 -DWITH_BOOST=/usr/local/Cellar/boost/1.68.0_1 -DFORCE_INSOURCE_BUILD=1make -j 4make install -j 4cd /var/workspace/mysql/mysql-8.0.16/worksudo bin/mysqld --basedir=/var/workspace/mysql/mysql-8.0.16/work --datadir=/var/workspace/mysql/mysql-8.0.16/work/data --initialize-insecure --user=mysql 如果最后一步执行出错可以参考https://dev.mysql.com/doc/refman/8.0/en/binary-installation.html新建mysql-files并修改权限 可能会有各种神奇的报错，主要是权限问题！搞不定的话参考下面有最终的目录权限截图 配置导入mysql-8.0.16项目，配置cmake参数 options参考编译过程中的cmake参数 选择mysqld 并编辑启动参数 arguments如下：1--basedir=/var/workspace/mysql/mysql-8.0.16/work --datadir=/var/workspace/mysql/mysql-8.0.16/work/data --user=mysql 启动调试，此时可能还会报错 还是权限问题。。。clion无法以root权限启动debug，尝试各种方法无效。因此把mysql的data目录改为777最终目录权限如下图： 再此点击debug按钮，启动成功（注意没error了，可以用客户端测试启动成功了）。 调试 我们在代码中打上断点，客户端执行SQL语句时就能在断点处看到各变量信息了，比如图中的SQL解析。 可以看到执行阻塞了 Clion代码调试的具体方法不做赘述了，网上一堆。 总结之前一直想调试MySQL，但是总是没有迈出第一步，代码下载下来就完事儿了。这次一鼓作气走了下来，希望能开个好头，养成各种代码调试的好习惯。看代码中细节比任何文档中都来的扎实（当然，时间充裕前提下）。搭建环境的过程中遇到了很多问题，Google、百度无数遍都没有能解决问题，最终还是通过MySQL的官方手册找到的答案。MySQL的官方手册简直神器，大家可以好好利用起来。C++的知识仅停留在大学课本阶段，阅读源码简直困难，要能坚持下去，加油！]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>C++</tag>
      </tags>
  </entry>
</search>
