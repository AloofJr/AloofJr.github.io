<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[【从入门到放弃-MySQL】数据库连接过程分析]]></title>
    <url>%2F6c0fa14d.html</url>
    <content type="text"><![CDATA[前言上周出现了几次连接超时、连接池满还有dbc连接事务模板失败的问题。所以有必要深入了解下MySQL的连接过程。 正好，上周研究了怎么用Clion调试MySQL源码，接下来通过调试来研究一下吧。 服务端启动sql/main.ccmain：入口文件，仅调用了mysqld_main函数 sql/mysqld.ccmysql_main：MySQL服务端启动逻辑的主要处理函数，会做初始化和各种校验工作，最终会进行socket监听 sql/conn_handler/connection_acceptor.hconnection_event_loop：通过socket_connection.cc::listen_for_connection_event循环监听，直到有新的连接，开始connection_handler_manager.cc::process_new_connection新连接的处理过程。 1234567891011/** Connection acceptor loop to accept connections from clients.*/void connection_event_loop() &#123; Connection_handler_manager *mgr = Connection_handler_manager::get_instance(); while (!connection_events_loop_aborted()) &#123; Channel_info *channel_info = m_listener-&gt;listen_for_connection_event(); if (channel_info != NULL) mgr-&gt;process_new_connection(channel_info); &#125;&#125; 新连接服务端一直处于监听状态，当有新连接请求时，调用process_new_connection处理新连接。 sql/conn_handler/connection_handler_manager.cc1234567891011121314void Connection_handler_manager::process_new_connection( Channel_info *channel_info) &#123; if (connection_events_loop_aborted() || !check_and_incr_conn_count(channel_info-&gt;is_admin_connection())) &#123; channel_info-&gt;send_error_and_close_channel(ER_CON_COUNT_ERROR, 0, true); delete channel_info; return; &#125; if (m_connection_handler-&gt;add_connection(channel_info)) &#123; inc_aborted_connects(); delete channel_info; &#125;&#125; connection_events_loop_aborted：先判断是否已取消监听 check_and_incr_conn_count：再判断（会加锁）是否现有连接数是否大于连接最大值（连接池满），未满，则将线程数加一，满了则拒绝连接。（注意，这里的判断逻辑使MySQL的实际最大连接数是max_connections + 1） add_connection：调用add_connection添加连接 sql/conn_handler/connection_handler_pre_thread.cc123456789101112131415161718192021222324252627282930313233bool Per_thread_connection_handler::add_connection(Channel_info *channel_info) &#123; int error = 0; my_thread_handle id; DBUG_ENTER("Per_thread_connection_handler::add_connection"); // Simulate thread creation for test case before we check thread cache DBUG_EXECUTE_IF("fail_thread_create", error = 1; goto handle_error;); if (!check_idle_thread_and_enqueue_connection(channel_info)) DBUG_RETURN(false); /* There are no idle threads avaliable to take up the new connection. Create a new thread to handle the connection */ channel_info-&gt;set_prior_thr_create_utime(); error = mysql_thread_create(key_thread_one_connection, &amp;id, &amp;connection_attrib, handle_connection, (void *)channel_info);#ifndef DBUG_OFFhandle_error:#endif // !DBUG_OFF if (error) &#123; ... //错误处理，略 &#125; Global_THD_manager::get_instance()-&gt;inc_thread_created(); DBUG_PRINT("info", ("Thread created")); DBUG_RETURN(false);&#125; 调用check_idle_thread_and_enqueue_connection查看是否有空闲的线程，有则将本次连接信息加入等待队列，并给空闲线程发送唤醒信号；否则新建线程处理本次连接 在新线程中，调用handle_connection函数开始进行逻辑处理。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687static void *handle_connection(void *arg) &#123; Global_THD_manager *thd_manager = Global_THD_manager::get_instance(); Connection_handler_manager *handler_manager = Connection_handler_manager::get_instance(); Channel_info *channel_info = static_cast&lt;Channel_info *&gt;(arg); bool pthread_reused MY_ATTRIBUTE((unused)) = false; if (my_thread_init()) &#123; ... //错误处理，略 &#125; for (;;) &#123; THD *thd = init_new_thd(channel_info); if (thd == NULL) &#123; ... //错误处理，略 &#125;#ifdef HAVE_PSI_THREAD_INTERFACE if (pthread_reused) &#123; ... //错误处理，略 &#125;#endif#ifdef HAVE_PSI_THREAD_INTERFACE /* Find the instrumented thread */ PSI_thread *psi = PSI_THREAD_CALL(get_thread)(); /* Save it within THD, so it can be inspected */ thd-&gt;set_psi(psi);#endif /* HAVE_PSI_THREAD_INTERFACE */ mysql_thread_set_psi_id(thd-&gt;thread_id()); mysql_thread_set_psi_THD(thd); mysql_socket_set_thread_owner( thd-&gt;get_protocol_classic()-&gt;get_vio()-&gt;mysql_socket); thd_manager-&gt;add_thd(thd); if (thd_prepare_connection(thd)) handler_manager-&gt;inc_aborted_connects(); else &#123; while (thd_connection_alive(thd)) &#123; if (do_command(thd)) break; &#125; end_connection(thd); &#125; close_connection(thd, 0, false, false); thd-&gt;get_stmt_da()-&gt;reset_diagnostics_area(); thd-&gt;release_resources(); // Clean up errors now, before possibly waiting for a new connection.#ifndef HAVE_WOLFSSL#if OPENSSL_VERSION_NUMBER &lt; 0x10100000L ERR_remove_thread_state(0);#endif /* OPENSSL_VERSION_NUMBER &lt; 0x10100000L */#endif thd_manager-&gt;remove_thd(thd); Connection_handler_manager::dec_connection_count();#ifdef HAVE_PSI_THREAD_INTERFACE /* Delete the instrumentation for the job that just completed. */ thd-&gt;set_psi(NULL); PSI_THREAD_CALL(delete_current_thread)();#endif /* HAVE_PSI_THREAD_INTERFACE */ delete thd; // Server is shutting down so end the pthread. if (connection_events_loop_aborted()) break; channel_info = Per_thread_connection_handler::block_until_new_connection(); if (channel_info == NULL) break; pthread_reused = true; if (connection_events_loop_aborted()) &#123; ... //错误处理，略 &#125; &#125; my_thread_end(); my_thread_exit(0); return NULL;&#125; 会对连接进行thd_prepare_connection预处理操作，没问题后继续下面的逻辑。 当连接未被关闭，就会一直do_command处理请求。 当连接关闭，则走下面关闭逻辑 执行sql/sql_parse.cc12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697bool do_command(THD *thd) &#123; bool return_value; int rc; NET *net = NULL; enum enum_server_command command; COM_DATA com_data; DBUG_ENTER("do_command"); DBUG_ASSERT(thd-&gt;is_classic_protocol()); /* indicator of uninitialized lex =&gt; normal flow of errors handling (see my_message_sql) */ thd-&gt;lex-&gt;set_current_select(0); /* XXX: this code is here only to clear possible errors of init_connect. Consider moving to prepare_new_connection_state() instead. That requires making sure the DA is cleared before non-parsing statements such as COM_QUIT. */ thd-&gt;clear_error(); // Clear error message thd-&gt;get_stmt_da()-&gt;reset_diagnostics_area(); /* This thread will do a blocking read from the client which will be interrupted when the next command is received from the client, the connection is closed or "net_wait_timeout" number of seconds has passed. */ net = thd-&gt;get_protocol_classic()-&gt;get_net(); my_net_set_read_timeout(net, thd-&gt;variables.net_wait_timeout); net_new_transaction(net); /* Synchronization point for testing of KILL_CONNECTION. This sync point can wait here, to simulate slow code execution between the last test of thd-&gt;killed and blocking in read(). The goal of this test is to verify that a connection does not hang, if it is killed at this point of execution. (Bug#37780 - main.kill fails randomly) Note that the sync point wait itself will be terminated by a kill. In this case it consumes a condition broadcast, but does not change anything else. The consumed broadcast should not matter here, because the read/recv() below doesn't use it. */ DEBUG_SYNC(thd, "before_do_command_net_read"); /* Because of networking layer callbacks in place, this call will maintain the following instrumentation: - IDLE events - SOCKET events - STATEMENT events - STAGE events when reading a new network packet. In particular, a new instrumented statement is started. See init_net_server_extension() */ thd-&gt;m_server_idle = true; rc = thd-&gt;get_protocol()-&gt;get_command(&amp;com_data, &amp;command); thd-&gt;m_server_idle = false; if (rc) &#123; ... //错误处理，略 &#125; char desc[VIO_DESCRIPTION_SIZE]; vio_description(net-&gt;vio, desc); DBUG_PRINT("info", ("Command on %s = %d (%s)", desc, command, command_name[command].str)); DBUG_PRINT("info", ("packet: '%*.s'; command: %d", thd-&gt;get_protocol_classic()-&gt;get_packet_length(), thd-&gt;get_protocol_classic()-&gt;get_raw_packet(), command)); if (thd-&gt;get_protocol_classic()-&gt;bad_packet) DBUG_ASSERT(0); // Should be caught earlier // Reclaim some memory thd-&gt;get_protocol_classic()-&gt;get_output_packet()-&gt;shrink( thd-&gt;variables.net_buffer_length); /* Restore read timeout value */ my_net_set_read_timeout(net, thd-&gt;variables.net_read_timeout); return_value = dispatch_command(thd, &amp;com_data, command); thd-&gt;get_protocol_classic()-&gt;get_output_packet()-&gt;shrink( thd-&gt;variables.net_buffer_length);out: /* The statement instrumentation must be closed in all cases. */ DBUG_ASSERT(thd-&gt;m_digest == NULL); DBUG_ASSERT(thd-&gt;m_statement_psi == NULL); DBUG_RETURN(return_value);&#125; 主要的处理逻辑为dispatch_command，根据不同的command类型进行分发。 123456789101112131415161718192021222324252627282930313233343536373839/** Perform one connection-level (COM_XXXX) command. @param thd connection handle @param command type of command to perform @param com_data com_data union to store the generated command @todo set thd-&gt;lex-&gt;sql_command to SQLCOM_END here. @todo The following has to be changed to an 8 byte integer @retval 0 ok @retval 1 request of thread shutdown, i. e. if command is COM_QUIT*/bool dispatch_command(THD *thd, const COM_DATA *com_data, enum enum_server_command command) &#123; ... //太长不看 switch (command) &#123; case ... //太长不看 case COM_QUERY: &#123; ... //太长不看 mysql_parse(thd, &amp;parser_state); ... //太长不看 DBUG_PRINT("info", ("query ready")); break; &#125; case ... //太长不看 default: my_error(ER_UNKNOWN_COM_ERROR, MYF(0)); break; &#125;&#125; 主要看COM_QUERY这个逻辑，我们要用到的DDL、DML都会走这个流程，这个流程中主要是调用mysql_parse方法 123456789101112131415161718192021222324252627282930/** Parse a query. @param thd Current session. @param parser_state Parser state.*/void mysql_parse(THD *thd, Parser_state *parser_state) &#123; ... //太长不看 mysql_reset_thd_for_next_command(thd); if (!err) &#123; err = parse_sql(thd, parser_state, NULL); ... //太长不看 &#125; if (!err) &#123; mysql_rewrite_query(thd); ... //太长不看 &#125; if (!err) &#123; ... error = mysql_execute_command(thd, true); ... &#125;&#125; 主要是SQL语法解析和执行 mysql_reset_thd_for_next_command是对下一次执行做准备，重置线程各变量 mysql_rewrite_query看着像是SQL优化？待定 还没追进去，记个TODO 词法解析前不应该有缓存吗？没有找到缓存的逻辑，记个TODO 关闭连接sql/conn_handler/connection_handler_pre_thread.cc123456789101112131415161718192021222324252627282930313233343536373839Channel_info *Per_thread_connection_handler::block_until_new_connection() &#123; Channel_info *new_conn = NULL; mysql_mutex_lock(&amp;LOCK_thread_cache); if (blocked_pthread_count &lt; max_blocked_pthreads &amp;&amp; !shrink_cache) &#123; /* Don't kill the pthread, just block it for reuse */ DBUG_PRINT("info", ("Blocking pthread for reuse")); /* mysys_var is bound to the physical thread, so make sure mysys_var-&gt;dbug is reset to a clean state before picking another session in the thread cache. */ DBUG_POP(); DBUG_ASSERT(!_db_is_pushed_()); // Block pthread blocked_pthread_count++; while (!connection_events_loop_aborted() &amp;&amp; !wake_pthread &amp;&amp; !shrink_cache) mysql_cond_wait(&amp;COND_thread_cache, &amp;LOCK_thread_cache); blocked_pthread_count--; if (shrink_cache &amp;&amp; blocked_pthread_count &lt;= max_blocked_pthreads) &#123; mysql_cond_signal(&amp;COND_flush_thread_cache); &#125; if (wake_pthread) &#123; wake_pthread--; if (!waiting_channel_info_list-&gt;empty()) &#123; new_conn = waiting_channel_info_list-&gt;front(); waiting_channel_info_list-&gt;pop_front(); DBUG_PRINT("info", ("waiting_channel_info_list-&gt;pop %p", new_conn)); &#125; else &#123; DBUG_ASSERT(0); // We should not get here. &#125; &#125; &#125; mysql_mutex_unlock(&amp;LOCK_thread_cache); return new_conn;&#125; 如果阻塞的线程数小于最大阻塞线程数，则此线程不回收，而是进入阻塞状态（等待），等待新连接来的时候重复使用。 否则关闭线程。 客户端未完待续。。。 参考文献：https://www.cnblogs.com/FateTHarlaown/p/8676166.html]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-PHP】答题助手 PHP SWOOLE WebSocket 实战]]></title>
    <url>%2Fd59cfb42.html</url>
    <content type="text"><![CDATA[前言2018年伊始，各种答题赚钱热流席卷了朋友圈，先有百万英雄、冲顶大会成为风口浪尖，又有全民答题推波助澜。 公司适时推出了 《XX答题助手》采用“真人工 · 智能“的方式在直播答题的同时为大家提供参考答案，帮助大家稳、准、快的答对12道题目，分得真金白银。接下来我们以xx答题助手为例聊一聊websocket的应用 背景介绍 答题助手目前的planA如上 客户端采用轮询的方式每秒向服务器发送2次http请求，若有正确答案返回则展示在页面上。这种方式给服务器带来了很大的压力 答题直播时，每一个使用答题助手的用户会给服务器带来2qps的压力。经过优化目前每台服务器能抗约1w/qps的并发，当用户数上来后只能加机器。 分析业务场景，其实大多数的请求是无效的，客户端只需要在答题结果出来后，接收答案并展示即可。因此完全可以采用websocket的方法，在服务端获取到答案时，主动push消息到客户端即可。 Websocket协议Websocket协议是基于tcp协议的应用层协议 主要是为了实现客户端与服务端的全双工通信。 Websocket与HTTPWebsocket与HTTP都是基于TCP协议的应用层协议，Websocket在建立连接时需要先发送HTTP请求与服务器握手，待服务器返回101进行协议转换，从HTTP切成Websocket协议进行通信 握手过程如上：一、客户端：申请协议升级 客户端发起协议升级请求。采用HTTP报文，且仅支持GET方式 含义： Request Method: GET 使用get的方式 Connection: Upgrade 表示要升级协议 Upgrade: websocket 表示要升级的协议是websocket Sec-WebScoket-Version: 13 websocket协议支持的版本号。如果服务端不支持该版本，服务端需要返回一个Sec-WebScoket-Version Header，里面包含支持的版本号 Sec-WebSocket-Key: 7PMYxFH/jxrVsZvKeSTW1Q== 采用base64编码的随机16字节长的字符序列 Sec-WebScocket-Extensions: permessage-deflate; client_max_window_bits 希望采用的扩展协议 二、服务端：响应协议升级 Connection: upgrade 同意升级 Sec-WebSocket-Accept: E1rL2SuyYrDeuDYc5kUQApGBsyg= 服务端根据请求首部的Sec-WebSocket-Key计算出来的 计算方式如下： 1、将Sec-WebSocket-Key和 258EAFA5-E914-47DA-95CA-C5AB0DC85B11 进行拼接 2、经过SHA1计算并转成base64 Sec-WebSocket-Version: 13 升级版本为13 Upgrade: websocket 升级的协议是websocket 三、客户端验证客户端同样通过将Sec-WebSocket-Key和258EAFA5-E914-47DA-95CA-C5AB0DC85B11 拼接经过SHA1计算，转为base64后与Sec-WebSocket-Accept对比，相等则验证成功 至此连接建立，由HTTP协议切换为WebSocket协议 技术方案在了解WebSocket协议原理后 可基于TCP socket通过处理协议及数据帧搭建WebSocket服务。因swoole扩展已经对WebSocket进行了很好的封装以及进程的管理，同时是以C来实现的WebSocket，性能及稳定性都经过了很多大公司的检验，最终选用Swoole进行开发 Swoole扩展安装：下载swoole-2.0.12 table版 解压 进入解压目录 按以下步骤安装 (swoole2.0.12版本起不再支持php5，扩展编译需gcc-4.4+版本) 安装完毕在php.ini配置文件中加上extension=swoole.so即可启用swoole扩展 可使用下面几行代码实现一个最简单的WebSocket Server: 在on方法中注册事件以及其对应的回调函数进行处理。其中onMessage回调函数为必选，否则服务不会启动。用户可以onHandShake回调自定义握手协议，否则将使用Swoole默认的协议握手 广播：直接发http请求能触发onRequest回调，可在回调中遍历connections属性广播请求 注意：connections是一个迭代器对象 并且依赖pcre库，若编译时为安装prce库，此属性无法使用。需yum install pcre-devel 后重新编译swoole扩展使用 动态路由：搭建通用服务，使用一个websocket server提供多种类型的服务，需要根据路由动态选择服务类型和处理逻辑 可在onOpen时获取request对象的request_uri属性来根据url选择不同的路由做处理 onMessage时，无法获取request 需要在消息体内指定request_uri选择路由 性能压测主要测试WebSocket Server能抗住多少长连接和并发，以及push消息时的速度和消息到达率 fork N个进程使用异步非阻塞客户端进行压测 在32核 128G机器上测得部分数据如下： 并发数为55000时，cpu的idle峰值约为87%，链接建立后保持连接时约为99% push消息时97% push55000条消息平均需要200ms，消息送达率为100% 可见WebSocket长连接对机器资源的消耗非常小。 监控为了能在系统负载过大、无法申请到内存、程序被误杀等情况下 能重新拉起server需要有脚本监测 自动启动主进程，脚本如下 停止脚本 需要在Server启动后设置进程名称 至此WebSocket服务的搭建及压测监控都已完成。接下来在完成服务的稳定性、上下线等运维相关的工作后会计划灰度上线 后期结论会继续同步]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>WebSocket</tag>
        <tag>Swoole</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-Hadoop】Hadoop基础学习]]></title>
    <url>%2F76483f54.html</url>
    <content type="text"><![CDATA[前言目前人工智能和大数据火热，使用的场景也越来越广，日常开发中也逐渐接触了更多与大数据相关的开发需求。因此对大数据知识也有必要进行一些学习理解 基础概念大数据的本质一、数据的存储：分布式文件系统（分布式存储） 二、数据的计算：分部署计算 基础知识学习大数据需要具备Java知识基础及Linux知识基础 学习路线Java基础和Linux基础Hadoop的学习：体系结构、原理、编程第一阶段： HDFS、MapReduce、HBase（NoSQL数据库） 第二阶段： 数据分析引擎 -&gt; Hive、Pig 数据采集引擎 -&gt; Sqoop、Flume 第三阶段： HUE：Web管理工具 ZooKeeper：实现Hadoop的HA Oozie：工作流引擎 Spark的学习第一阶段：Scala编程语言 第二阶段：Spark Core -&gt; 基于内存、数据的计算 第三阶段：Spark SQL -&gt; 类似于mysql 的sql语句 第四阶段：Spark Streaming -&gt;进行流式计算：比如：自来水厂 Apache Storm 类似Spark Streaming -&gt;进行流式计算 NoSQLRedis基于内存的数据库 HDFS分布式文件系统 解决以下问题： 1、硬盘不够大：多几块硬盘，理论上可以无限大 2、数据不够安全：冗余度，hdfs默认冗余为3 ，用水平复制提高效率，传输按照数据库为单位：Hadoop1.x 64M，Hadoop2.x 128M 管理员：NameNode 硬盘：DataNode MapReduce基础编程模型：把一个大任务拆分成小任务，再进行汇总 MR任务：Job = Map + Reduce Map的输出是Reduce的输入、MR的输入和输出都是在HDFS MapReduce数据流程分析： Map的输出是Reduce的输入，Reduce的输入是Map的集合 HBase什么是BigTable？: 把所有的数据保存到一张表中，采用冗余 —&gt; 好处：提高效率 1、因为有了bigtable的思想：NoSQL：HBase数据库 2、HBase基于Hadoop的HDFS的 3、描述HBase的表结构 核心思想是：利用空间换效率 Hadoop环境搭建环境准备Linux环境、JDK、http://mirrors.shu.edu.cn/apache/hadoop/common/hadoop-3.0.0/hadoop-3.0.0-src.tar.gz 安装1、安装jdk、并配置环境变量 vim /etc/profile 末尾添加 2、解压hadoop-3.0.0.tar.gz、并配置环境变量 tar -zxvf hadoop-3.0.0.tar.gz -C /usr/local/ mv hadoop-3.0.0/ hadoop vim /etc/profile 末尾添加 配置Hadoop有三种安装模式： 本地模式 ： 1台主机 不具备HDFS，只能测试MapReduce程序 伪分布模式： 1台主机 具备Hadoop的所有功能，在单机上模拟一个分布式的环境 （1）HDFS：主：NameNode，数据节点：DataNode （2）Yarn：容器，运行MapReduce程序 主节点：ResourceManager 从节点：NodeManager 全分布模式： 至少3台 我们以伪分布模式为例配置： 修改hdfs-site.xml：冗余度1、权限检查false&lt;!--配置冗余度为1--&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;!--配置权限检查为false--&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; 修改core-site.xml&lt;!--配置HDFS的NameNode--&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://192.168.56.102:9000&lt;/value&gt; &lt;/property&gt; &lt;!--配置DataNode保存数据的位置--&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt; &lt;/property&gt; 修改mapred-site.xml&lt;!--配置MR运行的框架--&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yar&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.map.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.reduce.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.application.classpath&lt;/name&gt; &lt;value&gt; /usr/local/hadoop/etc/hadoop, /usr/local/hadoop/share/hadoop/common/*, /usr/local/hadoop/share/hadoop/common/lib/*, /usr/local/hadoop/share/hadoop/hdfs/*, /usr/local/hadoop/share/hadoop/hdfs/lib/*, /usr/local/hadoop/share/hadoop/mapreduce/*, /usr/local/hadoop/share/hadoop/mapreduce/lib/*, /usr/local/hadoop/share/hadoop/yarn/*, /usr/local/hadoop/share/hadoop/yarn/lib/*, &lt;/value&gt; &lt;/property&gt; 修改yarn-site.xml&lt;!--配置ResourceManager地址--&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;192.168.56.102&lt;/value&gt; &lt;/property&gt; &lt;!--配置NodeManager执行任务的方式--&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-service&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; 格式化NameNodehdfs namenode -format 看到common.Storage: Storage directory /usr/local/hadoop/tmp/dfs/name has been successfully formatted表示格式化成功 启动start-all.sh HDFS：存储数据 YARN： 访问 命令行 Java Api WEB Console HDFS: http://192.168.56.102:50070 Yarn: http://192.168.56.102:8088 查看HDFS管理界面和yarn资源管理系统 基本操作：HDFS相关命令-mkdir 在HDFD创建目录 hdfs dfs -mkdir /data -ls 查看目录 hdfs dfs -ls -ls -R 查看目录与子目录 hdfs dfs -ls -R -put 上传一个文件 hdfs dfs -put data.txt /data/input -copyFromLocal 上传一个文件 与-put一样 -moveFromLocal 上传一个文件并删除本地文件 -copyToLocal 下载文件 hdfs dfs -copyTolocal /data/input/data.txt -put 下载文件 hdfs dfs -put/data/input/data.txt -rm 删除文件 hdfs dfs -rm -getmerge 将目录所有文件先合并再下载 -cp 拷贝 -mv 移动 -count 统计目录下的文件个数 -text、-cat 查看文件 -balancer 平衡操作 MapReduce示例 结果： 如上 一个最简单的MapReduce示例就执行成功了 思考Hadoop是基于Java语言的，日常开发是用的PHP(写文章时，博主主要是用PHP，现在已经转Java了)，在使用、查找错误时还是蛮吃力的。工作之余还是需要多补充点其它语言的相关知识，编程语言是我们开发、学习的工具，而不应成为限制我们技术成长的瓶颈]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-PHP】foreach 引用的坑]]></title>
    <url>%2F76b41bca.html</url>
    <content type="text"><![CDATA[背景描述先看一段代码。1234567891011121314151617181920212223242526272829&lt;?php/*$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];$b = &amp;$arr['jack'];$a = $arr;$b = 30;var_dump($a);$str = '20';$c = &amp;$str;$d = $str;$c = 30;var_dump($d);*/$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];foreach ($arr as &amp;$val) &#123; echo $val;&#125;foreach ($arr as $val) &#123; echo $val;&#125;print_r($arr); 想一下应该输出什么呢？ 运行一下脚本，真实结果和你想的是否一致呢？ 在foreach中使用了引用后再次foreach发现$arr[‘less’]的值变成了54，常规理解应该是23才对。 猜测可能是因为使用引用导致该值变为54 但本着知其然更要知其所以然 我们一起追一下php源码 是什么原因导致的 环境准备工欲善其事必先利其器，先下载调试工具及源码 下载Visual Studio 2017，并安装下载地址：https://www.visualstudio.com/zh-hans/downloads/ 下载php源码http://cn2.php.net/distributions/php-7.0.27.tar.bz2 从文件夹创建解决方案创建成功后如下图所示 源码追踪先搜索关键字foreach 可以在zend_language_parser.c 中看到， 语法解析时 foreach会当做T_FOREACH 在zend_language_parser.y可以看到语法解析的具体方式 ZEND_AST_FOREACH 查找zend_ast_create zend_ast.c中： zend_ast_create 函数是创建一个抽象语法树（abstract syntax tree）返回的zend_ast结构如下： 具体的赋值操作如下： 接下来在zend_compile.c中根据抽象语法树生成opcode： 通过上图及语法解析的分析可知，foreach在编译阶段会生成如上图的四个zend_ast节点，分别表示：要遍历的数组或对象expr_ast，要遍历的value value_ast，要遍历的key key_ast，循环体stmt_ast如： 12345$arr = [1, 2, 3];foreach ($arr as $key =&gt; $val) &#123; echo $val;&#125; expr_ast 是可理解为是$arr编译时对应的ast结构 value_ast对应$val key_ast对应$key stmt_ast对应”echo $val;” copy一份要遍历的数组或对象，如果是引用则把原数组或对象设为引用类型如：123foreach ($arr as $k =&gt; $v) &#123; echo $v;&#125; copy一份$arr用于遍历，从arData的首元素起，把bucket.zval.value赋值给$v,把bucket.h或key赋值给$k，然后将下一个元素的位置记录在zval.u2.fe_iter_idx中，下次遍历从该位置开始 当u2.fe_iter_idex到了arData的末尾则遍历结束并销毁copy的$arr副本 如果$v是引用 则在循环前，将原$arr设置为引用类型 即：123foreach ($arr as $k =&gt; &amp;$v) &#123; echo $v;&#125; 编译copy的数组、对象操作的指令：增加一条opcode指令 ZEND_FE_RESET_R（如果value是引用则用ZEND_FE_RESET_RW） 。执行时如果发现遍历的不是数组、对象 则抛出一个warning，然后跳出循环。 编译fetch数组、对象当前单元key 、value的opcode : ZEND_FE_FETCH_R（如果value是引用则用ZEND_FE_FETCH_RW）。此opcode需要知道当遍历到达数组末尾时跳出遍历的位置。此外还会对key和value分配他们在内存中的位置，如果value不是一CV个变量，还会编译其它操作的opcode 如果定义了key，则会编译一条opcode，对key进行赋值 编译循环体statement 编译跳回遍历开始时的opcode，一次遍历结束后跳到步骤2编译的opcode进行下次遍历 设置步骤1、2两条opcode如果出错要跳到的opcode 结束循环 编译ZEND_FE_FREE用于释放1中copy的数组或对象结论分析编译后的结构： 运行时步骤： (1) 执行ZEND_FE_RESET_R，过程上面已经介绍了； (2) 执行ZEND_FE_FETCH_R，此opcode的操作主要有三个：检查遍历位置是否到达末尾、将数组元素的value赋值给$value、将数组元素的key赋值给一个临时变量(注意与value不同)； (3) 如果定义了key则执行ZEND_ASSIGN，将key的值从临时变量赋值给$key，否则跳到步骤(4)； (4) 执行循环体的statement； (5) 执行ZEND_JMPNZ跳回步骤(2)； (6) 遍历结束后执行ZEND_FE_FREE释放数组。 因此根据上面的分析：赋值的核心操作是ZEND_FE_FETCH_RW 上面的例子可等价于123456789101112131415$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];$val = &amp;$arr['jack'];$val = &amp;$arr['tom'];$val = &amp;$arr['marry'];$val = &amp;$arr['less'];$val = $arr['jack'];$val = $arr['tom'];$val = $arr['marry'];$val = $arr['less'];print_r($arr); 等价于：12345678910$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];$val = &amp;$arr['less']; (23)$val = $arr['marry']; (54，并且此时因为引用 $arr['less']也变为54了)$val = $arr['less']; (54)print_r($arr); 因此 为了避免出现不必要的错误，建议在使用完&amp;后，unset掉变量以取消对地址的引用 思维发散：针对以上情况，如果不取消对变量的引用，而是将数组赋值给一个新的变量再foreach。是否可行？ 先看一段代码：123456&lt;?php$str = '20';$c = &amp;$str;$a = $str;$c = 30;var_dump($a); 输出20 没有任何问题如果换成数组：1234567891011&lt;?php$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];$b = &amp;$arr;$a = $arr;$b['jack'] = 30;var_dump($a); 还是20 符合预期但如果这样呢：1234567891011&lt;?php$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];$b = &amp;$arr['jack'];$a = $arr;$b = 30;var_dump($a) 值却变成了30我们加上xdebug_debug_zval看看发生了什么12345678910111213&lt;?php$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];$b = &amp;$arr;$a = $arr;$b['jack'] = 30;var_dump($a);xdebug_debug_zval('a');xdebug_debug_zval('arr'); 可以看出，直接引用数组， $b = &amp;$arr, $arr 的is_ref是1，refcount是2, 给$a = $arr时，发生分离，$a 与$arr指向不同的zval，$b 与 $arr指向相同的zval，因此给$b[‘jack’] = 30, $a的值不会发生改变12345678910111213&lt;?php$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];$b = &amp;$arr['jack'];$a = $arr;$b = 30;var_dump($a);xdebug_debug_zval('a');xdebug_debug_zval('arr') 可以看出，对数组中一个元素引用时，数组的is_ref是0，因为$a = $arr 因此refcount是2 ，指向同一个zval，改变$b的值时，因为$arr[‘jack’]是一个引用，zval的值改变，$a和$arr的zval相同，$a[‘jack’]也变为30同理可以回答最开始提出的疑问：如果我不取消对变量的引用，而是将数组赋值给一个新的变量再foreach。是否可行？答：不行。123456789101112131415&lt;?php$arr = [ 'jack' =&gt; '20', 'tom' =&gt; '21', 'marry' =&gt; '54', 'less' =&gt; '23'];foreach ($arr as &amp;$val) &#123; echo $val;&#125;$a = $arr;foreach ($a as $val) &#123; echo $val;&#125;print_r($a); 因为$arr与$a指向同一份zval，还是会出现$a[‘less’] = 54的结果。因此，在foreach使用完&amp;后，还是unset掉变量 取消对地址的引用再进行下一步操作吧 参考文献：https://github.com/pangudashu/php7-internal/blob/master/4/loop.md]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-MySQL】mysql 数据恢复实战&踩坑记录]]></title>
    <url>%2F6e2383f1.html</url>
    <content type="text"><![CDATA[背景介绍线下环境的两个mysql实例安装部署在同一台测试机器上使用不同端口，某天，机器硬盘故障无法启动、并且无法重装系统，需要将重要数据备份重新部署mysql并恢复 操作步骤备份数据首先联系pe同学通过带外方式启动故障主机并将硬盘挂载，通过scp方式将两个mysql实例的data目录下所有文件copy备份注意 切勿仅copy MYD，MYI，frm及ibd文件 准备环境原主机硬盘故障无法重装系统，需要到现场维修。所以新申请了一台主机使用安装与原mysql版本一致的mysql历史原因原主机安装的版本分别为5.1.40 和5.6.26主机自带5.1.40版本的mysql不需要自己再安装，直接将备份的data目录覆盖copy新机器的data目录 并修改好文件权限即可 安装mysql高版本的mysql需要重新安装 。步骤如下 下载glibc版wget https://cdn.mysql.com/archives/mysql-5.6/mysql-5.6.26-linux-glibc2.5-x86_64.tar.gz 解压并移动tar -zxvf mysql-5.6.26-linux-glibc2.5-x86_64.tar.gzmv mysql-5.6.26-linux-glibc2.5-x86_64.tar.gz /usr/local/mysql 修改权限并初始化1234chown -R mysql:mysql /usr/local/mysql cd /usr/local/mysql/bin# 修改/usr/local/mysql/my.cnf 修改启动端口和文件存放路径 1234sudo ./mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --lc_messages_dir=/usr/local/mysql/share --lc_messages=en_US --defaults-file=/usr/local/mysql/my.cnf #（如忘记密码可执行以下操作免密码登录）sudo /usr/bin/mysqld_safe --skip-grant-tables &amp; 将原数据data目录覆盖并修改权限登录验证至此 mysql数据恢复工作已经完成 踩坑记录背景之前两台测试环境mysql分别安装在不同的主机上，其中一台为虚拟主机，硬盘容量只有50G，出现过数据不断累积导致硬盘容量不足的情况，同时因为测试机器资源紧张，考虑将两个mysql实例安装在同一台物理主机上因物理主机上使用的mysql版本过低 所以新的mysql实例决定升级为高版本 安装时出现的问题在mysql官网现在了最新的稳定版mysql，解压、进行安装出现以下报错123456sudo ./mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --lc_messages_dir=/usr/local/mysql/share --lc_messages=en_US --defaults-file=/usr/local/mysql/my.cnf ./mysqld: /usr/lib64/libnuma.so.1: no version information available (required by ./mysqld)./mysqld: /usr/lib64/libnuma.so.1: no version information available (required by ./mysqld)./mysqld: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.11&apos; not found (required by ./mysqld)./mysqld: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.9&apos; not found (required by ./mysqld)./mysqld: /lib64/libc.so.6: version `GLIBC_2.10&apos; not found (required by ./mysqld) 看报错内容是一些依赖库版本过低导致，当时准备升级版本库在网上找到了 高版本的libstdc++ 、glibc等进行编译升级成功安装好了高版本 libstdc++后继续编译安装glibc编译安装好后，在删除原libc-2.5.so 更改软链为高版本libc时，悲剧出现了！因缺少libc库，所有的ls、ln、cp、sudo等命令全都无法使用了在网上找解决办法，可以在执行命令前使用LD_PRELOAD=/lib64/libc-2.5.so提前载入链接库来执行命令，ls、cp等命令可以用了但是使用ln命令时，发现权限不够ok，没关系 我们在sudo前 也提前载入链接库不就行了？执行：？？？ 尴尬了 竟然不行！查阅资料发现 sudo命令因为安全原因 不能使用LD_PRELOAD的方式 。我当时是在admin用户下 也无法sudo su切换到root 用户陷入了死循环、不切换到root用户就没权限恢复libc-2.5.so库 不恢复libc-2.5.so就没办法切换到root用户。。。无解，只能找pe同学帮忙，通过带外的方式恢复libc-2.5.so 解决方式系统恢复正常了，但是我们高版本的mysql还是没装上，系统库是不敢随便乱动了，那咋办呢？查看下glibc库版本天无绝人之路，发现有https://cdn.mysql.com/archives/mysql-5.6/mysql-5.6.26-linux-glibc2.5-x86_64.tar.gz glibc2.5版本的glibc版mysql安装包安装试试？通过上文 “安装mysql”中的方式 安装成功接下来修改用户密码、权限，通过mysqldump将原虚拟机中数据库的数据导入到5.6.26版本的数据库中 一台虚拟机上运行两个不同版本实例数据库大功告成~ mysql数据文件介绍表结构 .frm.frm文件：存储数据表的框架结构，文件名与表名相同，每个表对应一个同名frm文件，与操作系统和存储引擎无关 MyISAM数据文件.MYD文件：即MY Data，表数据文件.MYI文件：即MY Index，索引文件.log文件：日志文件 InnoDB数据文件ibdata1、ibdata2等：系统表空间文件，存储InnoDB系统信息和用户数据库表数据和索引，所有表共用.ibd文件：单表表空间文件，每个表使用一个表空间文件（file per table），存放用户数据库表数据和索引日志文件： ib_logfile1、ib_logfile2在备份和恢复数据时，我发现两个不同版本的数据库，ibdata1文件的大小相差很大查阅资料后发现原来InnoDB有两种不同的数据存储方式：共享表空间: 某一个数据库的所有的表数据，索引文件全部放在一个文件中，默认这个共享表空间的文件路径在data目录下。 默认的文件名为:ibdata1 初始化为10M。独占表空间: 每一个表都将会生成以独立的文件方式来进行存储（.ibd文件，这个文件包括了单独一个表的数据内容以及索引内容)。 存储内容比较使用独占表空间之后：每个表对应的数据、索引和插入缓冲 存放在独占表空间（.idb文件）每个表对应的撤销（undo）信息，系统事务信息，二次写缓冲等还是存放在了原来的共享表空间内（ibdata1文件） 特点比较具体的共享表空间和独立表空间优缺点如下：共享表空间：优点：可以放表空间分成多个文件存放到各个磁盘上（表空间文件大小不受表大小的限制，如一个表可以分布在不同的文件上）。数据和文件放在一起方便管理。缺点：所有的数据和索引存放到一个文件中，则将有一个很常大的文件，虽然可以把一个大文件分成多个小文件，但是多个表及索引在表空间中混合存储，这样对于一个表做了大量删除操作后表空间中将会有大量的空隙，特别是对于统计分析，日志系统这类应用最不适合用共享表空间。独立表空间：（在配置文件（my.cnf）中设置 innodb_file_per_table）优点：每个表都有自已独立的表空间。每个表的数据和索引都会存在自已的表空间中。可以实现单表在不同的数据库中移动。空间可以回收对于使用独立表空间的表，不管怎么删除，表空间的碎片不会太严重的影响性能，而且还有机会处理。a)Drop table操作自动回收表空间b）如果对于统计分析或是日值表，删除大量数据后可以通过:alter table TableName engine=innodb;回缩不用的空间。c) 对于使innodb-plugin的Innodb使用truncate table也会使空间收缩。5、在服务器资源有限,单表数据不是特别多的情况下, 独立表空间明显比共享方式效率更高 . 但是MySQL 默认是共享表空间 。缺点：单表体积可能过大，如超过100个G。查看innodb_file_per_table配置可以看到两个mysql的配置不一样，一个使用的共享表空间，一个使用的独占表空间，这就是为什么两个ibdata1文件大小相差很大注意：因为.frm、.ibd、.MYD、.MYI文件都存在于与database同名的文件夹下，我们通常会注意到而ibdata1文件是直接在data目录下，不理解其是什么文件的情况下很容易被忽略，所以 这就是在上文备份和恢复数据中提到需要注意的地方 参考文献http://www.jb51.net/article/134901.htm]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-MySQL】mysql中要避免使用大事务]]></title>
    <url>%2Fb382ba8d.html</url>
    <content type="text"><![CDATA[前言在日常工作中经常会使用一些比较“大”的数据库查询和操作，这里的“大”主要是指 执行时间长：含有较多的逻辑处理、存在较耗时操作等 操作数据多：需要查询或更新操作的数量记录较多，会锁定大量数据造成阻塞和锁超时等。 本文会和大家一起探讨下，为什么 在数据库中要避免使用这些大查询。 事务大家都清楚事务具备ACID特性（即原子性、一致性、隔离性、持久性），针对隔离性，在数据库事务隔离标准中，定义了四种隔离级别：读未提交、读提交、可重复读、串行化。MySQL默认的事务隔离级别是可重复读，我们以此来展开分析 事务隔离的实现多版本并发控制（MMVC）每行记录后面会有两个隐藏列，记录创建版本号及删除版本号。创建本本号记为row trx_id 对于一个事务来说，启动时（申请完事务id后），MySQL会给此事务创建一个活跃事务（即已启动但还未提交的事务）id数组。数组中的最小值记为minTid，最大值记为maxTid。 如果minTid &gt; row trx_id，则数据是可见的。 如果maxTid &lt; row trx_id，则数据是不可见的。 如果minTid &lt;= row trx_id &lt;= maxTid，且： row trx_id在数组中，则说明启动时，此事务未提交，数据不可见 row trx_id不在数组中，则说明启动是，此事务已提交，数据可见 如：当前事务id为50，活跃id数组为[35, 43, 44, 45, 46, 50, 51, 52]则 row trx_id小于35的数据为可见 row trx_id大于52的数据不可见 35 &lt;= row trx_id &lt;= 52且在数组中的数据不可见，不在数组中的数据可见。 对于不可见的数据，则需要依次去数据上一个版本查询，直到查询到可用版本数据为止。 只有在新的RW事务建立的时候 才会新建一个视图 否则继续使用上次创建的视图。 回滚日志（undo log）上面提到对于不可见数据需要依次查询上一版本来获取到可用数据。我们知道数据库的数据更新是非常频繁的，不可能将每一版本的数据都存下来，那样数据量会巨大查询也会非常的缓慢。MySQL通过undo log来获取历史版本的数据。undo log不会记录每个版本的最终数据，它是一个逻辑日志，是反向将之前的操作取消掉。比如对insert的会进行执行delete，delete的执行insert，对于update的数据会执行一个反向update，将之前修改的内容改回去。 例如： S1时刻，事务34启动，进行insert i = 5 操作后，commit，数据记录为D1：i = 5，row_id为34； S2时刻，事务36启动； S3时刻，事务37启动，进行update i + 3 操作后，commit，数据记录为D3：i = 8，row_id为37； S4时刻，事务42启动 S5时刻，事务54启动，进行update i * 2 操作后，commit，数据记录为D5：i = 16，row_id为54 此时，如果事务42需要查询i的数据，因为当前i = 16，row_id为54，数据不可见，因此需要根据undo log查询上一版本的数据。update i / 2，得到row_id为37。可见，获取i = 8如果事务36需要查询i的数据，需要update i / 2, 查到row_id = 37,不可见，继续回滚 update i - 3，查到row_id = 34，可见，获取到i = 5 只有当回滚日志不再需要时，才会删除。系统会判断，当没有事务再需要这些回滚日志的时候，才会删除。 所以长事务意味着系统里面会存在很多非常老的事务视图，因为这些事务可能会访问数据库中的任何数据，所以在这个事务提交之前，系统不得不保留它之后可能用到的所有回滚记录。这就会占用大量的存储空间。 事务启动autocommit参数控制事务是否自动提交，MySQL默认set autocommit=1，开启自动提交，即每条select、update都会自动提交。所以我们日常使用的SQL语句其实等价于123begin;select * from table where xxx;commit; 但有些客户端连接框架默认会在连接成功后执行一条set autocommit = 0，这样会导致你只有执行一条select语句其实就开启了事务。这样会意外导致长事务的出现。因此还是建议set autocommit = 1配合begin来显示的启动事务。 锁大事务还会长时间、大量占用锁资源，阻塞DML、DDL操作、造成锁超时影响系统并发能力，并且很容易引发死锁问题。 连接数大事务会长时间占用数据库连接，并发情况下容易造成连接数满的问题 拖垮整个应用 主备延迟MySQL主备复制只会在事务执行完毕后才会进行，即binlog在事务commit后才会生成（两阶段提交）。大事务执行多久就会造成多长时间的主备延迟，主备延迟的时间越长带来的风险也就越高 缓存MySQL的buffer pool对查询具有缓存效果，对于很多高频查询可以直接从缓存返回不需要查找磁盘文件。但是当有大量数据需要返回时通常有很多顺序查询，记录在同一磁盘页中就会命中缓存机制 对缓存造成一定影响MySQL buffer pool的缓存机制是使用的改良LRU算法（主要增加了访问时间控制） 内存&amp;CPUMySQL数据返回默认是边取边发，因此数据较多，传输时间较长也也会引发长事务带来的问题。还有如果返回大量数据给客户端处理，对客户端的内存及CPU也会带来较大的压力。 超时和超出大小限制容易引起超时的问题和超出max_binlog_cache_size导致执行失败。（还要注意，避免出现为了让主库大事务顺利进行，临时调大主库max_binlog_cache_size，忽略备库导致的服务宕掉等严重后果） 回滚回滚大事务也是非常耗时和占用内存的，需要注意 总结应该尽量避免使用大事务，开发时要注意尽量 如果可以，将一个大事务拆分成多个小事务执行 将事务中可以提出的select查询放在事务外执行]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【从入门到放弃-MySQL】CLion调试MySQL8.0源码]]></title>
    <url>%2Fc4ec5dd3.html</url>
    <content type="text"><![CDATA[前言想对的MySQL底层实现做一些了解，奈何没有用过C++不知道怎么调试一个大型项目，一日和大神交流时大神扔给我了一份《XCode调试MySQL8秘籍》。于是在几经波折（主要是因为菜）之后终于打开了MySQL的调试大门。 环境搭建准备MacOS： 10.14.5：因为根据大神秘籍，要使用Xcode，但Xcode下载目前只支持10.14.3，因此在10.13.6下强升的系统版本，Xcode下MySQL成功编译运行成功，但是遇到了诡异的调试无法的问题，排查无果最后转用CLionCLion：2019.1.3mysql源码：https://github.com/mysql/mysql-servercmake和boost：brew install cmake boost 编译MySQL源码目录：/var/workspace/mysql/mysql-8.0.16/boost目录：/usr/local/Cellar/boost/1.68.0_1 12345678910111213cd /var/workspace/mysql/mysql-8.0.16/mkdir workcd workcmake . -DWITH_DEBUG=1 -DCMAKE_INSTALL_PREFIX=/var/workspace/mysql/mysql-8.0.16/work -DMYSQL_DATADIR=/var/workspace/mysql/mysql-8.0.16/work/data -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_ARCHIVE_STORAGE_ENGINE=1 -DWITH_ARCHIVE_STORAGE_ENGINE=1 -DWITH_READLINE=1 -DWITH_LIBWRAP=0 -DMYSQL_UNIX_ADDR=/tmp/mysql.sock -DENABLED_LOCAL_INFILE=1 -DENABLED_LOCAL_INFILE=1 -DENABLE_DOWNLOADS=1 -DDOWNLOAD_BOOST=1 -DWITH_BOOST=/usr/local/Cellar/boost/1.68.0_1 -DFORCE_INSOURCE_BUILD=1make -j 4make install -j 4cd /var/workspace/mysql/mysql-8.0.16/worksudo bin/mysqld --basedir=/var/workspace/mysql/mysql-8.0.16/work --datadir=/var/workspace/mysql/mysql-8.0.16/work/data --initialize-insecure --user=mysql 如果最后一步执行出错可以参考https://dev.mysql.com/doc/refman/8.0/en/binary-installation.html新建mysql-files并修改权限 可能会有各种神奇的报错，主要是权限问题！搞不定的话参考下面有最终的目录权限截图 配置导入mysql-8.0.16项目，配置cmake参数 options参考编译过程中的cmake参数 选择mysqld 并编辑启动参数 arguments如下：1--basedir=/var/workspace/mysql/mysql-8.0.16/work --datadir=/var/workspace/mysql/mysql-8.0.16/work/data --user=mysql 启动调试，此时可能还会报错 还是权限问题。。。clion无法以root权限启动debug，尝试各种方法无效。因此把mysql的data目录改为777最终目录权限如下图： 再此点击debug按钮，启动成功（注意没error了，可以用客户端测试启动成功了）。 调试 我们在代码中打上断点，客户端执行SQL语句时就能在断点处看到各变量信息了，比如图中的SQL解析。 可以看到执行阻塞了 Clion代码调试的具体方法不做赘述了，网上一堆。 总结之前一直想调试MySQL，但是总是没有迈出第一步，代码下载下来就完事儿了。这次一鼓作气走了下来，希望能开个好头，养成各种代码调试的好习惯。看代码中细节比任何文档中都来的扎实（当然，时间充裕前提下）。搭建环境的过程中遇到了很多问题，Google、百度无数遍都没有能解决问题，最终还是通过MySQL的官方手册找到的答案。MySQL的官方手册简直神器，大家可以好好利用起来。C++的知识仅停留在大学课本阶段，阅读源码简直困难，要能坚持下去，加油！]]></content>
      <categories>
        <category>个人学习</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>C++</tag>
      </tags>
  </entry>
</search>
